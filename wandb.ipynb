{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Experiment Tracking with W&B\r\n",
    "\r\n",
    "- config: store hp and metadata for each run\r\n",
    "- wandb.init\r\n",
    "- wandb.watch: log model gradients and params over time (helps detect bugs e.g. weird grad behaviour)\r\n",
    "- wandb.log: log stuff we care about\r\n",
    "- wandb.save: save online\r\n",
    "\r\n",
    "use with block in context manager syntax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import wandb\r\n",
    "wandb.login()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = dict(\r\n",
    "    epochs = 50,\r\n",
    "    val_ratio = 0,\r\n",
    "    test_ratio = 0.2\r\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make(base_path, val_ratio, test_ratio, encode_data_name, decode_data_name, latent_dim):\r\n",
    "    # TODO: make edges to device here on when called on\r\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\r\n",
    "\r\n",
    "    # dataset to encode\r\n",
    "    encode_dataset = ReactionDataset(base_path, geo_file = encode_data_name, dataset_type= 'individual')\r\n",
    "    encode_data = encode_dataset.data\r\n",
    "    encode_data.train_mask = encode_data.val_mask = encode_data.test_mask = encode_data.y = None\r\n",
    "    encode_data = train_test_split_edges(data = encode_data, val_ratio = val_ratio, test_ratio = test_ratio)\r\n",
    "    encode_x = encode_data.x.to(device)\r\n",
    "    encode_train_pos_edge_index = encode_data.train_pos_edge_index.to(device)\r\n",
    "\r\n",
    "    # dataset to decode\r\n",
    "    decode_dataset = ReactionDataset(base_path, geo_file = decode_data_name, dataset_type= 'individual')\r\n",
    "    decode_data = decode_dataset.data\r\n",
    "    decode_data.train_mask = decode_data.val_mask = decode_data.test_mask = decode_data.y = None\r\n",
    "    decode_data = train_test_split_edges(data = decode_data, val_ratio = val_ratio, test_ratio = test_ratio)\r\n",
    "    decode_x = decode_data.x.to(device)\r\n",
    "    decode_train_pos_edge_index = decode_data.train_pos_edge_index.to(device)\r\n",
    "\r\n",
    "    # model creation\r\n",
    "    gae = GAE(MolEncoder(encode_data.num_node_features, latent_dim))\r\n",
    "    opt = torch.optim.Adam(gae.parameters(), lr = 0.01)\r\n",
    "\r\n",
    "    return gae, opt, encode_data, decode_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_pipeline(hps):\r\n",
    "\r\n",
    "    # start wandb\r\n",
    "    with wandb.init(project=\"test\", config=hps):\r\n",
    "        \r\n",
    "        # access hps through wandb.config so logging matches execution\r\n",
    "        config = wandb.config\r\n",
    "\r\n",
    "        # model data\r\n",
    "        \r\n",
    "        val_ratio = 0\r\n",
    "        test_ratio = 0.2\r\n",
    "        \r\n",
    "        # make model, data, opt problem\r\n",
    "        ts_r_gae, ts_r_opt, r_data, ts_data = make(r'data/', 0, 0.2, 'train_r', 'train_ts', 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing GAEs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ts_vae.gae import EGNN, EGNN_NEC, EGNN_AE\r\n",
    "from ts_vae.layers import GCL_PYG\r\n",
    "from ts_vae.data_processors.new_pyg_processor import ReactionDataset\r\n",
    "\r\n",
    "import torch\r\n",
    "import torch.nn as nn\r\n",
    "from torch_geometric.data import DataLoader\r\n",
    "\r\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove processed files\r\n",
    "\r\n",
    "import os\r\n",
    "import glob\r\n",
    "\r\n",
    "files = glob.glob(r'data/processed/*')\r\n",
    "for f in files:\r\n",
    "    os.remove(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/6739 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 30/6739 [00:00<01:22, 81.14it/s]\n",
      "  4%|▎         | 30/842 [00:00<00:02, 331.70it/s]\n",
      "  0%|          | 30/6739 [00:00<00:09, 692.98it/s]\n",
      "  4%|▎         | 30/842 [00:00<00:01, 416.85it/s]\n",
      "  0%|          | 30/6739 [00:00<00:16, 417.30it/s]\n",
      "  4%|▎         | 30/842 [00:00<00:01, 536.06it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done!\n"
     ]
    }
   ],
   "source": [
    "rxns = ReactionDataset(r'data')\r\n",
    "\r\n",
    "num_rxns = len(rxns)\r\n",
    "train_ratio = 0.8\r\n",
    "num_train = int(np.floor(train_ratio * num_rxns))\r\n",
    "\r\n",
    "train_loader = DataLoader(rxns[: num_train], batch_size = 2, follow_batch = ['r', 'p'])\r\n",
    "test_loader = DataLoader(rxns[num_train:], batch_size = 2, follow_batch = ['r', 'p'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "Data(edge_attr=[30, 4], edge_index=[2, 30], idx=48, pos=[15, 3], x=[15, 11], z=[15])"
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch = next(iter(test_loader))\r\n",
    "reactants = batch.r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "[Data(edge_attr=[30, 4], edge_index=[2, 30], idx=48, pos=[15, 3], x=[15, 11], z=[15]),\n Data(edge_attr=[26, 4], edge_index=[2, 26], idx=49, pos=[14, 3], x=[14, 11], z=[14])]"
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# prop_indices = [mol['edge_index'] for mol in batch.r]\r\n",
    "\r\n",
    "\r\n",
    "from torch_geometric.data.dataloader import DataListLoader\r\n",
    "\r\n",
    "# batch.r\r\n",
    "\r\n",
    "# dl = DataListLoader(rxns[0:10], batch_size = 2, follow_batch )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "def identity_collate(data_list):\r\n",
    "    return data_list\r\n",
    "\r\n",
    "class CustomDataLoader(torch.utils.data.DataLoader):\r\n",
    "    def __init__(self, dataset, batch_size = 1, shuffle = False, collate_fn = identity_collate, **kwargs):\r\n",
    "        super(CustomDataLoader, self).__init__(dataset, batch_size, shuffle, collate_fn = identity_collate, **kwargs)\r\n",
    "        # change to collate_fn = CustomCollater(follow_batch, exclude_keys)\r\n",
    "    \r\n",
    "\r\n",
    "class CustomCollater(object):\r\n",
    "    def __init__(self, follow_batch, exclude_keys):\r\n",
    "        self.follow_batch = follow_batch\r\n",
    "        self.exclude_keys = exclude_keys\r\n",
    "    \r\n",
    "    def collate(self, batch):\r\n",
    "        elem \r\n",
    "\r\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "[Data(edge_attr=[26, 4], edge_index=[2, 26], idx=0, pos=[15, 3], x=[15, 11], z=[15]),\n Data(edge_attr=[24, 4], edge_index=[2, 24], idx=1, pos=[13, 3], x=[13, 11], z=[13]),\n Data(edge_attr=[20, 4], edge_index=[2, 20], idx=2, pos=[10, 3], x=[10, 11], z=[10]),\n Data(edge_attr=[16, 4], edge_index=[2, 16], idx=3, pos=[9, 3], x=[9, 11], z=[9]),\n Data(edge_attr=[22, 4], edge_index=[2, 22], idx=4, pos=[11, 3], x=[11, 11], z=[11]),\n Data(edge_attr=[26, 4], edge_index=[2, 26], idx=5, pos=[14, 3], x=[14, 11], z=[14]),\n Data(edge_attr=[30, 4], edge_index=[2, 30], idx=6, pos=[15, 3], x=[15, 11], z=[15]),\n Data(edge_attr=[30, 4], edge_index=[2, 30], idx=7, pos=[15, 3], x=[15, 11], z=[15]),\n Data(edge_attr=[28, 4], edge_index=[2, 28], idx=8, pos=[15, 3], x=[15, 11], z=[15]),\n Data(edge_attr=[26, 4], edge_index=[2, 26], idx=9, pos=[14, 3], x=[14, 11], z=[14]),\n Data(edge_attr=[20, 4], edge_index=[2, 20], idx=10, pos=[11, 3], x=[11, 11], z=[11]),\n Data(edge_attr=[30, 4], edge_index=[2, 30], idx=11, pos=[15, 3], x=[15, 11], z=[15]),\n Data(edge_attr=[28, 4], edge_index=[2, 28], idx=12, pos=[15, 3], x=[15, 11], z=[15]),\n Data(edge_attr=[28, 4], edge_index=[2, 28], idx=13, pos=[14, 3], x=[14, 11], z=[14]),\n Data(edge_attr=[28, 4], edge_index=[2, 28], idx=14, pos=[14, 3], x=[14, 11], z=[14]),\n Data(edge_attr=[26, 4], edge_index=[2, 26], idx=15, pos=[13, 3], x=[13, 11], z=[13]),\n Data(edge_attr=[24, 4], edge_index=[2, 24], idx=16, pos=[13, 3], x=[13, 11], z=[13]),\n Data(edge_attr=[24, 4], edge_index=[2, 24], idx=17, pos=[12, 3], x=[12, 11], z=[12]),\n Data(edge_attr=[32, 4], edge_index=[2, 32], idx=18, pos=[16, 3], x=[16, 11], z=[16]),\n Data(edge_attr=[28, 4], edge_index=[2, 28], idx=19, pos=[15, 3], x=[15, 11], z=[15]),\n Data(edge_attr=[28, 4], edge_index=[2, 28], idx=20, pos=[15, 3], x=[15, 11], z=[15]),\n Data(edge_attr=[22, 4], edge_index=[2, 22], idx=21, pos=[13, 3], x=[13, 11], z=[13]),\n Data(edge_attr=[20, 4], edge_index=[2, 20], idx=22, pos=[10, 3], x=[10, 11], z=[10]),\n Data(edge_attr=[30, 4], edge_index=[2, 30], idx=23, pos=[15, 3], x=[15, 11], z=[15]),\n Data(edge_attr=[22, 4], edge_index=[2, 22], idx=24, pos=[11, 3], x=[11, 11], z=[11]),\n Data(edge_attr=[24, 4], edge_index=[2, 24], idx=25, pos=[12, 3], x=[12, 11], z=[12]),\n Data(edge_attr=[18, 4], edge_index=[2, 18], idx=26, pos=[9, 3], x=[9, 11], z=[9]),\n Data(edge_attr=[32, 4], edge_index=[2, 32], idx=27, pos=[17, 3], x=[17, 11], z=[17]),\n Data(edge_attr=[24, 4], edge_index=[2, 24], idx=28, pos=[13, 3], x=[13, 11], z=[13]),\n Data(edge_attr=[20, 4], edge_index=[2, 20], idx=29, pos=[11, 3], x=[11, 11], z=[11]),\n Data(edge_attr=[12, 4], edge_index=[2, 12], idx=30, pos=[7, 3], x=[7, 11], z=[7]),\n Data(edge_attr=[20, 4], edge_index=[2, 20], idx=31, pos=[11, 3], x=[11, 11], z=[11]),\n Data(edge_attr=[32, 4], edge_index=[2, 32], idx=32, pos=[16, 3], x=[16, 11], z=[16]),\n Data(edge_attr=[26, 4], edge_index=[2, 26], idx=33, pos=[13, 3], x=[13, 11], z=[13]),\n Data(edge_attr=[28, 4], edge_index=[2, 28], idx=34, pos=[13, 3], x=[13, 11], z=[13]),\n Data(edge_attr=[30, 4], edge_index=[2, 30], idx=35, pos=[14, 3], x=[14, 11], z=[14]),\n Data(edge_attr=[32, 4], edge_index=[2, 32], idx=36, pos=[15, 3], x=[15, 11], z=[15]),\n Data(edge_attr=[20, 4], edge_index=[2, 20], idx=37, pos=[11, 3], x=[11, 11], z=[11]),\n Data(edge_attr=[28, 4], edge_index=[2, 28], idx=38, pos=[14, 3], x=[14, 11], z=[14]),\n Data(edge_attr=[16, 4], edge_index=[2, 16], idx=39, pos=[8, 3], x=[8, 11], z=[8]),\n Data(edge_attr=[22, 4], edge_index=[2, 22], idx=40, pos=[11, 3], x=[11, 11], z=[11]),\n Data(edge_attr=[28, 4], edge_index=[2, 28], idx=41, pos=[14, 3], x=[14, 11], z=[14]),\n Data(edge_attr=[24, 4], edge_index=[2, 24], idx=42, pos=[12, 3], x=[12, 11], z=[12]),\n Data(edge_attr=[18, 4], edge_index=[2, 18], idx=43, pos=[10, 3], x=[10, 11], z=[10]),\n Data(edge_attr=[24, 4], edge_index=[2, 24], idx=44, pos=[13, 3], x=[13, 11], z=[13]),\n Data(edge_attr=[22, 4], edge_index=[2, 22], idx=45, pos=[11, 3], x=[11, 11], z=[11]),\n Data(edge_attr=[30, 4], edge_index=[2, 30], idx=46, pos=[16, 3], x=[16, 11], z=[16]),\n Data(edge_attr=[22, 4], edge_index=[2, 22], idx=47, pos=[11, 3], x=[11, 11], z=[11]),\n Data(edge_attr=[30, 4], edge_index=[2, 30], idx=48, pos=[15, 3], x=[15, 11], z=[15]),\n Data(edge_attr=[26, 4], edge_index=[2, 26], idx=49, pos=[14, 3], x=[14, 11], z=[14]),\n Data(edge_attr=[30, 4], edge_index=[2, 30], idx=50, pos=[14, 3], x=[14, 11], z=[14]),\n Data(edge_attr=[38, 4], edge_index=[2, 38], idx=51, pos=[17, 3], x=[17, 11], z=[17]),\n Data(edge_attr=[32, 4], edge_index=[2, 32], idx=52, pos=[15, 3], x=[15, 11], z=[15]),\n Data(edge_attr=[34, 4], edge_index=[2, 34], idx=53, pos=[17, 3], x=[17, 11], z=[17]),\n Data(edge_attr=[30, 4], edge_index=[2, 30], idx=54, pos=[13, 3], x=[13, 11], z=[13]),\n Data(edge_attr=[36, 4], edge_index=[2, 36], idx=55, pos=[17, 3], x=[17, 11], z=[17]),\n Data(edge_attr=[20, 4], edge_index=[2, 20], idx=56, pos=[10, 3], x=[10, 11], z=[10]),\n Data(edge_attr=[28, 4], edge_index=[2, 28], idx=57, pos=[15, 3], x=[15, 11], z=[15]),\n Data(edge_attr=[26, 4], edge_index=[2, 26], idx=58, pos=[13, 3], x=[13, 11], z=[13]),\n Data(edge_attr=[30, 4], edge_index=[2, 30], idx=59, pos=[14, 3], x=[14, 11], z=[14])]"
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rxns.data.r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'torch.Tensor'> <class 'torch.Tensor'>\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "The following operation failed in the TorchScript interpreter.\nTraceback of TorchScript (most recent call last):\n  File \"C:\\Users\\Avish\\miniconda3\\envs\\3d-rdkit\\lib\\site-packages\\torch_scatter\\scatter.py\", line 31, in scatter_add\n                out: Optional[torch.Tensor] = None,\n                dim_size: Optional[int] = None) -> torch.Tensor:\n    return scatter_sum(src, index, dim, out, dim_size)\n           ~~~~~~~~~~~ <--- HERE\n  File \"C:\\Users\\Avish\\miniconda3\\envs\\3d-rdkit\\lib\\site-packages\\torch_scatter\\scatter.py\", line 12, in scatter_sum\n                out: Optional[torch.Tensor] = None,\n                dim_size: Optional[int] = None) -> torch.Tensor:\n    index = broadcast(index, src, dim)\n            ~~~~~~~~~ <--- HERE\n    if out is None:\n        size = list(src.size())\n  File \"C:\\Users\\Avish\\miniconda3\\envs\\3d-rdkit\\lib\\site-packages\\torch_scatter\\utils.py\", line 13, in broadcast\n    for _ in range(src.dim(), other.dim()):\n        src = src.unsqueeze(-1)\n    src = src.expand_as(other)\n          ~~~~~~~~~~~~~ <--- HERE\n    return src\nRuntimeError: The expanded size of the tensor (29) must match the existing size (2) at non-singleton dimension 0.  Target sizes: [29].  Tensor sizes: [2]\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-71-61d400ef6295>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnode_feats\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch_idx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 14\u001b[1;33m \u001b[0mto_dense_batch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnode_feats\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_idx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;31m#, fill_value = 0, max_num_nodes = max_num_atoms)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\miniconda3\\envs\\3d-rdkit\\lib\\site-packages\\torch_geometric\\utils\\to_dense_batch.py\u001b[0m in \u001b[0;36mto_dense_batch\u001b[1;34m(x, batch, fill_value, max_num_nodes)\u001b[0m\n\u001b[0;32m     35\u001b[0m     \u001b[0mbatch_size\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     36\u001b[0m     num_nodes = scatter_add(batch.new_ones(x.size(0)), batch, dim=0,\n\u001b[1;32m---> 37\u001b[1;33m                             dim_size=batch_size)\n\u001b[0m\u001b[0;32m     38\u001b[0m     \u001b[0mcum_nodes\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mbatch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnew_zeros\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnum_nodes\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcumsum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdim\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     39\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: The following operation failed in the TorchScript interpreter.\nTraceback of TorchScript (most recent call last):\n  File \"C:\\Users\\Avish\\miniconda3\\envs\\3d-rdkit\\lib\\site-packages\\torch_scatter\\scatter.py\", line 31, in scatter_add\n                out: Optional[torch.Tensor] = None,\n                dim_size: Optional[int] = None) -> torch.Tensor:\n    return scatter_sum(src, index, dim, out, dim_size)\n           ~~~~~~~~~~~ <--- HERE\n  File \"C:\\Users\\Avish\\miniconda3\\envs\\3d-rdkit\\lib\\site-packages\\torch_scatter\\scatter.py\", line 12, in scatter_sum\n                out: Optional[torch.Tensor] = None,\n                dim_size: Optional[int] = None) -> torch.Tensor:\n    index = broadcast(index, src, dim)\n            ~~~~~~~~~ <--- HERE\n    if out is None:\n        size = list(src.size())\n  File \"C:\\Users\\Avish\\miniconda3\\envs\\3d-rdkit\\lib\\site-packages\\torch_scatter\\utils.py\", line 13, in broadcast\n    for _ in range(src.dim(), other.dim()):\n        src = src.unsqueeze(-1)\n    src = src.expand_as(other)\n          ~~~~~~~~~~~~~ <--- HERE\n    return src\nRuntimeError: The expanded size of the tensor (29) must match the existing size (2) at non-singleton dimension 0.  Target sizes: [29].  Tensor sizes: [2]\n"
     ]
    }
   ],
   "source": [
    "from torch_geometric.utils import to_dense_adj, to_dense_batch\r\n",
    "\r\n",
    "# do for node_feats, edge_index, edge_attr, \r\n",
    "\r\n",
    "# to_dense_batch()\r\n",
    "\r\n",
    "max_num_atoms = int(max(test_loader.dataset.data.num_atoms))\r\n",
    "\r\n",
    "\r\n",
    "\r\n",
    "node_feats = torch.cat([r.x for r in batch.r])\r\n",
    "batch_idx = batch.r_batch\r\n",
    "\r\n",
    "print(type(node_feats), type(batch_idx))\r\n",
    "\r\n",
    "to_dense_batch(node_feats, batch_idx)#, fill_value = 0, max_num_nodes = max_num_atoms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "The expanded size of the tensor (30) must match the existing size (26) at non-singleton dimension 1.  Target sizes: [2, 30].  Tensor sizes: [2, 26]",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-40-79436ec67cb3>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[0mlengths\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m \u001b[0mt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mt\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mprop_indices\u001b[0m \u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;31m## padd\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 8\u001b[1;33m \u001b[0mbatch\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrnn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpad_sequence\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mprop_indices\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      9\u001b[0m \u001b[1;31m## compute mask\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[0mmask\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mbatch\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\miniconda3\\envs\\3d-rdkit\\lib\\site-packages\\torch\\nn\\utils\\rnn.py\u001b[0m in \u001b[0;36mpad_sequence\u001b[1;34m(sequences, batch_first, padding_value)\u001b[0m\n\u001b[0;32m    372\u001b[0m             \u001b[0mout_tensor\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m:\u001b[0m\u001b[0mlength\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m...\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtensor\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    373\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 374\u001b[1;33m             \u001b[0mout_tensor\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mlength\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m...\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtensor\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    375\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    376\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mout_tensor\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: The expanded size of the tensor (30) must match the existing size (26) at non-singleton dimension 1.  Target sizes: [2, 30].  Tensor sizes: [2, 26]"
     ]
    }
   ],
   "source": [
    "# batch_mol_property(prop_indices)\r\n",
    "\r\n",
    "## get sequence lengths\r\n",
    "lengths = torch.tensor([ t.shape[0] for t in prop_indices ])\r\n",
    "## padd\r\n",
    "batch = torch.nn.utils.rnn.pad_sequence(prop_indices)\r\n",
    "## compute mask\r\n",
    "mask = (batch != 0).to(device)\r\n",
    "batch, lengths, mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0., 0., 0., 1., 0., 8., 0., 0., 0., 0., 1.],\n",
      "        [0., 1., 0., 0., 0., 6., 0., 0., 0., 0., 2.],\n",
      "        [0., 1., 0., 0., 0., 6., 0., 0., 0., 0., 2.],\n",
      "        [0., 0., 1., 0., 0., 7., 0., 0., 0., 0., 0.],\n",
      "        [0., 1., 0., 0., 0., 6., 0., 0., 0., 0., 2.],\n",
      "        [0., 1., 0., 0., 0., 6., 0., 0., 0., 0., 2.],\n",
      "        [1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.],\n",
      "        [1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.],\n",
      "        [1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.],\n",
      "        [1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.],\n",
      "        [1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.],\n",
      "        [1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.],\n",
      "        [1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.],\n",
      "        [1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.],\n",
      "        [1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.]])\n",
      "tensor([[0., 1., 0., 0., 0., 6., 0., 0., 0., 0., 3.],\n",
      "        [0., 1., 0., 0., 0., 6., 0., 0., 0., 0., 2.],\n",
      "        [0., 1., 0., 0., 0., 6., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 1., 0., 8., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 1., 0., 8., 0., 0., 0., 0., 0.],\n",
      "        [0., 1., 0., 0., 0., 6., 0., 0., 0., 0., 3.],\n",
      "        [1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.],\n",
      "        [1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.],\n",
      "        [1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.],\n",
      "        [1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.],\n",
      "        [1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.],\n",
      "        [1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.],\n",
      "        [1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.],\n",
      "        [1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.]])\n",
      "tensor([[ 0,  0,  1,  1,  1,  1,  2,  2,  2,  2,  3,  3,  3,  4,  4,  4,  4,  5,\n",
      "          5,  5,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14],\n",
      "        [ 1,  6,  0,  2,  7,  8,  1,  3,  9, 10,  2,  4,  5,  3,  5, 11, 12,  3,\n",
      "          4, 13, 14,  0,  1,  1,  2,  2,  4,  4,  5,  5]])\n",
      "tensor([[ 0,  0,  0,  0,  1,  1,  1,  1,  2,  2,  2,  3,  4,  4,  5,  5,  5,  5,\n",
      "          6,  7,  8,  9, 10, 11, 12, 13],\n",
      "        [ 1,  6,  7,  8,  0,  2,  9, 10,  1,  3,  4,  2,  2,  5,  4, 11, 12, 13,\n",
      "          0,  0,  0,  1,  1,  5,  5,  5]])\n",
      "tensor([[1., 0., 0., 0.],\n",
      "        [1., 0., 0., 0.],\n",
      "        [1., 0., 0., 0.],\n",
      "        [1., 0., 0., 0.],\n",
      "        [1., 0., 0., 0.],\n",
      "        [1., 0., 0., 0.],\n",
      "        [1., 0., 0., 0.],\n",
      "        [1., 0., 0., 0.],\n",
      "        [1., 0., 0., 0.],\n",
      "        [1., 0., 0., 0.],\n",
      "        [1., 0., 0., 0.],\n",
      "        [1., 0., 0., 0.],\n",
      "        [1., 0., 0., 0.],\n",
      "        [1., 0., 0., 0.],\n",
      "        [1., 0., 0., 0.],\n",
      "        [1., 0., 0., 0.],\n",
      "        [1., 0., 0., 0.],\n",
      "        [1., 0., 0., 0.],\n",
      "        [1., 0., 0., 0.],\n",
      "        [1., 0., 0., 0.],\n",
      "        [1., 0., 0., 0.],\n",
      "        [1., 0., 0., 0.],\n",
      "        [1., 0., 0., 0.],\n",
      "        [1., 0., 0., 0.],\n",
      "        [1., 0., 0., 0.],\n",
      "        [1., 0., 0., 0.],\n",
      "        [1., 0., 0., 0.],\n",
      "        [1., 0., 0., 0.],\n",
      "        [1., 0., 0., 0.],\n",
      "        [1., 0., 0., 0.]])\n",
      "tensor([[1., 0., 0., 0.],\n",
      "        [1., 0., 0., 0.],\n",
      "        [1., 0., 0., 0.],\n",
      "        [1., 0., 0., 0.],\n",
      "        [1., 0., 0., 0.],\n",
      "        [1., 0., 0., 0.],\n",
      "        [1., 0., 0., 0.],\n",
      "        [1., 0., 0., 0.],\n",
      "        [1., 0., 0., 0.],\n",
      "        [0., 1., 0., 0.],\n",
      "        [1., 0., 0., 0.],\n",
      "        [0., 1., 0., 0.],\n",
      "        [1., 0., 0., 0.],\n",
      "        [1., 0., 0., 0.],\n",
      "        [1., 0., 0., 0.],\n",
      "        [1., 0., 0., 0.],\n",
      "        [1., 0., 0., 0.],\n",
      "        [1., 0., 0., 0.],\n",
      "        [1., 0., 0., 0.],\n",
      "        [1., 0., 0., 0.],\n",
      "        [1., 0., 0., 0.],\n",
      "        [1., 0., 0., 0.],\n",
      "        [1., 0., 0., 0.],\n",
      "        [1., 0., 0., 0.],\n",
      "        [1., 0., 0., 0.],\n",
      "        [1., 0., 0., 0.]])\n",
      "tensor([[-2.4820, -0.0263, -0.3611],\n",
      "        [-1.6290, -0.3296,  0.7170],\n",
      "        [-0.3704,  0.5170,  0.6765],\n",
      "        [ 0.2987,  0.3007, -0.5960],\n",
      "        [ 1.6858,  0.6974, -0.6805],\n",
      "        [ 1.3135, -0.7351, -0.6228],\n",
      "        [-1.9135,  0.0651, -1.1335],\n",
      "        [-1.3528, -1.3944,  0.7105],\n",
      "        [-2.1830, -0.1373,  1.6380],\n",
      "        [-0.6400,  1.5745,  0.7397],\n",
      "        [ 0.2782,  0.2755,  1.5337],\n",
      "        [ 1.9979,  1.1448, -1.6166],\n",
      "        [ 2.1371,  1.1289,  0.2085],\n",
      "        [ 1.5131, -1.2656,  0.3042],\n",
      "        [ 1.3462, -1.3447, -1.5174]])\n",
      "tensor([[-2.2924, -0.0746, -0.0553],\n",
      "        [-1.0052,  0.4631,  0.5428],\n",
      "        [ 0.2299, -0.1318, -0.0843],\n",
      "        [ 0.2445, -0.9494, -0.9642],\n",
      "        [ 1.3432,  0.3718,  0.4695],\n",
      "        [ 2.5719, -0.1269, -0.0530],\n",
      "        [-3.1571,  0.3835,  0.4263],\n",
      "        [-2.3441,  0.1332, -1.1242],\n",
      "        [-2.3610, -1.1553,  0.0698],\n",
      "        [-0.9341,  1.5488,  0.4354],\n",
      "        [-0.9495,  0.2700,  1.6174],\n",
      "        [ 3.3582,  0.3832,  0.4977],\n",
      "        [ 2.6429, -1.2048,  0.0938],\n",
      "        [ 2.6527,  0.0894, -1.1185]])\n",
      "tensor([8, 6, 6, 7, 6, 6, 1, 1, 1, 1, 1, 1, 1, 1, 1])\n",
      "tensor([6, 6, 6, 8, 8, 6, 1, 1, 1, 1, 1, 1, 1, 1])\n",
      "48\n",
      "49\n"
     ]
    }
   ],
   "source": [
    "for key in batch.r[0].keys:\r\n",
    "    for mol in batch.r:\r\n",
    "        print(mol[key])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "The expanded size of the tensor (30) must match the existing size (26) at non-singleton dimension 1.  Target sizes: [2, 30].  Tensor sizes: [2, 26]",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-19-2de43a0b0151>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      4\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mpad_sequence\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mprop\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_first\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpadding_value\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m \u001b[0mnew_batch\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m{\u001b[0m\u001b[0mdata_prop\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mbatch_mol_property\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mmol\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mdata_prop\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mmol\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mbatch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mr\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mdata_prop\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mbatch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mr\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-19-2de43a0b0151>\u001b[0m in \u001b[0;36m<dictcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m      4\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mpad_sequence\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mprop\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_first\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpadding_value\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m \u001b[0mnew_batch\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m{\u001b[0m\u001b[0mdata_prop\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mbatch_mol_property\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mmol\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mdata_prop\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mmol\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mbatch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mr\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mdata_prop\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mbatch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mr\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-19-2de43a0b0151>\u001b[0m in \u001b[0;36mbatch_mol_property\u001b[1;34m(prop)\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mbatch_mol_property\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mprop\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mpad_sequence\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mprop\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_first\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpadding_value\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[0mnew_batch\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m{\u001b[0m\u001b[0mdata_prop\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mbatch_mol_property\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mmol\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mdata_prop\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mmol\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mbatch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mr\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mdata_prop\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mbatch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mr\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\miniconda3\\envs\\3d-rdkit\\lib\\site-packages\\torch\\nn\\utils\\rnn.py\u001b[0m in \u001b[0;36mpad_sequence\u001b[1;34m(sequences, batch_first, padding_value)\u001b[0m\n\u001b[0;32m    370\u001b[0m         \u001b[1;31m# use index notation to prevent duplicate references to the tensor\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    371\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mbatch_first\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 372\u001b[1;33m             \u001b[0mout_tensor\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m:\u001b[0m\u001b[0mlength\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m...\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtensor\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    373\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    374\u001b[0m             \u001b[0mout_tensor\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mlength\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m...\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtensor\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: The expanded size of the tensor (30) must match the existing size (26) at non-singleton dimension 1.  Target sizes: [2, 30].  Tensor sizes: [2, 26]"
     ]
    }
   ],
   "source": [
    "from torch.nn.utils.rnn import pad_sequence\r\n",
    "\r\n",
    "def batch_mol_property(prop):\r\n",
    "    return pad_sequence(prop, batch_first = True, padding_value = 0)\r\n",
    "\r\n",
    "new_batch = {data_prop: batch_mol_property([mol[data_prop] for mol in batch.r]) for data_prop in batch.r[0].keys}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def collate_fn(rxn_batch):\r\n",
    "    rxn_batch = "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "OtherReactionTriple(edge_attr_p=[28, 4], edge_attr_r=[26, 4], edge_attr_ts=[28, 4], edge_index_p=[2, 28], edge_index_r=[2, 26], edge_index_ts=[2, 28], idx=[1], num_atoms=[1], p=Data(edge_attr=[28, 4], edge_index=[2, 28], idx=0, pos=[15, 3], x=[15, 11], z=[15]), pos_p=[15, 3], pos_r=[15, 3], pos_ts=[15, 3], r=Data(edge_attr=[26, 4], edge_index=[2, 26], idx=0, pos=[15, 3], x=[15, 11], z=[15]), ts=Data(edge_attr=[28, 4], edge_index=[2, 28], idx=0, pos=[15, 3], x=[15, 11], z=[15]), x_p=[15, 11], x_r=[15, 11], x_ts=[15, 11])"
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from torch.utils.data import DataLoader\r\n",
    "\r\n",
    "std_test_loader = DataLoader(rxns[0:10], batch_size = 2, collate_fn = collate_fn)\r\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "unsupported operand type(s) for +: 'NoneType' and 'int'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-4-36d867ab66ed>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# TODO: make batching proper\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mbatch\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miter\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtest_loader\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mr_batch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\miniconda3\\envs\\3d-rdkit\\lib\\site-packages\\torch\\utils\\data\\dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    515\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_sampler_iter\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    516\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 517\u001b[1;33m             \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    518\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    519\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mIterable\u001b[0m \u001b[1;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\miniconda3\\envs\\3d-rdkit\\lib\\site-packages\\torch\\utils\\data\\dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    555\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_next_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    556\u001b[0m         \u001b[0mindex\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_next_index\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# may raise StopIteration\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 557\u001b[1;33m         \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_dataset_fetcher\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfetch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# may raise StopIteration\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    558\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_pin_memory\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    559\u001b[0m             \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_utils\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\miniconda3\\envs\\3d-rdkit\\lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py\u001b[0m in \u001b[0;36mfetch\u001b[1;34m(self, possibly_batched_index)\u001b[0m\n\u001b[0;32m     45\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     46\u001b[0m             \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 47\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcollate_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\miniconda3\\envs\\3d-rdkit\\lib\\site-packages\\torch_geometric\\data\\dataloader.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m     34\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     35\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 36\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcollate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     37\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     38\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\miniconda3\\envs\\3d-rdkit\\lib\\site-packages\\torch_geometric\\data\\dataloader.py\u001b[0m in \u001b[0;36mcollate\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m     15\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0melem\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mData\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     16\u001b[0m             return Batch.from_data_list(batch, self.follow_batch,\n\u001b[1;32m---> 17\u001b[1;33m                                         self.exclude_keys)\n\u001b[0m\u001b[0;32m     18\u001b[0m         \u001b[1;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0melem\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     19\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mdefault_collate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\miniconda3\\envs\\3d-rdkit\\lib\\site-packages\\torch_geometric\\data\\batch.py\u001b[0m in \u001b[0;36mfrom_data_list\u001b[1;34m(cls, data_list, follow_batch, exclude_keys)\u001b[0m\n\u001b[0;32m    106\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mtuple\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    107\u001b[0m                     \u001b[0minc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 108\u001b[1;33m                 \u001b[0mcumsum\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minc\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mcumsum\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    109\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    110\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0mkey\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mfollow_batch\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: unsupported operand type(s) for +: 'NoneType' and 'int'"
     ]
    }
   ],
   "source": [
    "# TODO: make batching proper\r\n",
    "\r\n",
    "batch = next(iter(test_loader))\r\n",
    "print(batch.r_batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def collate_fn(rxn_batch):\r\n",
    "    # takes in batch as list of datapoints RT(r, ts, p) and returns collated batch as dict of pytorch tensors\r\n",
    "\r\n",
    "    \r\n",
    "    \r\n",
    "    \r\n",
    "    reactants = rxn_batch.r\r\n",
    "    #products = rxn_batch.p\r\n",
    "\r\n",
    "    # max num edges and nodes\r\n",
    "    max_num_edges = max([r.edge_attr.size(0) for r in reactants])\r\n",
    "    max_num_nodes = max([r.z.size(0) for r in reactants])\r\n",
    "\r\n",
    "    rxn_batch['atom_mask']\r\n",
    "\r\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch_geometric.data import Data\r\n",
    "\r\n",
    "class PairData(Data):\r\n",
    "    def __init__(self, edge_index_s, x_s, edge_index_t, x_t):\r\n",
    "        super(PairData, self).__init__()\r\n",
    "        self.edge_index_s = edge_index_s\r\n",
    "        self.x_s = x_s\r\n",
    "        self.edge_index_t = edge_index_t\r\n",
    "        self.x_t = x_t\r\n",
    "\r\n",
    "    def __inc__(self, key, value):\r\n",
    "        if key == 'edge_index_s':\r\n",
    "            return self.x_s.size(0)\r\n",
    "        if key == 'edge_index_t':\r\n",
    "            return self.x_t.size(0)\r\n",
    "        else:\r\n",
    "            return super().__inc__(key, value)\r\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch(edge_index_s=[2, 8], edge_index_t=[2, 6], x_s=[10, 16], x_s_batch=[10], x_t=[8, 16])\n",
      "tensor([[0, 0, 0, 0, 5, 5, 5, 5],\n",
      "        [1, 2, 3, 4, 6, 7, 8, 9]])\n"
     ]
    }
   ],
   "source": [
    "edge_index_s = torch.tensor([\r\n",
    "    [0, 0, 0, 0],\r\n",
    "    [1, 2, 3, 4],\r\n",
    "])\r\n",
    "x_s = torch.randn(5, 16)  # 5 nodes.\r\n",
    "edge_index_t = torch.tensor([\r\n",
    "    [0, 0, 0],\r\n",
    "    [1, 2, 3],\r\n",
    "])\r\n",
    "x_t = torch.randn(4, 16)  # 4 nodes.\r\n",
    "\r\n",
    "data = PairData(edge_index_s, x_s, edge_index_t, x_t)\r\n",
    "data_list = [data, data]\r\n",
    "loader = DataLoader(data_list, batch_size=2, follow_batch = ['x_s'])\r\n",
    "batch = next(iter(loader))\r\n",
    "\r\n",
    "print(batch)\r\n",
    "print(batch.edge_index_s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0, 1])\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x :  torch.Size([789, 11])\n",
      "edge_index :  torch.Size([2, 1550])\n",
      "edge_attr :  torch.Size([1550, 4])\n",
      "pos :  torch.Size([789, 3])\n",
      "z :  torch.Size([789])\n",
      "idx :  torch.Size([60])\n",
      "789 11\n"
     ]
    }
   ],
   "source": [
    "for key in test_loader.dataset.r_data.keys:\r\n",
    "    print(key, \": \", test_loader.dataset.r_data[key].shape)\r\n",
    "\r\n",
    "print(test_loader.dataset.r_data['x'].size(0), test_loader.dataset.r_data['x'].size(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "in_nf = test_loader.dataset.r_data['x'].size(1) # = out_nf?\r\n",
    "h_nf = 5\r\n",
    "emb_nf = 2 \r\n",
    "\r\n",
    "egnn_ae = EGNN_AE(h_nf = h_nf, emb_nf = emb_nf, num_node_fs = in_nf)\r\n",
    "opt = torch.optim.Adam(egnn_ae.parameters(), lr = 1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_egnn_ae(gae, opt):\r\n",
    "    \r\n",
    "    # lr_scheduler.step()\r\n",
    "\r\n",
    "    # simple results dict for now\r\n",
    "    res = {'loss': 0, 'counter': 0, 'loss_arr': []}\r\n",
    "\r\n",
    "    for i, rxn_batch in enumerate(test_loader):\r\n",
    "        \r\n",
    "        gae.train()\r\n",
    "        opt.zero_grad()\r\n",
    "    \r\n",
    "        # from batch get data info: node_feats, edge_index, edge_attr\r\n",
    "        # pass into model and get out ... adj?\r\n",
    "\r\n",
    "        # calc loss\r\n",
    "        loss = 0 # = bce(adj_pred, adj_gt)\r\n",
    "        loss.backward() \r\n",
    "        opt.step()\r\n",
    "\r\n",
    "        # add results to experiment dataclass: loss, epoch,  batch_size\r\n",
    "        # temp: use dict\r\n",
    "        res['loss'] += loss.item() * batch\r\n",
    "    \r\n",
    "    # return final loss i.e. return experimentlog final loss\r\n",
    "    pass\r\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_gae(gae, opt, x, train_pos_edge_index):\r\n",
    "    gae.train()\r\n",
    "    opt.zero_grad()\r\n",
    "    print(\"train x shape: \", x.shape)\r\n",
    "    z = gae.encode(x, train_pos_edge_index)\r\n",
    "    print(\"train z shape: \", z.shape)\r\n",
    "    loss = gae.recon_loss(z, train_pos_edge_index)\r\n",
    "    loss.backward()\r\n",
    "    opt.step()\r\n",
    "    return float(loss)\r\n",
    "\r\n",
    "def test_gae(gae, x, train_pos_edge_index, test_pos_edge_index, test_neg_edge_index):\r\n",
    "    gae.eval()\r\n",
    "    with torch.no_grad():\r\n",
    "        z = gae.encode(x, train_pos_edge_index)\r\n",
    "    return gae.test(z, test_pos_edge_index, test_neg_edge_index)\r\n",
    "\r\n",
    "def new_test_gae(gae, x, edge_index):\r\n",
    "    # this just does recon loss again\r\n",
    "    gae.eval()\r\n",
    "    with torch.no_grad():\r\n",
    "        print(\"test x shape: \", x.shape)\r\n",
    "        z = gae.encode(x, edge_index)\r\n",
    "        print(\"test z shape: \", z.shape)\r\n",
    "    return gae.recon_loss(z, edge_index)\r\n",
    "\r\n",
    "r_ae.reset_parameters()\r\n",
    "\r\n",
    "epochs = 10\r\n",
    "for epoch in range(1, epochs + 1):\r\n",
    "\r\n",
    "    # value = (z[edge_index[0]] * z[edge_index[1]]).sum(dim = 1)\r\n",
    "    loss_train = train_gae(r_ae, r_opt, r_x, r_data.edge_index)\r\n",
    "    print(\"===== Training complete with loss: {:.4f}, now testing ====\".format(loss_train))\r\n",
    "    loss_test = new_test_gae(r_ae, test_x, test_data.edge_index)\r\n",
    "    if epoch % 1 == 0:\r\n",
    "        print('===== Epoch: {:03d}, Loss: {:.4f} ===== \\n'.format(epoch, loss_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch(num_atoms=[3], p=[3], p_batch=[3], r=[3], r_batch=[3], ts=[3])\n",
      "Batch(num_atoms=[3], p=[3], p_batch=[3], r=[3], r_batch=[3], ts=[3])\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_loader.dataset.data.r\r\n",
    "\r\n",
    "baseline_losses = []\r\n",
    "epoch_losses = []\r\n",
    "\r\n",
    "\r\n",
    "# for ep in range(2):\r\n",
    "for batch_id, rxn_batch in enumerate(test_loader):\r\n",
    "    reactants = rxn_batch.r\r\n",
    "    \r\n",
    "\r\n",
    "\r\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.6.13 64-bit (conda)",
   "name": "3d-rdkit"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  },
  "orig_nbformat": 2
 },
 "nbformat": 4,
 "nbformat_minor": 2
}