{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Go over notes and build up from simpler models\r\n",
    "\r\n",
    "1. R AE \r\n",
    "2. R-P AE \r\n",
    "3. R encoder and TS decoder \r\n",
    "4. R-P encoder, TS decoder\r\n",
    "\r\n",
    "TODO:\r\n",
    "- Have an visualise function where you can plot embeddings e.g. umap, pca, tsne and interpolate between rs and ps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\r\n",
    "import torch.nn as nn\r\n",
    "from torch_geometric.nn import GCNConv, GAE\r\n",
    "from torch_geometric.utils import train_test_split_edges\r\n",
    "from ts_vae.data_processors.grambow_processor import ReactionDataset, ConcatReactionDataset, Temp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Molecule Autoencoder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reset(nn):\r\n",
    "    def _reset(item):\r\n",
    "        if hasattr(item, 'reset_parameters'):\r\n",
    "            item.reset_parameters()\r\n",
    "\r\n",
    "    if nn is not None:\r\n",
    "        if hasattr(nn, 'children') and len(list(nn.children())) > 0:\r\n",
    "            for item in nn.children():\r\n",
    "                _reset(item)\r\n",
    "        else:\r\n",
    "            _reset(nn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_auc_score, average_precision_score\r\n",
    "from torch_geometric.utils import (negative_sampling, remove_self_loops, add_self_loops)\r\n",
    "EPS = 1e-15\r\n",
    "\r\n",
    "class GAE(nn.Module):\r\n",
    "    def __init__(self, encoder, decoder = None):\r\n",
    "        super(GAE, self).__init__()\r\n",
    "        self.encoder = encoder\r\n",
    "        self.decoder = InnerProductDecoder()\r\n",
    "        GAE.reset_parameters(self)\r\n",
    "\r\n",
    "    def reset_parameters(self):\r\n",
    "        reset(self.encoder)\r\n",
    "        reset(self.decoder) \r\n",
    "\r\n",
    "    def encode(self, *args, **kwargs):\r\n",
    "        return self.encoder(*args, **kwargs)\r\n",
    "\r\n",
    "    def decode(self, *args, **kwargs):\r\n",
    "        return self.decoder(*args, **kwargs)\r\n",
    "\r\n",
    "    def recon_loss(self, z, pos_edge_index, neg_edge_index = None):\r\n",
    "        \"\"\" BCE for input on its reconstruction. \"\"\"\r\n",
    "        pos_loss = -torch.log(self.decoder(z, pos_edge_index, sigmoid = True) + EPS).mean()\r\n",
    "\r\n",
    "        # no self-loops in negative samples\r\n",
    "        pos_edge_index, _ = remove_self_loops(pos_edge_index)\r\n",
    "        pos_edge_index, _ = add_self_loops(pos_edge_index)\r\n",
    "        if neg_edge_index is None:\r\n",
    "            neg_edge_index = negative_sampling(pos_edge_index, z.size(0))\r\n",
    "        neg_loss = -torch.log(1 - self.decoder(z, neg_edge_index, sigmoid = True) + EPS).mean()\r\n",
    "\r\n",
    "        return pos_loss + neg_loss\r\n",
    "\r\n",
    "    def test(self, z, pos_edge_index, neg_edge_index):\r\n",
    "        pos_y = z.new_ones(pos_edge_index.size(1))\r\n",
    "        neg_y = z.new_zeros(neg_edge_index.size(1))\r\n",
    "        y = torch.cat([pos_y, neg_y], dim=0)\r\n",
    "\r\n",
    "        pos_pred = self.decoder(z, pos_edge_index, sigmoid=True)\r\n",
    "        neg_pred = self.decoder(z, neg_edge_index, sigmoid=True)\r\n",
    "        pred = torch.cat([pos_pred, neg_pred], dim=0)\r\n",
    "\r\n",
    "        y, pred = y.detach().cpu().numpy(), pred.detach().cpu().numpy()\r\n",
    "\r\n",
    "        return roc_auc_score(y, pred), average_precision_score(y, pred)\r\n",
    "\r\n",
    "class MolEncoder(nn.Module):\r\n",
    "    def __init__(self, in_channels, out_channels):\r\n",
    "        super(MolEncoder, self).__init__()\r\n",
    "        self.conv = GCNConv(in_channels, out_channels)\r\n",
    "\r\n",
    "    def forward(self, x, edge_index):\r\n",
    "        return self.conv(x, edge_index)\r\n",
    "\r\n",
    "class InnerProductDecoder(nn.Module):\r\n",
    "    def forward(self, z, edge_index, sigmoid = True):\r\n",
    "        value = (z[edge_index[0]] * z[edge_index[1]]).sum(dim = 1)\r\n",
    "        return torch.sigmoid(value) if sigmoid else value\r\n",
    "    \r\n",
    "    def forward_all(self, z, sigmoid = True):\r\n",
    "        adj = torch.matmul(z, z.t())\r\n",
    "        return torch.sigmoid(adj) if sigmoid else adj\r\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_gae(gae, opt, x, train_pos_edge_index):\r\n",
    "    gae.train()\r\n",
    "    opt.zero_grad()\r\n",
    "    z = gae.encode(x, train_pos_edge_index)\r\n",
    "    loss = gae.recon_loss(z, train_pos_edge_index)\r\n",
    "    loss.backward()\r\n",
    "    opt.step()\r\n",
    "    return float(loss)\r\n",
    "\r\n",
    "def test_gae(gae, x, train_pos_edge_index, test_pos_edge_index, test_neg_edge_index):\r\n",
    "    gae.eval()\r\n",
    "    with torch.no_grad():\r\n",
    "        z = gae.encode(x, train_pos_edge_index)\r\n",
    "    return gae.test(z, test_pos_edge_index, test_neg_edge_index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reactant Autoencoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model data\r\n",
    "base_path = r'data/'\r\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\r\n",
    "val_ratio = 0\r\n",
    "test_ratio = 0.2\r\n",
    "\r\n",
    "# reactant data\r\n",
    "r_dataset = ReactionDataset(base_path, geo_file = 'train_r') \r\n",
    "r_data = r_dataset.data\r\n",
    "r_data.train_mask = r_data.val_mask = r_data.test_mask = r_data.y = None\r\n",
    "r_data = train_test_split_edges(data = r_data, val_ratio = val_ratio, test_ratio = test_ratio)\r\n",
    "r_x = r_data.x.to(device)\r\n",
    "r_train_pos_edge_index = r_data.train_pos_edge_index.to(device)\r\n",
    "\r\n",
    "# reactant encoder\r\n",
    "r_num_node_fs = r_data.num_node_features\r\n",
    "r_latent_dim = 2\r\n",
    "r_ae = GAE(MolEncoder(r_num_node_fs, r_latent_dim))\r\n",
    "r_opt = torch.optim.Adam(r_ae.parameters(), lr = 0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 010, AUC: 0.8173, AP: 0.6778\n",
      "Epoch: 020, AUC: 0.8166, AP: 0.6770\n",
      "Epoch: 030, AUC: 0.8162, AP: 0.6764\n",
      "Epoch: 040, AUC: 0.7617, AP: 0.6447\n",
      "Epoch: 050, AUC: 0.6425, AP: 0.5646\n",
      "Epoch: 060, AUC: 0.5798, AP: 0.5157\n",
      "Epoch: 070, AUC: 0.5806, AP: 0.5166\n",
      "Epoch: 080, AUC: 0.5808, AP: 0.5169\n",
      "Epoch: 090, AUC: 0.6277, AP: 0.5545\n",
      "Epoch: 100, AUC: 0.6814, AP: 0.5949\n"
     ]
    }
   ],
   "source": [
    "r_ae.reset_parameters()\r\n",
    "\r\n",
    "epochs = 100\r\n",
    "for epoch in range(1, epochs + 1):\r\n",
    "    loss = train_gae(r_ae, r_opt, r_x, r_data.train_pos_edge_index)\r\n",
    "    auc, ap = test_gae(r_ae, r_x, r_data.train_pos_edge_index, r_data.test_pos_edge_index, r_data.test_neg_edge_index)\r\n",
    "    if epoch % 10 == 0:\r\n",
    "        print('Epoch: {:03d}, AUC: {:.4f}, AP: {:.4f}'.format(epoch, auc, ap))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Product Autoencoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model data\r\n",
    "base_path = r'data/'\r\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\r\n",
    "val_ratio = 0\r\n",
    "test_ratio = 0.2\r\n",
    "\r\n",
    "# product data\r\n",
    "p_dataset = ReactionDataset(base_path, geo_file = 'train_p') \r\n",
    "p_data = p_dataset.data\r\n",
    "p_data.train_mask = p_data.val_mask = p_data.test_mask = p_data.y = None\r\n",
    "p_data = train_test_split_edges(data = p_data, val_ratio = val_ratio, test_ratio = test_ratio)\r\n",
    "p_x = p_data.x.to(device)\r\n",
    "p_train_pos_edge_index = p_data.train_pos_edge_index.to(device)\r\n",
    "\r\n",
    "# product encoder\r\n",
    "p_num_node_fs = p_data.num_node_features\r\n",
    "p_latent_dim = 2\r\n",
    "p_ae = GAE(MolEncoder(p_num_node_fs, p_latent_dim))\r\n",
    "p_opt = torch.optim.Adam(p_ae.parameters(), lr = 0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 010, AUC: 0.7871, AP: 0.6643\n",
      "Epoch: 020, AUC: 0.7860, AP: 0.6698\n",
      "Epoch: 030, AUC: 0.7876, AP: 0.6959\n",
      "Epoch: 040, AUC: 0.8174, AP: 0.7411\n",
      "Epoch: 050, AUC: 0.8711, AP: 0.7817\n",
      "Epoch: 060, AUC: 0.8898, AP: 0.7884\n",
      "Epoch: 070, AUC: 0.8851, AP: 0.7721\n",
      "Epoch: 080, AUC: 0.8831, AP: 0.7654\n",
      "Epoch: 090, AUC: 0.8754, AP: 0.7582\n",
      "Epoch: 100, AUC: 0.8780, AP: 0.7616\n"
     ]
    }
   ],
   "source": [
    "p_ae.reset_parameters()\r\n",
    "\r\n",
    "epochs = 100\r\n",
    "for epoch in range(1, epochs + 1):\r\n",
    "    loss = train_gae(p_ae, p_opt, p_x, p_data.train_pos_edge_index)\r\n",
    "    auc, ap = test_gae(p_ae, p_x, p_data.train_pos_edge_index, p_data.test_pos_edge_index, p_data.test_neg_edge_index)\r\n",
    "    if epoch % 10 == 0:\r\n",
    "        print('Epoch: {:03d}, AUC: {:.4f}, AP: {:.4f}'.format(epoch, auc, ap))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Same AE architecture but with reactant and product data concatenated"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hacky way\r\n",
    "Create train_rp_50.sdf file with first 50 reactants and products.\r\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model data\r\n",
    "base_path = r'data/'\r\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\r\n",
    "val_ratio = 0\r\n",
    "test_ratio = 0.2 # 50 reactants and 50 products. will end up training on 50 reactants + 30 products and testing on 20 products\r\n",
    "\r\n",
    "# rp data\r\n",
    "rp_dataset = ReactionDataset(base_path, geo_file = 'train_rp_50')\r\n",
    "rp_data = rp_dataset.data\r\n",
    "rp_data.train_mask = rp_data.val_mask = rp_data.test_mask = rp_data.y = None\r\n",
    "rp_data = train_test_split_edges(data = rp_data, val_ratio = val_ratio, test_ratio = test_ratio)\r\n",
    "rp_x = rp_data.x.to(device)\r\n",
    "rp_train_pos_edge_index = rp_data.train_pos_edge_index.to(device)\r\n",
    "\r\n",
    "# rp autoencoder\r\n",
    "rp_num_node_fs = rp_data.num_node_features\r\n",
    "rp_latent_dim = 2\r\n",
    "rp_ae = GAE(MolEncoder(rp_num_node_fs, rp_latent_dim))\r\n",
    "rp_opt = torch.optim.Adam(rp_ae.parameters(), lr = 0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 010, AUC: 0.6097, AP: 0.5554\n",
      "Epoch: 020, AUC: 0.3769, AP: 0.4165\n",
      "Epoch: 030, AUC: 0.5066, AP: 0.4703\n",
      "Epoch: 040, AUC: 0.6515, AP: 0.5624\n",
      "Epoch: 050, AUC: 0.7327, AP: 0.6283\n",
      "Epoch: 060, AUC: 0.8057, AP: 0.6766\n",
      "Epoch: 070, AUC: 0.8086, AP: 0.6799\n",
      "Epoch: 080, AUC: 0.8160, AP: 0.6874\n",
      "Epoch: 090, AUC: 0.8062, AP: 0.6833\n",
      "Epoch: 100, AUC: 0.8261, AP: 0.6953\n"
     ]
    }
   ],
   "source": [
    "rp_ae.reset_parameters()\r\n",
    "\r\n",
    "epochs = 100\r\n",
    "for epoch in range(1, epochs + 1):\r\n",
    "    loss = train_gae(rp_ae, rp_opt, rp_x, rp_data.train_pos_edge_index)\r\n",
    "    auc, ap = test_gae(rp_ae, rp_x, rp_data.train_pos_edge_index, rp_data.test_pos_edge_index, rp_data.test_neg_edge_index)\r\n",
    "    if epoch % 10 == 0:\r\n",
    "        print('Epoch: {:03d}, AUC: {:.4f}, AP: {:.4f}'.format(epoch, auc, ap))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create ConcatReactionDataset\r\n",
    "\r\n",
    "i.e. not hacky, create a concatenated dataset at source.\r\n",
    "\r\n",
    "Key words for network: dual, double, siamese, twin networks.\r\n",
    "- Siamese/twin: same weights while working in tandem on two different input vectors to compute comparable output vectors.\r\n",
    "\r\n",
    "Key words for training: simultaneous training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model data\r\n",
    "base_path = r'data/'\r\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\r\n",
    "val_ratio = 0\r\n",
    "test_ratio = 0.2\r\n",
    "\r\n",
    "# concat rp data\r\n",
    "concat_rp_dataset = ConcatReactionDataset(base_path)\r\n",
    "concat_rp_data = concat_rp_dataset.data\r\n",
    "concat_rp_data.train_mask = concat_rp_data.val_mask = concat_rp_data.test_mask = concat_rp_data.y = None\r\n",
    "concat_rp_data = train_test_split_edges(data = concat_rp_data, val_ratio = val_ratio, test_ratio = test_ratio)\r\n",
    "concat_rp_x = concat_rp_data.x.to(device)\r\n",
    "concat_rp_train_pos_edge_index = concat_rp_data.train_pos_edge_index.to(device)\r\n",
    "\r\n",
    "# concat rp encoder\r\n",
    "concat_rp_num_node_fs = concat_rp_data.num_node_features\r\n",
    "concat_rp_latent_dim = 2\r\n",
    "concat_rp_ae = GAE(MolEncoder(concat_rp_num_node_fs, concat_rp_latent_dim))\r\n",
    "concat_rp_opt = torch.optim.Adam(concat_rp_ae.parameters(), lr = 0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 010, AUC: 0.7733, AP: 0.6341\n",
      "Epoch: 020, AUC: 0.6032, AP: 0.5291\n",
      "Epoch: 030, AUC: 0.4524, AP: 0.4456\n",
      "Epoch: 040, AUC: 0.4638, AP: 0.4493\n",
      "Epoch: 050, AUC: 0.5354, AP: 0.4963\n",
      "Epoch: 060, AUC: 0.6539, AP: 0.5780\n",
      "Epoch: 070, AUC: 0.7542, AP: 0.6320\n",
      "Epoch: 080, AUC: 0.7680, AP: 0.6445\n",
      "Epoch: 090, AUC: 0.7813, AP: 0.6524\n",
      "Epoch: 100, AUC: 0.7971, AP: 0.6696\n"
     ]
    }
   ],
   "source": [
    "concat_rp_ae.reset_parameters()\r\n",
    "\r\n",
    "epochs = 100\r\n",
    "for epoch in range(1, epochs + 1):\r\n",
    "    loss = train_gae(concat_rp_ae, concat_rp_opt, concat_rp_x, concat_rp_data.train_pos_edge_index)\r\n",
    "    auc, ap = test_gae(concat_rp_ae, concat_rp_x, concat_rp_data.train_pos_edge_index, concat_rp_data.test_pos_edge_index, concat_rp_data.test_neg_edge_index)\r\n",
    "    if epoch % 10 == 0:\r\n",
    "        print('Epoch: {:03d}, AUC: {:.4f}, AP: {:.4f}'.format(epoch, auc, ap))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rp data\r\n",
    "rp_dataset = ReactionDataset(base_path, geo_file = 'train_rp_50')\r\n",
    "rp_data = rp_dataset.data\r\n",
    "rp_data.train_mask = rp_data.val_mask = rp_data.test_mask = rp_data.y = None\r\n",
    "rp_data = train_test_split_edges(data = rp_data, val_ratio = val_ratio, test_ratio = test_ratio)\r\n",
    "rp_x = rp_data.x.to(device)\r\n",
    "rp_train_pos_edge_index = rp_data.train_pos_edge_index.to(device)\r\n",
    "\r\n",
    "# rp autoencoder\r\n",
    "rp_num_node_fs = rp_data.num_node_features\r\n",
    "rp_latent_dim = 2\r\n",
    "rp_ae = GAE(MolEncoder(rp_num_node_fs, rp_latent_dim))\r\n",
    "rp_opt = torch.optim.Adam(rp_ae.parameters(), lr = 0.01)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reactant-Product Autoencoder\r\n",
    "\r\n",
    "Train reactant and product autoencoders simultaneously and decode to either (i) $z_{RP}$ or (ii) $(z_R, z_P)$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### One GAE on (R, P) tuple $\\rightarrow z_{RP} \\rightarrow$ reactant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "EPS = 1e-15\r\n",
    "\r\n",
    "class DualGAE(nn.Module):\r\n",
    "    \r\n",
    "    def __init__(self, r_encoder, p_encoder, decoder = None):\r\n",
    "        super(DualGAE, self).__init__()\r\n",
    "        self.r_encoder = r_encoder\r\n",
    "        self.p_encoder = p_encoder\r\n",
    "        self.decoder = InnerProductDecoder() if decoder is None else decoder\r\n",
    "        DualGAE.reset_parameters(self)\r\n",
    "    \r\n",
    "    def reset_parameters(self):\r\n",
    "        reset(self.r_encoder)\r\n",
    "        reset(self.p_encoder)\r\n",
    "        reset(self.decoder)\r\n",
    "    \r\n",
    "    def encode(self, r_x, p_x, r_train_pos_edge_index, p_train_pos_edge_index):\r\n",
    "        z_r = self.r_encoder(r_x, r_train_pos_edge_index)\r\n",
    "        z_p = self.p_encoder(p_x, p_train_pos_edge_index)\r\n",
    "        return self.combine_r_and_p(z_r, z_p)\r\n",
    "\r\n",
    "    def combine_r_and_p(self, r, p):\r\n",
    "        return r + p\r\n",
    "    \r\n",
    "    def decode(self, *args, **kwargs):\r\n",
    "        return self.decoder(*args, **kwargs)\r\n",
    "\r\n",
    "    def recon_loss(self, z, pos_edge_index, neg_edge_index = None):\r\n",
    "        \"\"\" BCE for input on its reconstruction. \r\n",
    "            TODO: recon both as a tuple?\r\n",
    "        \"\"\"\r\n",
    "        pos_loss = - torch.log(self.decoder(z, pos_edge_index, sigmoid = True) + EPS).mean()\r\n",
    "\r\n",
    "        # no self-loops in negative samples\r\n",
    "        pos_edge_index, _ = remove_self_loops(pos_edge_index)\r\n",
    "        pos_edge_index, _ = add_self_loops(pos_edge_index)\r\n",
    "        if neg_edge_index is None:\r\n",
    "            neg_edge_index = negative_sampling(pos_edge_index, z.size(0))\r\n",
    "        neg_loss = -torch.log(1 - self.decoder(z, neg_edge_index, sigmoid = True) + EPS).mean()\r\n",
    "\r\n",
    "        return pos_loss + neg_loss\r\n",
    "\r\n",
    "    def test(self, z, pos_edge_index, neg_edge_index):\r\n",
    "        pos_y = z.new_ones(pos_edge_index.size(1))\r\n",
    "        neg_y = z.new_zeros(neg_edge_index.size(1))\r\n",
    "        y = torch.cat([pos_y, neg_y], dim=0)\r\n",
    "\r\n",
    "        pos_pred = self.decoder(z, pos_edge_index, sigmoid=True)\r\n",
    "        neg_pred = self.decoder(z, neg_edge_index, sigmoid=True)\r\n",
    "        pred = torch.cat([pos_pred, neg_pred], dim=0)\r\n",
    "\r\n",
    "        y, pred = y.detach().cpu().numpy(), pred.detach().cpu().numpy()\r\n",
    "\r\n",
    "        return roc_auc_score(y, pred), average_precision_score(y, pred)\r\n",
    "\r\n",
    "class MolEncoder(nn.Module):\r\n",
    "    def __init__(self, in_channels, out_channels):\r\n",
    "        super(MolEncoder, self).__init__()\r\n",
    "        self.conv = GCNConv(in_channels, out_channels)\r\n",
    "\r\n",
    "    def forward(self, x, edge_index):\r\n",
    "        z = self.conv(x, edge_index)\r\n",
    "        return z\r\n",
    "\r\n",
    "class InnerProductDecoder(nn.Module):\r\n",
    "    def forward(self, z, edge_index, sigmoid = True):\r\n",
    "        value = (z[edge_index[0]] * z[edge_index[1]]).sum(dim = 1)\r\n",
    "        return torch.sigmoid(value) if sigmoid else value\r\n",
    "    \r\n",
    "    def forward_all(self, z, sigmoid = True):\r\n",
    "        adj = torch.matmul(z, z.t())\r\n",
    "        return torch.sigmoid(adj) if sigmoid else adj\r\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model data\r\n",
    "base_path = r'data/'\r\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\r\n",
    "val_ratio = 0\r\n",
    "test_ratio = 0.2\r\n",
    "\r\n",
    "# reactant dataset\r\n",
    "r_dataset = ReactionDataset(base_path, geo_file = 'train_r')\r\n",
    "r_data = r_dataset.data\r\n",
    "r_data.train_mask = r_data.val_mask = r_data.test_mask = r_data.y = None\r\n",
    "r_data = train_test_split_edges(data = r_data, val_ratio = val_ratio, test_ratio = test_ratio)\r\n",
    "r_x = r_data.x.to(device)\r\n",
    "r_train_pos_edge_index = r_data.train_pos_edge_index.to(device)\r\n",
    "\r\n",
    "# product dataset\r\n",
    "p_dataset = ReactionDataset(base_path, geo_file = 'train_p')  \r\n",
    "p_data = p_dataset.data\r\n",
    "p_data.train_mask = p_data.val_mask = p_data.test_mask = p_data.y = None\r\n",
    "p_data = train_test_split_edges(data = p_data, val_ratio = val_ratio, test_ratio = test_ratio)\r\n",
    "p_x = p_data.x.to(device)\r\n",
    "p_train_pos_edge_index = p_data.train_pos_edge_index.to(device)\r\n",
    "\r\n",
    "# dual gae\r\n",
    "dgae = DualGAE(r_encoder = MolEncoder(p_data.num_node_features, 2), p_encoder = MolEncoder(p_data.num_node_features, 2))\r\n",
    "dgae_opt = torch.optim.Adam(dgae.parameters(), lr = 0.01) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_dgae(dgae, opt, r_x, p_x, r_train_pos_edge_index, p_train_pos_edge_index):\r\n",
    "    dgae.train()\r\n",
    "    opt.zero_grad()\r\n",
    "    z_rp = dgae.encode(r_x, p_x, r_train_pos_edge_index, p_train_pos_edge_index)\r\n",
    "    loss = dgae.recon_loss(z_rp, r_train_pos_edge_index)\r\n",
    "    loss.backward()\r\n",
    "    opt.step()\r\n",
    "    return float(loss)\r\n",
    "\r\n",
    "# the test indices here will be for reactant\r\n",
    "def test_dgae(dgae, r_x, p_x, r_train_pos_edge_index, p_train_pos_edge_index, test_pos_edge_index, test_neg_edge_index):\r\n",
    "    dgae.eval()\r\n",
    "    with torch.no_grad():\r\n",
    "        z_rp = dgae.encoder(r_x, p_x, r_train_pos_edge_index, p_train_pos_edge_index)\r\n",
    "    return dgae.test(z_rp, test_pos_edge_index, test_neg_edge_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'remove_self_loops' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-18-e62ea6f59497>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mepochs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m100\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepochs\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m     \u001b[0mloss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain_dgae\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdgae\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdgae_opt\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mr_x\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mp_x\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mr_train_pos_edge_index\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mp_train_pos_edge_index\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m     \u001b[0mauc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0map\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtest_gae\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdgae\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mr_x\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mp_x\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mr_train_pos_edge_index\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mp_train_pos_edge_index\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mr_data\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtest_pos_edge_index\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mr_data\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtest_neg_edge_index\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mepoch\u001b[0m \u001b[1;33m%\u001b[0m \u001b[1;36m10\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-17-d7360a8d4e63>\u001b[0m in \u001b[0;36mtrain_dgae\u001b[1;34m(dgae, opt, r_x, p_x, r_train_pos_edge_index, p_train_pos_edge_index)\u001b[0m\n\u001b[0;32m      3\u001b[0m     \u001b[0mopt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m     \u001b[0mz_rp\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdgae\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mencode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mr_x\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mp_x\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mr_train_pos_edge_index\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mp_train_pos_edge_index\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m     \u001b[0mloss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdgae\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrecon_loss\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mz_rp\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mr_train_pos_edge_index\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m     \u001b[0mloss\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m     \u001b[0mopt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-12-190307a2feee>\u001b[0m in \u001b[0;36mrecon_loss\u001b[1;34m(self, z, pos_edge_index, neg_edge_index)\u001b[0m\n\u001b[0;32m     33\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     34\u001b[0m         \u001b[1;31m# no self-loops in negative samples\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 35\u001b[1;33m         \u001b[0mpos_edge_index\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mremove_self_loops\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpos_edge_index\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     36\u001b[0m         \u001b[0mpos_edge_index\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0madd_self_loops\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpos_edge_index\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     37\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mneg_edge_index\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'remove_self_loops' is not defined"
     ]
    }
   ],
   "source": [
    "dgae.reset_parameters()\r\n",
    "\r\n",
    "epochs = 100\r\n",
    "for epoch in range(1, epochs + 1):\r\n",
    "    loss = train_dgae(dgae, dgae_opt, r_x, p_x, r_train_pos_edge_index, p_train_pos_edge_index)\r\n",
    "    auc, ap = test_gae(dgae, r_x, p_x, r_train_pos_edge_index, p_train_pos_edge_index, r_data.test_pos_edge_index, r_data.test_neg_edge_index)\r\n",
    "    if epoch % 10 == 0:\r\n",
    "        print('Epoch: {:03d}, AUC: {:.4f}, AP: {:.4f}'.format(epoch, auc, ap))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Combine R and P on latent space for corresponding features and then decode to R, say."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_auc_score, average_precision_score\r\n",
    "from torch_geometric.utils import (negative_sampling, remove_self_loops, add_self_loops)\r\n",
    "EPS = 1e-15\r\n",
    "\r\n",
    "class SameGAE(nn.Module):\r\n",
    "    # r and p in same encoder\r\n",
    "    # either train sequentially i.e. concat r and p data or train on tuples of (r[i], p[i])\r\n",
    "\r\n",
    "    def __init__(self, rp_encoder, decoder, type = \"concat\"):\r\n",
    "        super(SameGAE, self).__init__()\r\n",
    "        self.rp_encoder = rp_encoder\r\n",
    "        self.decoder = decoder\r\n",
    "        self.type = type # \"concat\" or \"tuple\"\r\n",
    "        SameGAE.reset_parameters(self)\r\n",
    "    \r\n",
    "    def reset_parameters(self):\r\n",
    "        reset(self.rp_encoder)\r\n",
    "        reset(self.decoder)\r\n",
    "        reset(self.type)\r\n",
    "    \r\n",
    "    def encode(self, *args, **kwargs):\r\n",
    "        return self.rp_encoder(*args, **kwargs)\r\n",
    "    \r\n",
    "    def decode(self, *args, **kwargs):\r\n",
    "        return self.decoder(*args, **kwargs)\r\n",
    "    \r\n",
    "    def recon_loss(self, z, pos_edge_index, neg_edge_index = None):\r\n",
    "        pos_loss = - torch.log(self.decoder(z, pos_edge_index, sigmoid = True) + EPS).mean()\r\n",
    "\r\n",
    "        # no self-loops in negative samples\r\n",
    "        pos_edge_index, _ = remove_self_loops(pos_edge_index)\r\n",
    "        pos_edge_index, _ = add_self_loops(pos_edge_index)\r\n",
    "        if neg_edge_index is None:\r\n",
    "            neg_edge_index = negative_sampling(pos_edge_index, z.size(0))\r\n",
    "        neg_loss = - torch.log(1 - self.decoder(z, neg_edge_index, sigmoid = True) + EPS).mean()\r\n",
    "\r\n",
    "        return pos_loss + neg_loss\r\n",
    "    \r\n",
    "    def test(self, z, pos_edge_index, neg_edge_index):\r\n",
    "        pos_y = z.new_ones(pos_edge_index.size(1))\r\n",
    "        neg_y = z.new_zeros(neg_edge_index.size(1))\r\n",
    "        y = torch.cat([pos_y, neg_y], dim=0)\r\n",
    "\r\n",
    "        pos_pred = self.decoder(z, pos_edge_index, sigmoid=True)\r\n",
    "        neg_pred = self.decoder(z, neg_edge_index, sigmoid=True)\r\n",
    "        pred = torch.cat([pos_pred, neg_pred], dim=0)\r\n",
    "\r\n",
    "        y, pred = y.detach().cpu().numpy(), pred.detach().cpu().numpy()\r\n",
    "\r\n",
    "        return roc_auc_score(y, pred), average_precision_score(y, pred)\r\n",
    "\r\n",
    "class MolEncoder(nn.Module):\r\n",
    "    def __init__(self, in_channels, out_channels):\r\n",
    "        super(MolEncoder, self).__init__()\r\n",
    "        self.conv = GCNConv(in_channels, out_channels)\r\n",
    "\r\n",
    "    def forward(self, x, edge_index):\r\n",
    "        return self.conv(x, edge_index)\r\n",
    "\r\n",
    "class InnerProductDecoder(nn.Module):\r\n",
    "    def forward(self, z, edge_index, sigmoid = True):\r\n",
    "        value = (z[edge_index[0]] * z[edge_index[1]]).sum(dim = 1)\r\n",
    "        return torch.sigmoid(value) if sigmoid else value\r\n",
    "    \r\n",
    "    def forward_all(self, z, sigmoid = True):\r\n",
    "        adj = torch.matmul(z, z.t())\r\n",
    "        return torch.sigmoid(adj) if sigmoid else adj"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train SameGAE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'p_ae' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-3-dc87af3b7fab>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     14\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mgae\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtest\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mz\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest_pos_edge_index\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest_neg_edge_index\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     15\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 16\u001b[1;33m \u001b[0mp_ae\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreset_parameters\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     17\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     18\u001b[0m \u001b[0mepochs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m100\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'p_ae' is not defined"
     ]
    }
   ],
   "source": [
    "def train_samegae(gae, opt, x, train_pos_edge_index):\r\n",
    "    gae.train()\r\n",
    "    opt.zero_grad()\r\n",
    "    z = gae.encode(x, train_pos_edge_index)\r\n",
    "    loss = gae.recon_loss(z, train_pos_edge_index)\r\n",
    "    loss.backward()\r\n",
    "    opt.step()\r\n",
    "    return float(loss)\r\n",
    "\r\n",
    "def test_samegae(gae, x, train_pos_edge_index, test_pos_edge_index, test_neg_edge_index):\r\n",
    "    gae.eval()\r\n",
    "    with torch.no_grad():\r\n",
    "        z = gae.encode(x, train_pos_edge_index)\r\n",
    "    return gae.test(z, test_pos_edge_index, test_neg_edge_index)\r\n",
    "\r\n",
    "p_ae.reset_parameters()\r\n",
    "\r\n",
    "epochs = 100\r\n",
    "for epoch in range(1, epochs + 1):\r\n",
    "    loss = train_gae(p_ae, p_opt, p_x, p_data.train_pos_edge_index)\r\n",
    "    auc, ap = test_gae(p_ae, p_x, p_data.train_pos_edge_index, p_data.test_pos_edge_index, p_data.test_neg_edge_index)\r\n",
    "    if epoch % 10 == 0:\r\n",
    "        print('Epoch: {:03d}, AUC: {:.4f}, AP: {:.4f}'.format(epoch, auc, ap))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'MolEncoder' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-5-56d3557801a4>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     16\u001b[0m \u001b[0mrp_num_node_fs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mrp_data\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnum_node_features\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     17\u001b[0m \u001b[0mrp_latent_dim\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 18\u001b[1;33m \u001b[0mrp_ae\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mGAE\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mMolEncoder\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrp_num_node_fs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrp_latent_dim\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     19\u001b[0m \u001b[0mrp_opt\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptim\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mAdam\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrp_ae\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0.01\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'MolEncoder' is not defined"
     ]
    }
   ],
   "source": [
    "# model data\r\n",
    "base_path = r'data/'\r\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\r\n",
    "val_ratio = 0\r\n",
    "test_ratio = 0.1 # 50 reactants and 50 products. will end up training on 50 reactants + 40 products and testing on 10 products\r\n",
    "\r\n",
    "# rp data\r\n",
    "rp_dataset = ReactionDataset(base_path, geo_file = 'train_rp_50')\r\n",
    "rp_data = rp_dataset.data\r\n",
    "rp_data.train_mask = rp_data.val_mask = rp_data.test_mask = rp_data.y = None\r\n",
    "rp_data = train_test_split_edges(data = rp_data, val_ratio = val_ratio, test_ratio = test_ratio)\r\n",
    "rp_x = rp_data.x.to(device)\r\n",
    "rp_train_pos_edge_index = rp_data.train_pos_edge_index.to(device)\r\n",
    "\r\n",
    "# rp autoencoder\r\n",
    "rp_num_node_fs = rp_data.num_node_features\r\n",
    "rp_latent_dim = 2\r\n",
    "rp_ae = GAE(MolEncoder(rp_num_node_fs, rp_latent_dim))\r\n",
    "rp_opt = torch.optim.Adam(rp_ae.parameters(), lr = 0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "dict_keys(['x', 'edge_index', 'edge_attr', 'y', 'pos', 'normal', 'face', 'z', 'idx'])"
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r_dataset.data.__dict__.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Sizes of tensors must match except in dimension 0. Got 2486 and 2504 in dimension 1 (The offending index is 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-85-71e67f1b9f80>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mdataset_param\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mr_dataset\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__dict__\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 10\u001b[1;33m     \u001b[0mrp_data_dict\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mdataset_param\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mr_dataset\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mdataset_param\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mp_dataset\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mdataset_param\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m: Sizes of tensors must match except in dimension 0. Got 2486 and 2504 in dimension 1 (The offending index is 1)"
     ]
    }
   ],
   "source": [
    "# ways of combining:\r\n",
    "#   - combine sdf files (need just first 100) and process that normally\r\n",
    "#   - manually once created datasets\r\n",
    "\r\n",
    "from torch_geometric.data.data import Data\r\n",
    "\r\n",
    "rp_data_dict = {}\r\n",
    "\r\n",
    "for dataset_param in r_dataset.data.__dict__.keys():\r\n",
    "    rp_data_dict[dataset_param] = torch.cat((r_dataset.data[dataset_param], p_dataset.data[dataset_param]))\r\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "tensor([[0, 0, 0,  ..., 7, 8, 9],\n        [7, 8, 9,  ..., 3, 3, 5]])"
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r_dataset.data['edge_index']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2486 2504\n"
     ]
    }
   ],
   "source": [
    "print(len(r_dataset.data.edge_attr), len(p_dataset.data.edge_attr)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x\n",
      "edge_index\n",
      "edge_attr\n",
      "y\n",
      "pos\n",
      "normal\n",
      "face\n",
      "z\n",
      "idx\n"
     ]
    }
   ],
   "source": [
    "for i in r_dataset.data.__dict__.keys():\r\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "tensor([[1., 0., 0., 0.],\n        [1., 0., 0., 0.],\n        [1., 0., 0., 0.],\n        ...,\n        [1., 0., 0., 0.],\n        [1., 0., 0., 0.],\n        [1., 0., 0., 0.]])"
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cat((r_dataset.data['edge_attr'], p_dataset.data['edge_attr']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model data\r\n",
    "base_path = r'data/'\r\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\r\n",
    "val_ratio = 0\r\n",
    "test_ratio = 0.2\r\n",
    "\r\n",
    "# reactant data\r\n",
    "r_dataset = ReactionDataset(base_path, geo_file = 'train_r') \r\n",
    "r_data = r_dataset.data\r\n",
    "r_data.train_mask = r_data.val_mask = r_data.test_mask = r_data.y = None\r\n",
    "r_data = train_test_split_edges(data = r_data, val_ratio = val_ratio, test_ratio = test_ratio)\r\n",
    "r_x = r_data.x.to(device)\r\n",
    "r_train_pos_edge_index = r_data.train_pos_edge_index.to(device)\r\n",
    "\r\n",
    "# product data\r\n",
    "p_dataset = ReactionDataset(base_path, geo_file = 'train_p') \r\n",
    "p_data = p_dataset.data\r\n",
    "p_data.train_mask = p_data.val_mask = p_data.test_mask = p_data.y = None\r\n",
    "p_data = train_test_split_edges(data = p_data, val_ratio = val_ratio, test_ratio = test_ratio)\r\n",
    "p_x = p_data.x.to(device)\r\n",
    "p_train_pos_edge_index = p_data.train_pos_edge_index.to(device)\r\n",
    "\r\n",
    "# product encoder\r\n",
    "p_num_node_fs = p_data.num_node_features\r\n",
    "p_latent_dim = 2\r\n",
    "p_ae = GAE(MolEncoder(p_num_node_fs, p_latent_dim))\r\n",
    "p_opt = torch.optim.Adam(p_ae.parameters(), lr = 0.01)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.6.13 64-bit (conda)",
   "name": "python3613jvsc74a57bd0f4671ad35fdc0609fa675edcd17de5b3092cb55d03f1d9670a78611a41fb18f3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  },
  "orig_nbformat": 2
 },
 "nbformat": 4,
 "nbformat_minor": 2
}