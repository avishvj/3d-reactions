{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Go over notes and build up from simpler models\r\n",
    "\r\n",
    "1. R AE \r\n",
    "2. R-P AE \r\n",
    "3. R encoder and TS decoder \r\n",
    "4. R-P encoder, TS decoder\r\n",
    "\r\n",
    "TODO:\r\n",
    "- Have an visualise function where you can plot embeddings e.g. umap, pca, tsne and interpolate between rs and ps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\r\n",
    "import torch.nn as nn\r\n",
    "from torch_geometric.nn import GCNConv, GAE\r\n",
    "from torch_geometric.utils import train_test_split_edges\r\n",
    "from ts_vae.data_processors.grambow_processor import ReactionDataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Molecule Autoencoder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reset(nn):\r\n",
    "    def _reset(item):\r\n",
    "        if hasattr(item, 'reset_parameters'):\r\n",
    "            item.reset_parameters()\r\n",
    "\r\n",
    "    if nn is not None:\r\n",
    "        if hasattr(nn, 'children') and len(list(nn.children())) > 0:\r\n",
    "            for item in nn.children():\r\n",
    "                _reset(item)\r\n",
    "        else:\r\n",
    "            _reset(nn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_auc_score, average_precision_score\r\n",
    "from torch_geometric.utils import (negative_sampling, remove_self_loops, add_self_loops)\r\n",
    "EPS = 1e-15\r\n",
    "\r\n",
    "class GAE(nn.Module):\r\n",
    "    \"\"\" Identical copy of the GAE given in PyTorch Geometric. \"\"\"\r\n",
    "\r\n",
    "    def __init__(self, encoder, decoder = None):\r\n",
    "        super(GAE, self).__init__()\r\n",
    "        self.encoder = encoder\r\n",
    "        self.decoder = InnerProductDecoder()\r\n",
    "        GAE.reset_parameters(self)\r\n",
    "\r\n",
    "    def reset_parameters(self):\r\n",
    "        reset(self.encoder)\r\n",
    "        reset(self.decoder) \r\n",
    "\r\n",
    "    def encode(self, *args, **kwargs):\r\n",
    "        return self.encoder(*args, **kwargs)\r\n",
    "\r\n",
    "    def decode(self, *args, **kwargs):\r\n",
    "        return self.decoder(*args, **kwargs)\r\n",
    "\r\n",
    "    def recon_loss(self, z, pos_edge_index, neg_edge_index = None):\r\n",
    "        \"\"\" BCE loss between input adj matrix and reconstructed adj matrix.\r\n",
    "        \"\"\"\r\n",
    "        pos_loss = - torch.log(self.decoder(z, pos_edge_index, sigmoid = True) + EPS).mean()\r\n",
    "\r\n",
    "        # no self-loops in negative samples -> not sure if mini-batch is stochastic but this is definitely the reason for variation\r\n",
    "        pos_edge_index, _ = remove_self_loops(pos_edge_index)\r\n",
    "        pos_edge_index, _ = add_self_loops(pos_edge_index)\r\n",
    "        if neg_edge_index is None:\r\n",
    "            neg_edge_index = negative_sampling(pos_edge_index, z.size(0))\r\n",
    "        neg_loss = -torch.log(1 - self.decoder(z, neg_edge_index, sigmoid = True) + EPS).mean()\r\n",
    "\r\n",
    "        return pos_loss + neg_loss\r\n",
    "\r\n",
    "    def test(self, z, pos_edge_index, neg_edge_index):\r\n",
    "        \"\"\" Take latent z and test_edge_indices, recreate adj matrix and compare to default.\r\n",
    "        \"\"\"\r\n",
    "\r\n",
    "        # create 1s of pos edges and 0s of neg edges, then concat\r\n",
    "        pos_y = z.new_ones(pos_edge_index.size(1))\r\n",
    "        neg_y = z.new_zeros(neg_edge_index.size(1))\r\n",
    "        y = torch.cat([pos_y, neg_y], dim=0)\r\n",
    "\r\n",
    "        # reconstruct pos edges and neg edges, then concat\r\n",
    "        pos_pred = self.decoder(z, pos_edge_index, sigmoid=True)\r\n",
    "        neg_pred = self.decoder(z, neg_edge_index, sigmoid=True)\r\n",
    "        pred = torch.cat([pos_pred, neg_pred], dim=0)\r\n",
    "\r\n",
    "        y, pred = y.detach().cpu().numpy(), pred.detach().cpu().numpy()\r\n",
    "\r\n",
    "        return roc_auc_score(y, pred), average_precision_score(y, pred)\r\n",
    "\r\n",
    "class MolEncoder(nn.Module):\r\n",
    "    def __init__(self, in_channels, out_channels):\r\n",
    "        super(MolEncoder, self).__init__()\r\n",
    "        self.conv = GCNConv(in_channels, out_channels)\r\n",
    "\r\n",
    "    def forward(self, x, edge_index):\r\n",
    "        z = self.conv(x, edge_index) \r\n",
    "        return z\r\n",
    "\r\n",
    "class InnerProductDecoder(nn.Module):\r\n",
    "    def forward(self, z, edge_index, sigmoid = True):\r\n",
    "        value = (z[edge_index[0]] * z[edge_index[1]]).sum(dim = 1)\r\n",
    "        return torch.sigmoid(value) if sigmoid else value\r\n",
    "    \r\n",
    "    def forward_all(self, z, sigmoid = True):\r\n",
    "        \"\"\" Decode latent variables into probabilistic adj matrix. \"\"\"\r\n",
    "        adj = torch.matmul(z, z.t())\r\n",
    "        return torch.sigmoid(adj) if sigmoid else adj\r\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_gae(gae, opt, x, train_pos_edge_index):\r\n",
    "    gae.train()\r\n",
    "    opt.zero_grad()\r\n",
    "    z = gae.encode(x, train_pos_edge_index)\r\n",
    "    loss = gae.recon_loss(z, train_pos_edge_index)\r\n",
    "    loss.backward()\r\n",
    "    opt.step()\r\n",
    "    return float(loss)\r\n",
    "\r\n",
    "def test_gae(gae, x, train_pos_edge_index, test_pos_edge_index, test_neg_edge_index):\r\n",
    "    gae.eval()\r\n",
    "    with torch.no_grad():\r\n",
    "        z = gae.encode(x, train_pos_edge_index)\r\n",
    "    return gae.test(z, test_pos_edge_index, test_neg_edge_index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reactant Autoencoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model data\r\n",
    "base_path = r'data/'\r\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\r\n",
    "val_ratio = 0\r\n",
    "test_ratio = 0.2\r\n",
    "\r\n",
    "# reactant data\r\n",
    "r_dataset = ReactionDataset(base_path, geo_file = 'train_r') \r\n",
    "r_data = r_dataset.data\r\n",
    "r_data.train_mask = r_data.val_mask = r_data.test_mask = r_data.y = None\r\n",
    "r_data = train_test_split_edges(data = r_data, val_ratio = val_ratio, test_ratio = test_ratio)\r\n",
    "r_x = r_data.x.to(device)\r\n",
    "r_train_pos_edge_index = r_data.train_pos_edge_index.to(device)\r\n",
    "\r\n",
    "# reactant encoder\r\n",
    "r_num_node_fs = r_data.num_node_features\r\n",
    "r_latent_dim = 2\r\n",
    "r_ae = GAE(MolEncoder(r_num_node_fs, r_latent_dim))\r\n",
    "r_opt = torch.optim.Adam(r_ae.parameters(), lr = 0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 010, AUC: 0.8173, AP: 0.6778\n",
      "Epoch: 020, AUC: 0.8166, AP: 0.6770\n",
      "Epoch: 030, AUC: 0.8162, AP: 0.6764\n",
      "Epoch: 040, AUC: 0.7617, AP: 0.6447\n",
      "Epoch: 050, AUC: 0.6425, AP: 0.5646\n",
      "Epoch: 060, AUC: 0.5798, AP: 0.5157\n",
      "Epoch: 070, AUC: 0.5806, AP: 0.5166\n",
      "Epoch: 080, AUC: 0.5808, AP: 0.5169\n",
      "Epoch: 090, AUC: 0.6277, AP: 0.5545\n",
      "Epoch: 100, AUC: 0.6814, AP: 0.5949\n"
     ]
    }
   ],
   "source": [
    "r_ae.reset_parameters()\r\n",
    "\r\n",
    "epochs = 100\r\n",
    "for epoch in range(1, epochs + 1):\r\n",
    "    loss = train_gae(r_ae, r_opt, r_x, r_data.train_pos_edge_index)\r\n",
    "    auc, ap = test_gae(r_ae, r_x, r_data.train_pos_edge_index, r_data.test_pos_edge_index, r_data.test_neg_edge_index)\r\n",
    "    if epoch % 10 == 0:\r\n",
    "        print('Epoch: {:03d}, AUC: {:.4f}, AP: {:.4f}'.format(epoch, auc, ap))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Product Autoencoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model data\r\n",
    "base_path = r'data/'\r\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\r\n",
    "val_ratio = 0\r\n",
    "test_ratio = 0.2\r\n",
    "\r\n",
    "# product data\r\n",
    "p_dataset = ReactionDataset(base_path, geo_file = 'train_p') \r\n",
    "p_data = p_dataset.data\r\n",
    "p_data.train_mask = p_data.val_mask = p_data.test_mask = p_data.y = None\r\n",
    "p_data = train_test_split_edges(data = p_data, val_ratio = val_ratio, test_ratio = test_ratio)\r\n",
    "p_x = p_data.x.to(device)\r\n",
    "p_train_pos_edge_index = p_data.train_pos_edge_index.to(device)\r\n",
    "\r\n",
    "# product encoder\r\n",
    "p_num_node_fs = p_data.num_node_features\r\n",
    "p_latent_dim = 2\r\n",
    "p_ae = GAE(MolEncoder(p_num_node_fs, p_latent_dim))\r\n",
    "p_opt = torch.optim.Adam(p_ae.parameters(), lr = 0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 010, AUC: 0.7871, AP: 0.6643\n",
      "Epoch: 020, AUC: 0.7860, AP: 0.6698\n",
      "Epoch: 030, AUC: 0.7876, AP: 0.6959\n",
      "Epoch: 040, AUC: 0.8174, AP: 0.7411\n",
      "Epoch: 050, AUC: 0.8711, AP: 0.7817\n",
      "Epoch: 060, AUC: 0.8898, AP: 0.7884\n",
      "Epoch: 070, AUC: 0.8851, AP: 0.7721\n",
      "Epoch: 080, AUC: 0.8831, AP: 0.7654\n",
      "Epoch: 090, AUC: 0.8754, AP: 0.7582\n",
      "Epoch: 100, AUC: 0.8780, AP: 0.7616\n"
     ]
    }
   ],
   "source": [
    "p_ae.reset_parameters()\r\n",
    "\r\n",
    "epochs = 100\r\n",
    "for epoch in range(1, epochs + 1):\r\n",
    "    loss = train_gae(p_ae, p_opt, p_x, p_data.train_pos_edge_index)\r\n",
    "    auc, ap = test_gae(p_ae, p_x, p_data.train_pos_edge_index, p_data.test_pos_edge_index, p_data.test_neg_edge_index)\r\n",
    "    if epoch % 10 == 0:\r\n",
    "        print('Epoch: {:03d}, AUC: {:.4f}, AP: {:.4f}'.format(epoch, auc, ap))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Same AE architecture but with reactant and product data concatenated"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hacky way\r\n",
    "Create train_rp_50.sdf file with first 50 reactants and products.\r\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model data\r\n",
    "base_path = r'data/'\r\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\r\n",
    "val_ratio = 0\r\n",
    "test_ratio = 0.2 # 50 reactants and 50 products. will end up training on 50 reactants + 30 products and testing on 20 products\r\n",
    "\r\n",
    "# rp data\r\n",
    "rp_dataset = ReactionDataset(base_path, geo_file = 'train_rp_50')\r\n",
    "rp_data = rp_dataset.data\r\n",
    "rp_data.train_mask = rp_data.val_mask = rp_data.test_mask = rp_data.y = None\r\n",
    "rp_data = train_test_split_edges(data = rp_data, val_ratio = val_ratio, test_ratio = test_ratio)\r\n",
    "rp_x = rp_data.x.to(device)\r\n",
    "rp_train_pos_edge_index = rp_data.train_pos_edge_index.to(device)\r\n",
    "\r\n",
    "# rp autoencoder\r\n",
    "rp_num_node_fs = rp_data.num_node_features\r\n",
    "rp_latent_dim = 2\r\n",
    "rp_ae = GAE(MolEncoder(rp_num_node_fs, rp_latent_dim))\r\n",
    "rp_opt = torch.optim.Adam(rp_ae.parameters(), lr = 0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 010, AUC: 0.6097, AP: 0.5554\n",
      "Epoch: 020, AUC: 0.3769, AP: 0.4165\n",
      "Epoch: 030, AUC: 0.5066, AP: 0.4703\n",
      "Epoch: 040, AUC: 0.6515, AP: 0.5624\n",
      "Epoch: 050, AUC: 0.7327, AP: 0.6283\n",
      "Epoch: 060, AUC: 0.8057, AP: 0.6766\n",
      "Epoch: 070, AUC: 0.8086, AP: 0.6799\n",
      "Epoch: 080, AUC: 0.8160, AP: 0.6874\n",
      "Epoch: 090, AUC: 0.8062, AP: 0.6833\n",
      "Epoch: 100, AUC: 0.8261, AP: 0.6953\n"
     ]
    }
   ],
   "source": [
    "rp_ae.reset_parameters()\r\n",
    "\r\n",
    "epochs = 100\r\n",
    "for epoch in range(1, epochs + 1):\r\n",
    "    loss = train_gae(rp_ae, rp_opt, rp_x, rp_data.train_pos_edge_index)\r\n",
    "    auc, ap = test_gae(rp_ae, rp_x, rp_data.train_pos_edge_index, rp_data.test_pos_edge_index, rp_data.test_neg_edge_index)\r\n",
    "    if epoch % 10 == 0:\r\n",
    "        print('Epoch: {:03d}, AUC: {:.4f}, AP: {:.4f}'.format(epoch, auc, ap))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create ConcatReactionDataset\r\n",
    "\r\n",
    "i.e. not hacky, create a concatenated dataset at source.\r\n",
    "\r\n",
    "Key words for network: dual, double, siamese, twin networks.\r\n",
    "- Siamese/twin: same weights while working in tandem on two different input vectors to compute comparable output vectors.\r\n",
    "\r\n",
    "Key words for training: simultaneous training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model data\r\n",
    "base_path = r'data/'\r\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\r\n",
    "val_ratio = 0\r\n",
    "test_ratio = 0.2\r\n",
    "\r\n",
    "# concat rp data\r\n",
    "concat_rp_dataset = ConcatReactionDataset(base_path)\r\n",
    "concat_rp_data = concat_rp_dataset.data\r\n",
    "concat_rp_data.train_mask = concat_rp_data.val_mask = concat_rp_data.test_mask = concat_rp_data.y = None\r\n",
    "concat_rp_data = train_test_split_edges(data = concat_rp_data, val_ratio = val_ratio, test_ratio = test_ratio)\r\n",
    "concat_rp_x = concat_rp_data.x.to(device)\r\n",
    "concat_rp_train_pos_edge_index = concat_rp_data.train_pos_edge_index.to(device)\r\n",
    "\r\n",
    "# concat rp encoder\r\n",
    "concat_rp_num_node_fs = concat_rp_data.num_node_features\r\n",
    "concat_rp_latent_dim = 2\r\n",
    "concat_rp_ae = GAE(MolEncoder(concat_rp_num_node_fs, concat_rp_latent_dim))\r\n",
    "concat_rp_opt = torch.optim.Adam(concat_rp_ae.parameters(), lr = 0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 010, AUC: 0.7733, AP: 0.6341\n",
      "Epoch: 020, AUC: 0.6032, AP: 0.5291\n",
      "Epoch: 030, AUC: 0.4524, AP: 0.4456\n",
      "Epoch: 040, AUC: 0.4638, AP: 0.4493\n",
      "Epoch: 050, AUC: 0.5354, AP: 0.4963\n",
      "Epoch: 060, AUC: 0.6539, AP: 0.5780\n",
      "Epoch: 070, AUC: 0.7542, AP: 0.6320\n",
      "Epoch: 080, AUC: 0.7680, AP: 0.6445\n",
      "Epoch: 090, AUC: 0.7813, AP: 0.6524\n",
      "Epoch: 100, AUC: 0.7971, AP: 0.6696\n"
     ]
    }
   ],
   "source": [
    "concat_rp_ae.reset_parameters()\r\n",
    "\r\n",
    "epochs = 100\r\n",
    "for epoch in range(1, epochs + 1):\r\n",
    "    loss = train_gae(concat_rp_ae, concat_rp_opt, concat_rp_x, concat_rp_data.train_pos_edge_index)\r\n",
    "    auc, ap = test_gae(concat_rp_ae, concat_rp_x, concat_rp_data.train_pos_edge_index, concat_rp_data.test_pos_edge_index, concat_rp_data.test_neg_edge_index)\r\n",
    "    if epoch % 10 == 0:\r\n",
    "        print('Epoch: {:03d}, AUC: {:.4f}, AP: {:.4f}'.format(epoch, auc, ap))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rp data\r\n",
    "rp_dataset = ReactionDataset(base_path, geo_file = 'train_rp_50')\r\n",
    "rp_data = rp_dataset.data\r\n",
    "rp_data.train_mask = rp_data.val_mask = rp_data.test_mask = rp_data.y = None\r\n",
    "rp_data = train_test_split_edges(data = rp_data, val_ratio = val_ratio, test_ratio = test_ratio)\r\n",
    "rp_x = rp_data.x.to(device)\r\n",
    "rp_train_pos_edge_index = rp_data.train_pos_edge_index.to(device)\r\n",
    "\r\n",
    "# rp autoencoder\r\n",
    "rp_num_node_fs = rp_data.num_node_features\r\n",
    "rp_latent_dim = 2\r\n",
    "rp_ae = GAE(MolEncoder(rp_num_node_fs, rp_latent_dim))\r\n",
    "rp_opt = torch.optim.Adam(rp_ae.parameters(), lr = 0.01)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reactant-Product Autoencoder\r\n",
    "\r\n",
    "Train reactant and product autoencoders simultaneously and decode to either (i) $z_{RP}$ or (ii) $(z_R, z_P)$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### One GAE on (R, P) tuple $\\rightarrow z_{RP} \\rightarrow$ reactant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_auc_score, average_precision_score\r\n",
    "from torch_geometric.utils import (negative_sampling, remove_self_loops, add_self_loops)\r\n",
    "\r\n",
    "EPS = 1e-15\r\n",
    "\r\n",
    "class DualGAE(nn.Module):\r\n",
    "    \r\n",
    "    def __init__(self, r_encoder, p_encoder, decoder = None):\r\n",
    "        super(DualGAE, self).__init__()\r\n",
    "        self.r_encoder = r_encoder\r\n",
    "        self.p_encoder = p_encoder\r\n",
    "        self.decoder = InnerProductDecoder() if decoder is None else decoder\r\n",
    "        DualGAE.reset_parameters(self)\r\n",
    "    \r\n",
    "    def reset_parameters(self):\r\n",
    "        reset(self.r_encoder)\r\n",
    "        reset(self.p_encoder)\r\n",
    "        reset(self.decoder)\r\n",
    "    \r\n",
    "    def encode(self, r_x, p_x, r_train_pos_edge_index, p_train_pos_edge_index):\r\n",
    "        z_r = self.r_encoder(r_x, r_train_pos_edge_index)\r\n",
    "        z_p = self.p_encoder(p_x, p_train_pos_edge_index)\r\n",
    "        return self.combine_r_and_p(z_r, z_p)\r\n",
    "\r\n",
    "    def combine_r_and_p(self, r, p):\r\n",
    "        return r + p\r\n",
    "    \r\n",
    "    def decode(self, *args, **kwargs):\r\n",
    "        return self.decoder(*args, **kwargs)\r\n",
    "\r\n",
    "    def recon_loss(self, z, pos_edge_index, neg_edge_index = None):\r\n",
    "        \"\"\" BCE for input on its reconstruction. \r\n",
    "            TODO: recon both as a tuple?\r\n",
    "        \"\"\"\r\n",
    "        pos_loss = - torch.log(self.decoder(z, pos_edge_index, sigmoid = True) + EPS).mean()\r\n",
    "\r\n",
    "        # no self-loops in negative samples\r\n",
    "        pos_edge_index, _ = remove_self_loops(pos_edge_index)\r\n",
    "        pos_edge_index, _ = add_self_loops(pos_edge_index)\r\n",
    "        if neg_edge_index is None:\r\n",
    "            neg_edge_index = negative_sampling(pos_edge_index, z.size(0))\r\n",
    "        neg_loss = -torch.log(1 - self.decoder(z, neg_edge_index, sigmoid = True) + EPS).mean()\r\n",
    "\r\n",
    "        return pos_loss + neg_loss\r\n",
    "\r\n",
    "    def test(self, z, pos_edge_index, neg_edge_index):\r\n",
    "        pos_y = z.new_ones(pos_edge_index.size(1))\r\n",
    "        neg_y = z.new_zeros(neg_edge_index.size(1))\r\n",
    "        y = torch.cat([pos_y, neg_y], dim=0)\r\n",
    "\r\n",
    "        pos_pred = self.decoder(z, pos_edge_index, sigmoid=True)\r\n",
    "        neg_pred = self.decoder(z, neg_edge_index, sigmoid=True)\r\n",
    "        pred = torch.cat([pos_pred, neg_pred], dim=0)\r\n",
    "\r\n",
    "        y, pred = y.detach().cpu().numpy(), pred.detach().cpu().numpy()\r\n",
    "\r\n",
    "        return roc_auc_score(y, pred), average_precision_score(y, pred)\r\n",
    "\r\n",
    "class MolEncoder(nn.Module):\r\n",
    "    def __init__(self, in_channels, out_channels):\r\n",
    "        super(MolEncoder, self).__init__()\r\n",
    "        self.conv = GCNConv(in_channels, out_channels)\r\n",
    "\r\n",
    "    def forward(self, x, edge_index):\r\n",
    "        z = self.conv(x, edge_index)\r\n",
    "        return z\r\n",
    "\r\n",
    "class InnerProductDecoder(nn.Module):\r\n",
    "    def forward(self, z, edge_index, sigmoid = True):\r\n",
    "        value = (z[edge_index[0]] * z[edge_index[1]]).sum(dim = 1)\r\n",
    "        return torch.sigmoid(value) if sigmoid else value\r\n",
    "    \r\n",
    "    def forward_all(self, z, sigmoid = True):\r\n",
    "        adj = torch.matmul(z, z.t())\r\n",
    "        return torch.sigmoid(adj) if sigmoid else adj\r\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_dgae(dgae, opt, r_x, p_x, r_train_pos_edge_index, p_train_pos_edge_index):\r\n",
    "    dgae.train()\r\n",
    "    opt.zero_grad()\r\n",
    "    z_rp = dgae.encode(r_x, p_x, r_train_pos_edge_index, p_train_pos_edge_index)\r\n",
    "    loss = dgae.recon_loss(z_rp, r_train_pos_edge_index)\r\n",
    "    loss.backward()\r\n",
    "    opt.step()\r\n",
    "    return float(loss)\r\n",
    "\r\n",
    "# the test indices here will be for reactant but could now make them for TS\r\n",
    "def test_dgae(dgae, r_x, p_x, r_train_pos_edge_index, p_train_pos_edge_index, test_pos_edge_index, test_neg_edge_index):\r\n",
    "    dgae.eval()\r\n",
    "    with torch.no_grad():\r\n",
    "        z_rp = dgae.encode(r_x, p_x, r_train_pos_edge_index, p_train_pos_edge_index)\r\n",
    "    return dgae.test(z_rp, test_pos_edge_index, test_neg_edge_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model data\r\n",
    "base_path = r'data/'\r\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\r\n",
    "val_ratio = 0\r\n",
    "test_ratio = 0.2\r\n",
    "\r\n",
    "# reactant dataset\r\n",
    "r_dataset = ReactionDataset(base_path, geo_file = 'train_r')\r\n",
    "r_data = r_dataset.data\r\n",
    "r_data.train_mask = r_data.val_mask = r_data.test_mask = r_data.y = None\r\n",
    "r_data = train_test_split_edges(data = r_data, val_ratio = val_ratio, test_ratio = test_ratio)\r\n",
    "r_x = r_data.x.to(device)\r\n",
    "r_train_pos_edge_index = r_data.train_pos_edge_index.to(device)\r\n",
    "\r\n",
    "# product dataset\r\n",
    "p_dataset = ReactionDataset(base_path, geo_file = 'train_p')  \r\n",
    "p_data = p_dataset.data\r\n",
    "p_data.train_mask = p_data.val_mask = p_data.test_mask = p_data.y = None\r\n",
    "p_data = train_test_split_edges(data = p_data, val_ratio = val_ratio, test_ratio = test_ratio)\r\n",
    "p_x = p_data.x.to(device)\r\n",
    "p_train_pos_edge_index = p_data.train_pos_edge_index.to(device)\r\n",
    "\r\n",
    "# dual gae\r\n",
    "dgae = DualGAE(r_encoder = MolEncoder(p_data.num_node_features, 2), p_encoder = MolEncoder(p_data.num_node_features, 2))\r\n",
    "dgae_opt = torch.optim.Adam(dgae.parameters(), lr = 0.01) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 010, AUC: 0.5017, AP: 0.5388\n",
      "Epoch: 020, AUC: 0.7858, AP: 0.6639\n",
      "Epoch: 030, AUC: 0.8012, AP: 0.6687\n",
      "Epoch: 040, AUC: 0.7977, AP: 0.6651\n",
      "Epoch: 050, AUC: 0.8152, AP: 0.6853\n",
      "Epoch: 060, AUC: 0.8133, AP: 0.6838\n",
      "Epoch: 070, AUC: 0.8244, AP: 0.6981\n",
      "Epoch: 080, AUC: 0.8549, AP: 0.7332\n",
      "Epoch: 090, AUC: 0.8648, AP: 0.7434\n",
      "Epoch: 100, AUC: 0.8719, AP: 0.7502\n"
     ]
    }
   ],
   "source": [
    "dgae.reset_parameters()\r\n",
    "\r\n",
    "epochs = 100\r\n",
    "for epoch in range(1, epochs + 1):\r\n",
    "    loss = train_dgae(dgae, dgae_opt, r_x, p_x, r_train_pos_edge_index, p_train_pos_edge_index)\r\n",
    "    auc, ap = test_dgae(dgae, r_x, p_x, r_train_pos_edge_index, p_train_pos_edge_index, r_data.test_pos_edge_index, r_data.test_neg_edge_index)\r\n",
    "    if epoch % 10 == 0:\r\n",
    "        print('Epoch: {:03d}, AUC: {:.4f}, AP: {:.4f}'.format(epoch, auc, ap))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comparing $R \\rightarrow z_{R} \\rightarrow TS $  to  $ (R, P) \\rightarrow z_{RP} \\rightarrow TS $"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### $R \\rightarrow z_R \\rightarrow TS$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model data\r\n",
    "base_path = r'data/'\r\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\r\n",
    "val_ratio = 0\r\n",
    "test_ratio = 0.2\r\n",
    "\r\n",
    "# reactant dataset\r\n",
    "r_dataset = ReactionDataset(base_path, geo_file = 'reactants', dataset_type = 'full')\r\n",
    "r_data = r_dataset.data\r\n",
    "r_data.train_mask = r_data.val_mask = r_data.test_mask = r_data.y = None\r\n",
    "r_data = train_test_split_edges(data = r_data, val_ratio = val_ratio, test_ratio = test_ratio)\r\n",
    "r_x = r_data.x.to(device)\r\n",
    "r_train_pos_edge_index = r_data.train_pos_edge_index.to(device)\r\n",
    "\r\n",
    "# ts dataset\r\n",
    "ts_dataset = ReactionDataset(base_path, geo_file = 'ts', dataset_type = 'full')  \r\n",
    "ts_data = ts_dataset.data\r\n",
    "ts_data.train_mask = ts_data.val_mask = ts_data.test_mask = ts_data.y = None\r\n",
    "ts_data = train_test_split_edges(data = ts_data, val_ratio = val_ratio, test_ratio = test_ratio)\r\n",
    "ts_x = ts_data.x.to(device)\r\n",
    "ts_train_pos_edge_index = ts_data.train_pos_edge_index.to(device)\r\n",
    "\r\n",
    "# reactant->ts GAE\r\n",
    "r_ts_ae = GAE(MolEncoder(r_data.num_node_features, 2))\r\n",
    "r_ts_opt = torch.optim.Adam(r_ts_ae.parameters(), lr = 0.01)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Hiding + Not full dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch_geometric.utils import to_undirected\r\n",
    "def train_test_split_edges(data, val_ratio: float = 0.05, test_ratio: float = 0.1):\r\n",
    "\r\n",
    "    assert 'batch' not in data  # No batch-mode.\r\n",
    "\r\n",
    "    num_nodes = data.num_nodes\r\n",
    "    row, col = data.edge_index\r\n",
    "    edge_attr = data.edge_attr\r\n",
    "    data.edge_index = data.edge_attr = None\r\n",
    "\r\n",
    "    # Return upper triangular portion.\r\n",
    "    mask = row < col\r\n",
    "    row, col = row[mask], col[mask]\r\n",
    "\r\n",
    "    if edge_attr is not None:\r\n",
    "        edge_attr = edge_attr[mask]\r\n",
    "\r\n",
    "    n_v = int(math.floor(val_ratio * row.size(0)))\r\n",
    "    n_t = int(math.floor(test_ratio * row.size(0)))\r\n",
    "\r\n",
    "    # Positive edges.\r\n",
    "    perm = torch.randperm(row.size(0))\r\n",
    "    row, col = row[perm], col[perm]\r\n",
    "    if edge_attr is not None:\r\n",
    "        edge_attr = edge_attr[perm]\r\n",
    "\r\n",
    "    r, c = row[:n_v], col[:n_v]\r\n",
    "    data.val_pos_edge_index = torch.stack([r, c], dim=0)\r\n",
    "    if edge_attr is not None:\r\n",
    "        data.val_pos_edge_attr = edge_attr[:n_v]\r\n",
    "\r\n",
    "    r, c = row[n_v:n_v + n_t], col[n_v:n_v + n_t]\r\n",
    "    data.test_pos_edge_index = torch.stack([r, c], dim=0)\r\n",
    "    if edge_attr is not None:\r\n",
    "        data.test_pos_edge_attr = edge_attr[n_v:n_v + n_t]\r\n",
    "\r\n",
    "    r, c = row[n_v + n_t:], col[n_v + n_t:]\r\n",
    "    data.train_pos_edge_index = torch.stack([r, c], dim=0)\r\n",
    "    print(row.shape, col.shape, data.train_pos_edge_index.shape)\r\n",
    "    if edge_attr is not None:\r\n",
    "        out = to_undirected(data.train_pos_edge_index, edge_attr[n_v + n_t:])\r\n",
    "        data.train_pos_edge_index, data.train_pos_edge_attr = out\r\n",
    "    else:\r\n",
    "        data.train_pos_edge_index = to_undirected(data.train_pos_edge_index)\r\n",
    "\r\n",
    "    # Negative edges.\r\n",
    "    neg_adj_mask = torch.ones(num_nodes, num_nodes, dtype=torch.uint8)\r\n",
    "    neg_adj_mask = neg_adj_mask.triu(diagonal=1).to(torch.bool)\r\n",
    "    neg_adj_mask[row, col] = 0\r\n",
    "\r\n",
    "    neg_row, neg_col = neg_adj_mask.nonzero(as_tuple=False).t()\r\n",
    "    perm = torch.randperm(neg_row.size(0))[:n_v + n_t]\r\n",
    "    neg_row, neg_col = neg_row[perm], neg_col[perm]\r\n",
    "\r\n",
    "    neg_adj_mask[neg_row, neg_col] = 0\r\n",
    "    data.train_neg_adj_mask = neg_adj_mask\r\n",
    "\r\n",
    "    row, col = neg_row[:n_v], neg_col[:n_v]\r\n",
    "    data.val_neg_edge_index = torch.stack([row, col], dim=0)\r\n",
    "\r\n",
    "    row, col = neg_row[n_v:n_v + n_t], neg_col[n_v:n_v + n_t]\r\n",
    "    data.test_neg_edge_index = torch.stack([row, col], dim=0)\r\n",
    "\r\n",
    "    return data\r\n",
    "\r\n",
    "r_dataset = ReactionDataset(base_path, geo_file = 'reactants', dataset_type = 'full')\r\n",
    "r_data = r_dataset.data\r\n",
    "r_data.train_mask = r_data.val_mask = r_data.test_mask = r_data.y = None\r\n",
    "r_data = train_test_split_edges(data = r_data, val_ratio = 0, test_ratio = 0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/6739 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 30/6739 [00:00<01:20, 83.32it/s]\n",
      "  0%|          | 30/6739 [00:00<00:05, 1203.22it/s]\n",
      "  0%|          | 30/6739 [00:00<00:08, 771.68it/s]\n",
      "  4%|▎         | 30/842 [00:00<00:01, 474.28it/s]\n",
      "  4%|▎         | 30/842 [00:00<00:01, 478.90it/s]\n",
      "  4%|▎         | 30/842 [00:00<00:01, 578.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done!\n"
     ]
    }
   ],
   "source": [
    "# model data\r\n",
    "base_path = r'data/'\r\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\r\n",
    "val_ratio = 0\r\n",
    "test_ratio = 0.2\r\n",
    "\r\n",
    "# reactant dataset\r\n",
    "r_dataset = ReactionDataset(base_path, geo_file = 'train_r', dataset_type = 'individual')\r\n",
    "r_data = r_dataset.data\r\n",
    "r_data.train_mask = r_data.val_mask = r_data.test_mask = r_data.y = None\r\n",
    "r_data = train_test_split_edges(data = r_data, val_ratio = val_ratio, test_ratio = test_ratio)\r\n",
    "r_x = r_data.x.to(device)\r\n",
    "r_train_pos_edge_index = r_data.train_pos_edge_index.to(device)\r\n",
    "\r\n",
    "# ts dataset\r\n",
    "ts_dataset = ReactionDataset(base_path, geo_file = 'train_ts', dataset_type = 'individual')  \r\n",
    "ts_data = ts_dataset.data\r\n",
    "ts_data.train_mask = ts_data.val_mask = ts_data.test_mask = ts_data.y = None\r\n",
    "ts_data = train_test_split_edges(data = ts_data, val_ratio = val_ratio, test_ratio = test_ratio)\r\n",
    "ts_x = ts_data.x.to(device)\r\n",
    "ts_train_pos_edge_index = ts_data.train_pos_edge_index.to(device)\r\n",
    "\r\n",
    "# reactant->ts GAE\r\n",
    "r_ts_ae = GAE(MolEncoder(r_data.num_node_features, 2))\r\n",
    "r_ts_opt = torch.optim.Adam(r_ts_ae.parameters(), lr = 0.01)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_r_to_ts(gae, opt, x, train_index, recon_index):\r\n",
    "    gae.train()\r\n",
    "    opt.zero_grad()\r\n",
    "    # encode the reactant data as node features and edge indices\r\n",
    "    z = gae.encode(x, train_index) \r\n",
    "    # decode z to ts edge indices\r\n",
    "    loss = gae.recon_loss(z, recon_index)\r\n",
    "    loss.backward()\r\n",
    "    opt.step()\r\n",
    "    return float(loss)\r\n",
    "\r\n",
    "def test_r_to_ts(gae, x, train_index, test_pos_index, test_neg_index):\r\n",
    "    gae.eval()\r\n",
    "    with torch.no_grad():\r\n",
    "        z = gae.encode(x, train_index)\r\n",
    "    return gae.test(z, test_pos_index, test_neg_index)\r\n",
    "\r\n",
    "# print(r_data.train_pos_edge_index.shape, r_data.test_pos_edge_index.shape, r_data.test_neg_edge_index.shape)\r\n",
    "# print(ts_data.train_pos_edge_index.shape, ts_data.test_pos_edge_index.shape, ts_data.test_pos_edge_index.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 010, AUC: 0.9300, AP: 0.8886\n",
      "Epoch: 020, AUC: 0.6665, AP: 0.7978\n",
      "Epoch: 030, AUC: 0.8561, AP: 0.8909\n",
      "Epoch: 040, AUC: 0.8657, AP: 0.9003\n",
      "Epoch: 050, AUC: 0.8478, AP: 0.8869\n",
      "Epoch: 060, AUC: 0.8224, AP: 0.8683\n",
      "Epoch: 070, AUC: 0.7910, AP: 0.8528\n",
      "Epoch: 080, AUC: 0.7678, AP: 0.8404\n",
      "Epoch: 090, AUC: 0.7363, AP: 0.8278\n",
      "Epoch: 100, AUC: 0.7280, AP: 0.8258\n"
     ]
    }
   ],
   "source": [
    "# i need to encode the reactant to an embedding z_r then decode to a transition state. i'm training the whole autoencoder here\r\n",
    "# if my train:test split is 80:20, i want to:\r\n",
    "#   - training: take 80% of r data, generate z_r embeddings, then evaluate on 80% of ts_edge indices, modifying network\r\n",
    "#   - testing: take 20% of r data, generate z_r embeddings, then evaluate on 20% of ts_edge indices, without modifying network\r\n",
    "\r\n",
    "\r\n",
    "r_ts_ae.reset_parameters()\r\n",
    "epochs = 100\r\n",
    "\r\n",
    "for epoch in range(1, epochs + 1):\r\n",
    "    # you encode the reactant as node feat (x) and edge index, then reconstruct to TS edge index\r\n",
    "    loss = train_r_to_ts(r_ts_ae, r_ts_opt, r_x, r_train_pos_edge_index, ts_train_pos_edge_index)\r\n",
    "    # you encode the test datadata and then decode to TS\r\n",
    "    # TODO issue: ts edge index permutation from train_test_split_edges() won't be same for R and TS\r\n",
    "    auc, ap = test_r_to_ts(r_ts_ae, r_x, r_data.test_pos_edge_index, ts_data.test_pos_edge_index, ts_data.test_neg_edge_index)\r\n",
    "    if epoch % 10 == 0:\r\n",
    "        print('Epoch: {:03d}, AUC: {:.4f}, AP: {:.4f}'.format(epoch, auc, ap))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Don't think I need to do train and test edges if just training on reactants?\r\n",
    "\r\n",
    "I probably should associate the (r, ts, p in some way)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### $ (R, P) \\rightarrow z_R \\rightarrow TS$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model data\r\n",
    "base_path = r'data/'\r\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\r\n",
    "val_ratio = 0\r\n",
    "test_ratio = 0.2\r\n",
    "\r\n",
    "# reactant dataset\r\n",
    "r_dataset = ReactionDataset(base_path, geo_file = 'train_r')\r\n",
    "r_data = r_dataset.data\r\n",
    "r_data.train_mask = r_data.val_mask = r_data.test_mask = r_data.y = None\r\n",
    "r_data = train_test_split_edges(data = r_data, val_ratio = val_ratio, test_ratio = test_ratio)\r\n",
    "r_x = r_data.x.to(device)\r\n",
    "r_train_pos_edge_index = r_data.train_pos_edge_index.to(device)\r\n",
    "\r\n",
    "# product dataset\r\n",
    "p_dataset = ReactionDataset(base_path, geo_file = 'train_p')  \r\n",
    "p_data = p_dataset.data\r\n",
    "p_data.train_mask = p_data.val_mask = p_data.test_mask = p_data.y = None\r\n",
    "p_data = train_test_split_edges(data = p_data, val_ratio = val_ratio, test_ratio = test_ratio)\r\n",
    "p_x = p_data.x.to(device)\r\n",
    "p_train_pos_edge_index = p_data.train_pos_edge_index.to(device)\r\n",
    "\r\n",
    "# ts dataset\r\n",
    "ts_dataset = ReactionDataset(base_path, geo_file = 'train_ts')  \r\n",
    "ts_data = ts_dataset.data\r\n",
    "ts_data.train_mask = ts_data.val_mask = ts_data.test_mask = ts_data.y = None\r\n",
    "ts_data = train_test_split_edges(data = ts_data, val_ratio = val_ratio, test_ratio = test_ratio)\r\n",
    "ts_x = ts_data.x.to(device)\r\n",
    "\r\n",
    "# dual gae\r\n",
    "dgae = DualGAE(r_encoder = MolEncoder(p_data.num_node_features, 2), p_encoder = MolEncoder(p_data.num_node_features, 2))\r\n",
    "dgae_opt = torch.optim.Adam(dgae.parameters(), lr = 0.01) "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.6.13 64-bit (conda)",
   "name": "python3613jvsc74a57bd0f4671ad35fdc0609fa675edcd17de5b3092cb55d03f1d9670a78611a41fb18f3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  },
  "orig_nbformat": 2
 },
 "nbformat": 4,
 "nbformat_minor": 2
}