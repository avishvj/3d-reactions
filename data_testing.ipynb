{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Manual data processing if issues"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Note: used this before in top folder. \r\n",
    "- May have issues with imports.\r\n",
    "- Can move back to top folder if using."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy.core.fromnumeric import product\r\n",
    "from scipy.sparse import data\r\n",
    "import torch\r\n",
    "import torch.nn.functional as F\r\n",
    "from torch_scatter import scatter\r\n",
    "from torch_geometric.data import InMemoryDataset, DataLoader # , Data\r\n",
    "from torch_geometric.data.data import Data\r\n",
    "from rdkit import Chem\r\n",
    "from rdkit.Chem.rdchem import HybridizationType\r\n",
    "from rdkit.Chem.rdchem import BondType as BT\r\n",
    "from tqdm import tqdm\r\n",
    "\r\n",
    "def process_geometry_file(geometry_file, list = None):\r\n",
    "    \"\"\" Code mostly lifted from QM9 dataset creation https://pytorch-geometric.readthedocs.io/en/latest/_modules/torch_geometric/datasets/qm9.html \r\n",
    "        Transforms molecules to their atom features and adjacency lists.\r\n",
    "    \"\"\"\r\n",
    "    types = {'H': 0, 'C': 1, 'N': 2, 'O': 3, 'F': 4}\r\n",
    "    bonds = {BT.SINGLE: 0, BT.DOUBLE: 1, BT.TRIPLE: 2, BT.AROMATIC: 3}\r\n",
    "    limit = 100\r\n",
    "\r\n",
    "    data_list = list if list else []\r\n",
    "    full_path = r'data' + geometry_file\r\n",
    "    geometries = Chem.SDMolSupplier(full_path, removeHs=False, sanitize=False)\r\n",
    "\r\n",
    "    # get atom and edge features for each geometry\r\n",
    "    for i, mol in enumerate(tqdm(geometries)):\r\n",
    "\r\n",
    "        # temp soln cos of split edge memory issues\r\n",
    "        if i == limit:\r\n",
    "            break\r\n",
    "        \r\n",
    "        N = mol.GetNumAtoms()\r\n",
    "        # get atom positions as matrix w shape [num_nodes, num_dimensions] = [num_atoms, 3]\r\n",
    "        atom_data = geometries.GetItemText(i).split('\\n')[4:4 + N] \r\n",
    "        atom_positions = [[float(x) for x in line.split()[:3]] for line in atom_data]\r\n",
    "        atom_positions = torch.tensor(atom_positions, dtype=torch.float)\r\n",
    "        # all the features\r\n",
    "        type_idx = []\r\n",
    "        atomic_number = []\r\n",
    "        aromatic = []\r\n",
    "        sp = []\r\n",
    "        sp2 = []\r\n",
    "        sp3 = []\r\n",
    "        num_hs = []\r\n",
    "\r\n",
    "        # atom/node features\r\n",
    "        for atom in mol.GetAtoms():\r\n",
    "            type_idx.append(types[atom.GetSymbol()])\r\n",
    "            atomic_number.append(atom.GetAtomicNum())\r\n",
    "            aromatic.append(1 if atom.GetIsAromatic() else 0)\r\n",
    "            hybridisation = atom.GetHybridization()\r\n",
    "            sp.append(1 if hybridisation == HybridizationType.SP else 0)\r\n",
    "            sp2.append(1 if hybridisation == HybridizationType.SP2 else 0)\r\n",
    "            sp3.append(1 if hybridisation == HybridizationType.SP3 else 0)\r\n",
    "            # !!! should do the features that lucky does: whether bonded, 3d_rbf\r\n",
    "\r\n",
    "        # bond/edge features\r\n",
    "        row, col, edge_type = [], [], []\r\n",
    "        for bond in mol.GetBonds(): \r\n",
    "            start, end = bond.GetBeginAtomIdx(), bond.GetEndAtomIdx()\r\n",
    "            row += [start, end]\r\n",
    "            col += [end, start]\r\n",
    "            # edge type for each bond type; *2 because both ways\r\n",
    "            edge_type += 2 * [bonds[bond.GetBondType()]]\r\n",
    "        # edge_index is graph connectivity in COO format with shape [2, num_edges]\r\n",
    "        edge_index = torch.tensor([row, col], dtype=torch.long)\r\n",
    "        edge_type = torch.tensor(edge_type, dtype=torch.long)\r\n",
    "        # edge_attr is edge feature matrix with shape [num_edges, num_edge_features]\r\n",
    "        edge_attr = F.one_hot(edge_type, num_classes=len(bonds)).to(torch.float) \r\n",
    "\r\n",
    "        # order edges based on combined ascending order\r\n",
    "        perm = (edge_index[0] * N + edge_index[1]).argsort() # TODO\r\n",
    "        edge_index = edge_index[:, perm]\r\n",
    "        edge_type = edge_type[perm]\r\n",
    "        edge_attr = edge_attr[perm]\r\n",
    "\r\n",
    "        row, col = edge_index\r\n",
    "        z = torch.tensor(atomic_number, dtype=torch.long)\r\n",
    "        hs = (z == 1).to(torch.float) # hydrogens\r\n",
    "        num_hs = scatter(hs[row], col, dim_size=N).tolist() # scatter helps with one-hot\r\n",
    "        \r\n",
    "        x1 = F.one_hot(torch.tensor(type_idx), num_classes=len(types))\r\n",
    "        x2 = torch.tensor([atomic_number, aromatic, sp, sp2, sp3, num_hs], dtype=torch.float).t().contiguous()\r\n",
    "        x = torch.cat([x1.to(torch.float), x2], dim=-1)\r\n",
    "\r\n",
    "        data = Data(x=x, z=z, pos=atom_positions, edge_index=edge_index, edge_attr=edge_attr, idx=i)\r\n",
    "        \r\n",
    "        data_list.append(data)\r\n",
    "\r\n",
    "    return data_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|▏         | 100/6739 [00:00<00:20, 322.49it/s]\n",
      " 12%|█▏        | 100/842 [00:00<00:01, 630.53it/s]\n",
      "  1%|▏         | 100/6739 [00:00<00:04, 1348.46it/s]\n",
      " 12%|█▏        | 100/842 [00:00<00:01, 580.31it/s]\n",
      "  1%|▏         | 100/6739 [00:00<00:04, 1388.79it/s]\n",
      " 12%|█▏        | 100/842 [00:00<00:00, 773.73it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'torch_geometric.data.data.Data'> <class 'torch_geometric.data.data.Data'> <class 'torch_geometric.data.data.Data'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# concat train r and test r\r\n",
    "reactants = []\r\n",
    "reactants = process_geometry_file('/raw/train_reactants.sdf', reactants)\r\n",
    "reactants = process_geometry_file('/raw/test_reactants.sdf', reactants)\r\n",
    "\r\n",
    "# concat train ts and test ts\r\n",
    "ts = []\r\n",
    "ts = process_geometry_file('/raw/train_ts.sdf', ts)\r\n",
    "ts = process_geometry_file('/raw/test_ts.sdf', ts) \r\n",
    "\r\n",
    "# concat train p and test p\r\n",
    "products = []\r\n",
    "products = process_geometry_file('/raw/train_products.sdf', products)\r\n",
    "products = process_geometry_file('/raw/test_products.sdf', products) \r\n",
    "\r\n",
    "assert len(reactants) == len(ts) == len(products)\r\n",
    "\r\n",
    "print(type(reactants[0]), type(ts[0]), type(products[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ReactionTriple(Data):\r\n",
    "    def __init__(self, r = None, ts = None, p = None):\r\n",
    "        super(ReactionTriple, self).__init__()\r\n",
    "        self.r = r\r\n",
    "        self.ts = ts\r\n",
    "        self.p = p\r\n",
    "\r\n",
    "    def __inc__(self, key, value):\r\n",
    "        if key == 'r':\r\n",
    "            return self.r.edge_index.size(0)\r\n",
    "        elif key == 'ts':\r\n",
    "            return self.ts.edge_index.size(0)\r\n",
    "        elif key == 'p':\r\n",
    "            return self.p.edge_index.size(0)\r\n",
    "        else:\r\n",
    "            return super().__inc__(key, value)\r\n",
    "\r\n",
    "class OtherReactionTriple(Data):\r\n",
    "    # seeing if this works\r\n",
    "\r\n",
    "    def __init__(self, r, ts, p):\r\n",
    "        super(OtherReactionTriple, self).__init__()\r\n",
    "\r\n",
    "        # initial checks\r\n",
    "        if r and ts and p:\r\n",
    "            assert r.idx == ts.idx == p.idx, \\\r\n",
    "                \"The IDs of each mol don't match. Are you sure your data processing is correct?\"\r\n",
    "            assert len(r.z) == len(ts.z) == len(p.z), \\\r\n",
    "                \"The mols have different number of atoms.\"\r\n",
    "            self.idx = r.idx\r\n",
    "            self.num_atoms = len(r.z)\r\n",
    "\r\n",
    "            # reactant\r\n",
    "            self.edge_attr_r = r.edge_attr\r\n",
    "            self.edge_index_r = r.edge_index\r\n",
    "            self.pos_r = r.pos\r\n",
    "            self.x_r = r.x\r\n",
    "\r\n",
    "            # ts\r\n",
    "            self.edge_attr_ts = ts.edge_attr\r\n",
    "            self.edge_index_ts = ts.edge_index\r\n",
    "            self.pos_ts = ts.pos\r\n",
    "            self.x_ts = ts.x\r\n",
    "\r\n",
    "            # product\r\n",
    "            self.edge_attr_p = p.edge_attr\r\n",
    "            self.edge_index_p = p.edge_index\r\n",
    "            self.pos_p = p.pos\r\n",
    "            self.x_p = p.x\r\n",
    "        else:\r\n",
    "            NameError(\"Reactant, TS, or Product not defined for this reaction.\")\r\n",
    "\r\n",
    "    def __inc__(self, key, value):\r\n",
    "        if key == 'edge_index_r' or key == 'edge_attr_r':\r\n",
    "            return self.x_r.size(0)\r\n",
    "        if key == 'edge_index_ts' or key == 'edge_attr_ts':\r\n",
    "            return self.x_ts.size(0)\r\n",
    "        if key == 'edge_index_p' or key == 'edge_attr_p':\r\n",
    "            return self.x_p.size(0)\r\n",
    "        else:\r\n",
    "            return super().__inc__(key, value)\r\n",
    "    \r\n",
    "    def __cat_dim__(self, key, item):\r\n",
    "        # NOTE: automatically figures out .x and .pos\r\n",
    "        if key == 'edge_attr_r' or key == 'edge_attr_ts' or key == 'edge_attr_p':\r\n",
    "            return 0\r\n",
    "        if key == 'edge_index_r' or key == 'edge_index_ts' or key == 'edge_index_p':\r\n",
    "            return 1\r\n",
    "        else:\r\n",
    "            return super().__cat_dim__(key, item)\r\n",
    "\r\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "__init__() missing 3 required positional arguments: 'r', 'ts', and 'p'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-72-9fd0646c0815>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[0mloader\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mDataLoader\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrxns\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfollow_batch\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mto_follow\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[0mbatch\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miter\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mloader\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 11\u001b[1;33m \u001b[0mbatch\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\miniconda3\\envs\\3d-rdkit\\lib\\site-packages\\torch_geometric\\data\\batch.py\u001b[0m in \u001b[0;36m__getitem__\u001b[1;34m(self, idx)\u001b[0m\n\u001b[0;32m    239\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mBatch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__getitem__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0midx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    240\u001b[0m         \u001b[1;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0midx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mint\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 241\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_example\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0midx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    242\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    243\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mindex_select\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0midx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\miniconda3\\envs\\3d-rdkit\\lib\\site-packages\\torch_geometric\\data\\batch.py\u001b[0m in \u001b[0;36mget_example\u001b[1;34m(self, idx)\u001b[0m\n\u001b[0;32m    171\u001b[0m                  'object was not created using `Batch.from_data_list()`.'))\n\u001b[0;32m    172\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 173\u001b[1;33m         \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__data_class__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    174\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    175\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mkey\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__slices__\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: __init__() missing 3 required positional arguments: 'r', 'ts', and 'p'"
     ]
    }
   ],
   "source": [
    "rxns = []\r\n",
    "for rxn_id in range(len(reactants)):\r\n",
    "    rxn = OtherReactionTriple(reactants[rxn_id], ts[rxn_id], products[rxn_id])\r\n",
    "    rxns.append(rxn)\r\n",
    "\r\n",
    "to_follow = ['edge_index_r', 'edge_index_ts', 'edge_index_p', 'edge_attr_r', 'edge_attr_ts', 'edge_attr_p'\r\n",
    "             'pos_r', 'pos_ts', 'pos_p', 'x_r', 'x_ts', 'x_p']\r\n",
    "\r\n",
    "loader = DataLoader(rxns, batch_size = 2, follow_batch = to_follow)\r\n",
    "batch = next(iter(loader))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "def edge2adj(z, edge_index, sigmoid = True):\r\n",
    "    value = (z[edge_index[0]] * z[edge_index[1]]).sum(dim = 1)\r\n",
    "    return torch.sigmoid(value) if sigmoid else value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "26"
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# their model \r\n",
    "# so they take their nodes, edges, edge_attr and actual adj\r\n",
    "# adj_pred, z = model(nodes, edges, edge_attr)\r\n",
    "# bce, kl = loss(adj_pred, adj_gt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch_geometric.utils import to_dense_adj\r\n",
    "\r\n",
    "node_fs = mol_graph.x\r\n",
    "edge_index = mol_graph.edge_index\r\n",
    "edge_attr = mol_graph.edge_attr\r\n",
    "num_nodes = len(mol_graph.z)\r\n",
    "latent_dim = 3\r\n",
    "max_num_nodes = 21\r\n",
    "\r\n",
    "def sparse_to_dense_adj(num_nodes, edge_index):\r\n",
    "    # edge_index is sparse_adj matrix (given in coo format for graph connectivity)\r\n",
    "    sparse_adj = torch.cat([edge_index[0].unsqueeze(0), edge_index[1].unsqueeze(0)])\r\n",
    "    # the values we put in at each tuple; that's why length of sparse_adj\r\n",
    "    ones = torch.ones(sparse_adj.size(1)) \r\n",
    "    # FloatTensor() creates sparse coo tensor in torch format, then to_dense()\r\n",
    "    dense_adj = torch.sparse.FloatTensor(sparse_adj, ones, torch.Size([num_nodes, num_nodes])).to_dense() # to_dense adds the zeroes needed\r\n",
    "    return dense_adj\r\n",
    "\r\n",
    "\r\n",
    "adj_egnn = sparse_to_dense_adj(num_nodes, edge_index)\r\n",
    "# with edge_attr, we get a [1, num_nodes, num_nodes] for each edge_type\r\n",
    "adj_pyg = to_dense_adj(edge_index, edge_attr = edge_attr, max_num_nodes = num_nodes)\r\n",
    "\r\n",
    "# get_dense_graph(): returns self.nodes, self.edges_dense, self.edge_attr_dense, self.adj\r\n",
    "# adj = sparse2dense(n_nodes, self.edges); adjust for loops\r\n",
    "# compare sparse2dense (egnn) vs to_dense_adj (pyg)\r\n",
    "\r\n",
    "# adj_egnn.shape\r\n",
    "# (adj_pyg == adj_egnn).all()\r\n",
    "\r\n",
    "# gcn = GCNConv(num_nodes, latent_dim)\r\n",
    "# z = gcn(node_fs, edge_index)\r\n",
    "\r\n",
    "# adj_pred = adj_pred * (1 - torch.eye(num_nodes).to(self.device)) # removes self_loops\r\n",
    "# * is hadamard product"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# coords always same, maybe node and edge features too? need to pad adj matrix\r\n",
    "\r\n",
    "# dataset dims\r\n",
    "elements = \"HCNO\"\r\n",
    "num_elements = len(elements)\r\n",
    "max_n_atoms = max([r.GetNumAtoms() for r,ts,p in data])\r\n",
    "num_coords = 3\r\n",
    "num_bond_fs\r\n",
    "\r\n",
    "# want to pad exist features\r\n",
    "\r\n",
    "def prepare_batch(batch_mols):\r\n",
    "\r\n",
    "    # initialise batch\r\n",
    "    batch_size = len(batch_mols)\r\n",
    "    atom_fs = torch.zeros((batch_size, max_n_atoms, num_elements + 1), dtype = torch.float32) # num_atoms, max_num_atoms, \r\n",
    "    bond_fs = torch.zeros((batch_size, max_n_atoms, max_n_atoms, num_bond_fs), dtype = torch.float32)\r\n",
    "    sizes = torch.zeros(batch_size, dtype = torch.float32)\r\n",
    "    coords = torch.zeros((batch_size, max_size, num_coords), dtype = torch.float32)\r\n",
    "    \r\n",
    "    pass\r\n",
    "\r\n",
    "def pad_sequence(sequences: List[torch.Tensor], max_length: int, padding_value=0) -> torch.Tensor:\r\n",
    "    # assuming trailing dimensions and type of all the Tensors\r\n",
    "    # in sequences are same and fetching those from sequences[0]\r\n",
    "    max_size = sequences[0].size()\r\n",
    "    trailing_dims = max_size[1:]\r\n",
    "    out_dims = (len(sequences), max_length) + trailing_dims\r\n",
    "\r\n",
    "    out_tensor = sequences[0].data.new(*out_dims).fill_(padding_value)  # type: ignore\r\n",
    "    for i, tensor in enumerate(sequences):\r\n",
    "        length = tensor.size(0)\r\n",
    "        # use index notation to prevent duplicate references to the tensor\r\n",
    "        out_tensor[i, :length, ...] = tensor\r\n",
    "\r\n",
    "    return out_tensor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ts_gen processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from rdkit import Chem\r\n",
    "import numpy as np\r\n",
    "import torch\r\n",
    "from torch_geometric.data import DataLoader\r\n",
    "from torch_geometric.data.data import Data\r\n",
    "import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TSGenData(Data):\r\n",
    "    # seeing if this works\r\n",
    "\r\n",
    "    def __init__(self, x = None, pos = None, edge_attr = None, idx = None):\r\n",
    "        super(TSGenData, self).__init__(x = x, pos = pos, edge_attr = edge_attr)\r\n",
    "        self.idx = idx\r\n",
    "\r\n",
    "    def __inc__(self, key, value):\r\n",
    "        if key == 'edge_attr':\r\n",
    "            return self.x.size(0)\r\n",
    "        else:\r\n",
    "            return super().__inc__(key, value)\r\n",
    "    \r\n",
    "    def __cat_dim__(self, key, item):\r\n",
    "        # NOTE: automatically figures out .x and .pos\r\n",
    "        if key == 'edge_attr':\r\n",
    "            return (0, 1) # since N x N x edge_attr\r\n",
    "        else:\r\n",
    "            return super().__cat_dim__(key, item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# constants\r\n",
    "MAX_D = 10.\r\n",
    "COORD_DIM = 3\r\n",
    "ELEM_TYPES = {'H': 0, 'C': 1, 'N': 2, 'O': 3, 'F': 4}\r\n",
    "NUM_EDGE_ATTR = 3\r\n",
    "TEMP_MOLS_LIMIT = 10\r\n",
    "\r\n",
    "def process():\r\n",
    "\r\n",
    "    # reactants\r\n",
    "    r_train = Chem.SDMolSupplier('data/raw/train_reactants.sdf', removeHs = False, sanitize = False)\r\n",
    "    r_test = Chem.SDMolSupplier('data/raw/test_reactants.sdf', removeHs = False, sanitize = False)\r\n",
    "    rs = []\r\n",
    "    for mol in r_train:\r\n",
    "        rs.append(mol)\r\n",
    "    for mol in r_test:\r\n",
    "        rs.append(mol)\r\n",
    "    \r\n",
    "    # transition states\r\n",
    "    ts_train = Chem.SDMolSupplier('data/raw/train_ts.sdf', removeHs = False, sanitize = False)\r\n",
    "    ts_test = Chem.SDMolSupplier('data/raw/test_ts.sdf', removeHs = False, sanitize = False)\r\n",
    "    tss = []\r\n",
    "    for mol in ts_train:\r\n",
    "        tss.append(mol)\r\n",
    "    for mol in ts_test:\r\n",
    "        tss.append(mol)\r\n",
    "    \r\n",
    "    # products\r\n",
    "    p_train = Chem.SDMolSupplier('data/raw/train_products.sdf', removeHs = False, sanitize = False)\r\n",
    "    p_test = Chem.SDMolSupplier('data/raw/test_products.sdf', removeHs = False, sanitize = False)\r\n",
    "    ps = []\r\n",
    "    for mol in p_train:\r\n",
    "        ps.append(mol)\r\n",
    "    for mol in p_test:\r\n",
    "        ps.append(mol)\r\n",
    "    \r\n",
    "    assert len(rs) == len(tss) == len(ps), f\"Lengths of reactants ({len(rs)}), transition states \\\r\n",
    "                                            ({len(tss)}), products ({len(ps)}) don't match.\"\r\n",
    "\r\n",
    "    geometries = list(zip(rs, tss, ps))\r\n",
    "    data_list = process_geometries(geometries)\r\n",
    "    return data_list\r\n",
    "    # torch.save(self.collate(data_list), self.processed_paths[0])\r\n",
    "\r\n",
    "def process_geometries(geometries):\r\n",
    "    \"\"\"Process all geometries in same manner as ts_gen.\"\"\"\r\n",
    "    \r\n",
    "    data_list = []\r\n",
    "    \r\n",
    "    for rxn_id, rxn in enumerate(geometries):\r\n",
    "\r\n",
    "        if rxn_id == TEMP_MOLS_LIMIT:\r\n",
    "            break\r\n",
    "\r\n",
    "        r, ts, p = rxn\r\n",
    "        num_atoms = r.GetNumAtoms()\r\n",
    "\r\n",
    "        # dist matrices\r\n",
    "        D = (Chem.GetDistanceMatrix(r) + Chem.GetDistanceMatrix(p)) / 2\r\n",
    "        D[D > MAX_D] = MAX_D\r\n",
    "        D_3D_rbf = np.exp(-((Chem.Get3DDistanceMatrix(r) + Chem.Get3DDistanceMatrix(p)) / 2))  \r\n",
    "\r\n",
    "        # node feats, edge attr init\r\n",
    "        type_ids, atomic_ns = [], [] # TODO: init of vec N\r\n",
    "        edge_attr = torch.zeros(num_atoms, num_atoms, NUM_EDGE_ATTR)\r\n",
    "        \r\n",
    "        # ts ground truth coords\r\n",
    "        ts_gt_pos = torch.zeros((num_atoms, COORD_DIM))\r\n",
    "        ts_conf = ts.GetConformer()\r\n",
    "        for i in range(num_atoms):\r\n",
    "\r\n",
    "            # node feats\r\n",
    "            atom = r.GetAtomWithIdx(i)\r\n",
    "            type_ids.append(ELEM_TYPES[atom.GetSymbol()])\r\n",
    "            atomic_ns.append(atom.GetAtomicNum() / 10.)\r\n",
    "\r\n",
    "            # ts coordinates: atom positions as matrix w shape [num_atoms, 3]\r\n",
    "            pos = ts_conf.GetAtomPosition(i)\r\n",
    "            ts_gt_pos[i] = torch.tensor([pos.x, pos.y, pos.z])\r\n",
    "            \r\n",
    "            # edge attrs\r\n",
    "            for j in range(num_atoms):\r\n",
    "                if D[i][j] == 1: # if stays bonded\r\n",
    "                    edge_attr[i][j][0] = 1 # bonded?\r\n",
    "                    if r.GetBondBetweenAtoms(i, j).GetIsAromatic():\r\n",
    "                        edge_attr[i][j][1] = 1 # aromatic?\r\n",
    "                edge_attr[i][j][2] = D_3D_rbf[i][j] # 3d rbf\r\n",
    "        \r\n",
    "        node_feats = torch.tensor([type_ids, atomic_ns], dtype = torch.float).t().contiguous()\r\n",
    "        atomic_ns = torch.tensor(atomic_ns, dtype = torch.long)\r\n",
    "        # edge_attr = torch.tensor([bonded, aromatic, rbf], dtype = torch.float).t().contiguous()\r\n",
    "\r\n",
    "        data = TSGenData(x = node_feats, pos = ts_gt_pos, edge_attr = edge_attr, idx = rxn_id)\r\n",
    "        data_list.append(data) \r\n",
    "\r\n",
    "    return data_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_list = process()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'data_list' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-7-7d75ee687b4e>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     59\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mslices\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     60\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 61\u001b[1;33m \u001b[0mcollate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata_list\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'data_list' is not defined"
     ]
    }
   ],
   "source": [
    "from torch import Tensor\r\n",
    "from itertools import product\r\n",
    "\r\n",
    "def collate(data_list):\r\n",
    "    keys = data_list[0].keys\r\n",
    "    data = data_list[0].__class__()\r\n",
    "\r\n",
    "    for key in keys:\r\n",
    "        data[key] = []\r\n",
    "    slices = {key: [0] for key in keys}\r\n",
    "\r\n",
    "    for item, key in product(data_list, keys):\r\n",
    "        data[key].append(item[key])\r\n",
    "        if isinstance(item[key], Tensor) and (item[key].dim() == 1 or item[key].dim() == 2):\r\n",
    "            cat_dim = item.__cat_dim__(key, item[key])\r\n",
    "            cat_dim = 0 if cat_dim is None else cat_dim\r\n",
    "            s = slices[key][-1] + item[key].size(cat_dim)\r\n",
    "        elif isinstance(item[key], Tensor) and (item[key].dim() > 2):\r\n",
    "            cat_dims = item.__cat_dim__(key, item[key])\r\n",
    "            # print(cat_dims)\r\n",
    "            s = slices[key][-1]\r\n",
    "            for cat_dim in cat_dims:\r\n",
    "                s += item[key].size(cat_dim)\r\n",
    "        else:\r\n",
    "            s = slices[key][-1] + 1\r\n",
    "        slices[key].append(s)\r\n",
    "    # print(slices)\r\n",
    "\r\n",
    "    if hasattr(data_list[0], '__num_nodes__'):\r\n",
    "        data.__num_nodes__ = []\r\n",
    "        for item in data_list:\r\n",
    "            data.__num_nodes__.append(item.num_nodes)\r\n",
    "\r\n",
    "    for key in keys:\r\n",
    "        item = data_list[0][key]\r\n",
    "        if isinstance(item, Tensor) and len(data_list) > 1:\r\n",
    "            if item.dim() == 1 or item.dim() == 2:\r\n",
    "                cat_dim = data.__cat_dim__(key, item)\r\n",
    "                cat_dim = 0 if cat_dim is None else cat_dim\r\n",
    "                data[key] = torch.cat(data[key], dim=cat_dim)\r\n",
    "            elif item.dim() > 2:\r\n",
    "                print(item.dim())\r\n",
    "                cat_dim = data.__cat_dim__(key, item)\r\n",
    "                # size = torch.tensor(item.sizes())[torch.tensor(cat_dim)]\r\n",
    "                # print(len(data[key]))\r\n",
    "                data[key] = torch.stack(data[key])\r\n",
    "                # data[key] = torch.cat(data[key], dim = 0)\r\n",
    "                # data[key] = torch.cat(data[key], dim = 1)\r\n",
    "                continue\r\n",
    "            else:\r\n",
    "                data[key] = torch.stack(data[key])\r\n",
    "        elif isinstance(item, Tensor):  # Don't duplicate attributes...\r\n",
    "            data[key] = data[key][0]\r\n",
    "        elif isinstance(item, int) or isinstance(item, float):\r\n",
    "            data[key] = torch.tensor(data[key])\r\n",
    "\r\n",
    "        slices[key] = torch.tensor(slices[key], dtype=torch.long)\r\n",
    "\r\n",
    "    return data, slices\r\n",
    "\r\n",
    "collate(data_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Sizes of tensors must match except in dimension 0. Got 2 and 4 in dimension 1 (The offending index is 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-9-13487dd34304>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mones\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m4\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m4\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m10\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mones\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m6\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m6\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m10\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m \u001b[0mpack_padded_sequence\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mb\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mc\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m4\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m6\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m: Sizes of tensors must match except in dimension 0. Got 2 and 4 in dimension 1 (The offending index is 1)"
     ]
    }
   ],
   "source": [
    "import torch\r\n",
    "from torch.nn.utils.rnn import pad_sequence, pack_padded_sequence\r\n",
    "a = torch.ones(2, 2, 10)\r\n",
    "b = torch.ones(4, 4, 10)\r\n",
    "c = torch.ones(6, 6, 10)\r\n",
    "pack_padded_sequence(torch.cat([a, b, c]), [2, 4, 6])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "loader = DataLoader(data_list, batch_size = 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Masks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "(torch.Size([4, 21, 1]), torch.Size([4, 21, 21, 1]))"
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# you would need to do this for each batch\r\n",
    "import torch\r\n",
    "def sequence_mask(sizes, max_size = None, dtype = torch.bool):\r\n",
    "    if max_size is None:\r\n",
    "        max_size = sizes.max()\r\n",
    "    row_vector = torch.arange(0, max_size, 1)\r\n",
    "    matrix = torch.unsqueeze(sizes, dim = -1)\r\n",
    "    mask = row_vector < matrix\r\n",
    "\r\n",
    "    mask.type(dtype)\r\n",
    "    return mask\r\n",
    "\r\n",
    "sizes = torch.tensor([10, 12, 20, 18]) # num_atoms in each graph\r\n",
    "max_size = 21\r\n",
    "mask = sequence_mask(sizes, max_size)\r\n",
    "\r\n",
    "mask_n = torch.unsqueeze(mask, 2)\r\n",
    "mask_v = torch.unsqueeze(mask_n, 1) * torch.unsqueeze(mask_n, 2)\r\n",
    "mask_n.shape, mask_v.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Final ts_gen code from .py file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files removed.\n",
      "Processing...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 10/7581 [00:00<01:07, 112.66it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from ts_vae.data_processors.ts_gen_processor import TSGenDataset\r\n",
    "from torch_geometric.data import DataLoader\r\n",
    "import numpy as np\r\n",
    "from ts_vae.utils import remove_files\r\n",
    "remove_files() \r\n",
    "rxns = TSGenDataset(r'data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "tt_split = 0.8\r\n",
    "num_rxns = len(rxns)\r\n",
    "num_train = int(np.floor(tt_split * num_rxns))\r\n",
    "batch_size = 5\r\n",
    "train_loader = DataLoader(rxns[: num_train], batch_size = batch_size)\r\n",
    "test_loader = DataLoader(rxns[num_train: ], batch_size = batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "3"
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_loader.dataset[0].edge_attr.size(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "Batch(batch=[105], edge_attr=[21, 21, 15], idx=[5], pos=[105, 3], ptr=[6], x=[105, 5])"
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rxns[0]\r\n",
    "batch = next(iter(train_loader))\r\n",
    "batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 10/7581 [00:00<00:42, 178.77it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([15, 15, 3])\n",
      "\n",
      "torch.Size([13, 13, 3])\n",
      "\n",
      "torch.Size([10, 10, 3])\n",
      "\n",
      "torch.Size([9, 9, 3])\n",
      "\n",
      "torch.Size([11, 11, 3])\n",
      "\n",
      "torch.Size([14, 14, 3])\n",
      "\n",
      "torch.Size([15, 15, 3])\n",
      "\n",
      "torch.Size([15, 15, 3])\n",
      "\n",
      "torch.Size([15, 15, 3])\n",
      "\n",
      "torch.Size([14, 14, 3])\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "size() received an invalid combination of arguments - got (tuple), but expected one of:\n * (int dim)\n      didn't match because some of the arguments have invalid types: (!tuple!)\n * ()\n      didn't match because some of the arguments have invalid types: (!tuple!)\n * (name dim)\n      didn't match because some of the arguments have invalid types: (!tuple!)\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-fece2cb1f3df>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;31m# remove_files()\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;31m# have to use batch_size = 1 right now\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m \u001b[0mtrain_log\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest_log\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mablation_experiment\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0.8\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mc:\\Users\\Avish\\Documents\\RP\\3d-reactions\\experiments\\building_on_mit\\meta_eval\\meta_eval.py\u001b[0m in \u001b[0;36mablation_experiment\u001b[1;34m(tt_split, batch_size, epochs, test_interval)\u001b[0m\n\u001b[0;32m     30\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     31\u001b[0m     \u001b[1;31m# data prep\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 32\u001b[1;33m     \u001b[0mrxns\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mTSGenDataset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mr'data'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     33\u001b[0m     \u001b[0mnum_rxns\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrxns\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     34\u001b[0m     \u001b[0mnum_train\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfloor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtt_split\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mnum_rxns\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\Avish\\Documents\\RP\\3d-reactions\\ts_vae\\data_processors\\ts_gen_processor.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, root_folder, transform, pre_transform)\u001b[0m\n\u001b[0;32m     36\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     37\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mroot_folder\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtransform\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpre_transform\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 38\u001b[1;33m         \u001b[0msuper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mTSGenDataset\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mroot_folder\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtransform\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpre_transform\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     39\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mslices\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprocessed_paths\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     40\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\miniconda3\\envs\\3d-rdkit\\lib\\site-packages\\torch_geometric\\data\\in_memory_dataset.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, root, transform, pre_transform, pre_filter)\u001b[0m\n\u001b[0;32m     53\u001b[0m                  pre_filter=None):\n\u001b[0;32m     54\u001b[0m         super(InMemoryDataset, self).__init__(root, transform, pre_transform,\n\u001b[1;32m---> 55\u001b[1;33m                                               pre_filter)\n\u001b[0m\u001b[0;32m     56\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mslices\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     57\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__data_list__\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\miniconda3\\envs\\3d-rdkit\\lib\\site-packages\\torch_geometric\\data\\dataset.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, root, transform, pre_transform, pre_filter)\u001b[0m\n\u001b[0;32m     90\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     91\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;34m'process'\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__class__\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__dict__\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 92\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_process\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     93\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     94\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mindices\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\miniconda3\\envs\\3d-rdkit\\lib\\site-packages\\torch_geometric\\data\\dataset.py\u001b[0m in \u001b[0;36m_process\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    163\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    164\u001b[0m         \u001b[0mmakedirs\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprocessed_dir\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 165\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprocess\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    166\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    167\u001b[0m         \u001b[0mpath\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mosp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprocessed_dir\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'pre_transform.pt'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\Avish\\Documents\\RP\\3d-reactions\\ts_vae\\data_processors\\ts_gen_processor.py\u001b[0m in \u001b[0;36mprocess\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     88\u001b[0m         \u001b[0mgeometries\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtss\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mps\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     89\u001b[0m         \u001b[0mdata_list\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprocess_geometries_2\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgeometries\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 90\u001b[1;33m         \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msave\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcollate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata_list\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprocessed_paths\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     91\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     92\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mprocess_geometries_1\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgeometries\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\miniconda3\\envs\\3d-rdkit\\lib\\site-packages\\torch_geometric\\data\\in_memory_dataset.py\u001b[0m in \u001b[0;36mcollate\u001b[1;34m(data_list)\u001b[0m\n\u001b[0;32m    121\u001b[0m                 \u001b[0mcat_dim\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mitem\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__cat_dim__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mitem\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    122\u001b[0m                 \u001b[0mcat_dim\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mcat_dim\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;32melse\u001b[0m \u001b[0mcat_dim\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 123\u001b[1;33m                 \u001b[0ms\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mslices\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mitem\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcat_dim\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    124\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    125\u001b[0m                 \u001b[0ms\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mslices\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: size() received an invalid combination of arguments - got (tuple), but expected one of:\n * (int dim)\n      didn't match because some of the arguments have invalid types: (!tuple!)\n * ()\n      didn't match because some of the arguments have invalid types: (!tuple!)\n * (name dim)\n      didn't match because some of the arguments have invalid types: (!tuple!)\n"
     ]
    }
   ],
   "source": [
    "from experiments.building_on_mit.meta_eval.meta_eval import ablation_experiment\r\n",
    "# from ts_vae.utils import remove_files\r\n",
    "# remove_files()\r\n",
    "# have to use batch_size = 1 right now\r\n",
    "train_log, test_log = ablation_experiment(0.8, 1, 2, 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Redoing with GraphDataLoader\r\n",
    "\r\n",
    "- GraphDataLoader: takes collate_fn given by GraphCollater()\r\n",
    "- GraphCollater -> Collater for ABC\r\n",
    "- GraphBatch\r\n",
    "<br/><br/>\r\n",
    "- CustomDataLoader, CustomBatch, CustomCollater\r\n",
    "- Then create my own collate() and Batch.from_data_list() funcs\r\n",
    "- CustomDataLoader is super simple, the main logic would be in CustomCollater which defines the collate() func for the DataLoader\r\n",
    "<br/><br/>\r\n",
    "- All I need to do is create a DataLoader (which I have), then overwrite the collate() and \r\n",
    "\r\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "dict_keys(['x', 'edge_index', 'edge_attr', 'y', 'pos', 'normal', 'face', 'idx'])"
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_list[0].__dict__.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch_geometric.data import Data, Batch\r\n",
    "from collections.abc import Mapping, Sequence\r\n",
    "\r\n",
    "\r\n",
    "class TSGenBatch(TSGenData): # Data\r\n",
    "\r\n",
    "    def __init__(self, batch = None, ptr = None, **kwargs):\r\n",
    "        super(Batch, self).__init__(**kwargs)\r\n",
    "\r\n",
    "        for key, item in kwargs.items():\r\n",
    "            if key == 'num_nodes':\r\n",
    "                self.__num_nodes__ = item\r\n",
    "            else:\r\n",
    "                self[key] = item\r\n",
    "        \r\n",
    "        self.batch = batch\r\n",
    "        self.ptr = ptr\r\n",
    "        self.__data_class__ = TSGenData # Data\r\n",
    "        self.__slices__ = None\r\n",
    "        self.__cumsum__ = None\r\n",
    "        self.__cat_dims__ = None\r\n",
    "        self.__num_nodes_list__ = None\r\n",
    "        self.__num_graphs__ = None\r\n",
    "    \r\n",
    "    @classmethod\r\n",
    "    def from_data_list(cls, data_list, follow_batch = [], exclude_keys = []):\r\n",
    "        # construct batch from TSGenData objects\r\n",
    "        \r\n",
    "        # get relevant graph keys\r\n",
    "        keys = list(set(data_list[0].keys) - set(exclude_keys))\r\n",
    "        assert 'batch' not in keys and 'ptr' not in keys\r\n",
    "\r\n",
    "        batch = cls()\r\n",
    "        for key in data_list[0].__dict__.keys():\r\n",
    "            # no batch for those intrinsic class fs\r\n",
    "            if key[:2] != '__' and key[-2:] != '__':\r\n",
    "                batch[key] = None\r\n",
    "            \r\n",
    "        batch.__num_graphs__ = len(data_list)\r\n",
    "        batch.__data_class__ = data_list[0].__class__\r\n",
    "        # init all keys for the batch\r\n",
    "        for key in keys + ['batch']:\r\n",
    "            batch[key] = []\r\n",
    "        batch['ptr'] = [0] # pointer to this batch\r\n",
    "\r\n",
    "        device = None\r\n",
    "        slices = {key: [0] for key in keys}\r\n",
    "        cumsum = {key: [0] for key in keys}\r\n",
    "        cat_dims = {}\r\n",
    "        num_nodes_list = []\r\n",
    "        for i, data in enumerate(data_list):\r\n",
    "            for key in keys:\r\n",
    "                item = data[key]\r\n",
    "\r\n",
    "                # increase values by cumsum value\r\n",
    "                cum = cumsum[key][-1]\r\n",
    "                \r\n",
    "\r\n",
    "\r\n",
    "\r\n",
    "class TSGenCollater(object):\r\n",
    "\r\n",
    "    def __init__(self, follow_batch, exclude_keys):\r\n",
    "        self.follow_batch = follow_batch\r\n",
    "        self.exclude_keys = exclude_keys\r\n",
    "    \r\n",
    "    def collate(self, batch):\r\n",
    "        # dgl: collate(self, items): items is list of data points or tuples; elems in list same length\r\n",
    "        # pyg: collate(self, batch)\r\n",
    "        elem = batch[0]\r\n",
    "        if isinstance(elem, TSGenData):\r\n",
    "            return Batch.from_data_list(batch, self.follow_batch, self.exclude_keys)\r\n",
    "        if isinstance(elem, Data):\r\n",
    "            return Batch.from_data_list(batch, self.follow_batch, self.exclude_keys)\r\n",
    "        elif isinstance(elem, torch.Tensor):\r\n",
    "            return default_collate(batch)\r\n",
    "        elif isinstance(elem, float):\r\n",
    "            return torch.tensor(batch, dtype=torch.float)\r\n",
    "        elif isinstance(elem, int):\r\n",
    "            return torch.tensor(batch)\r\n",
    "        elif isinstance(elem, str):\r\n",
    "            return batch\r\n",
    "        elif isinstance(elem, Mapping):\r\n",
    "            return {key: self.collate([d[key] for d in batch]) for key in elem}\r\n",
    "        elif isinstance(elem, tuple) and hasattr(elem, '_fields'):\r\n",
    "            return type(elem)(*(self.collate(samples) for samples in zip(*batch)))\r\n",
    "        elif isinstance(elem, Sequence) and not isinstance(elem, str):\r\n",
    "            return [self.collate(samples) for ssamples in zip(*batch)]\r\n",
    "\r\n",
    "        raise TypeError('DataLoader found invalid type: {}'.format(type(elem)))\r\n",
    "\r\n",
    "    def __call__(self, batch):\r\n",
    "        return self.collate(batch)\r\n",
    "\r\n",
    "\r\n",
    "class TSGenDataLoader(torch.utils.data.DataLoader):\r\n",
    "\r\n",
    "    def __init__(self, dataset, batch_size = 1, shuffle = False, \\\r\n",
    "        follow_batch = [], exclude_keys = [], **kwargs):\r\n",
    "\r\n",
    "        if \"collate_fn\" in kwargs:\r\n",
    "            del kwargs[\"collate_fn\"]\r\n",
    "        \r\n",
    "        self.follow_batch = follow_batch\r\n",
    "        self.exclude_keys = exclude_keys\r\n",
    "\r\n",
    "        super(TSGenDataLoader, self).__init__(dataset, batch_size, shuffle, \\\r\n",
    "            collate_fn = TSGenCollater(follow_batch, exclude_keys), **kwargs)\r\n",
    "\r\n",
    "\r\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Collate function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\r\n",
    "\r\n",
    "# specific collate_fn in DataLoader\r\n",
    "\r\n",
    "def collate_fn(batch):\r\n",
    "\r\n",
    "    batch = {key: batch_stack([graph[key] for graph in batch]) for key in batch[0].keys()}\r\n",
    "    batch = {key: drop_z}\r\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.6.13 64-bit (conda)",
   "name": "python3613jvsc74a57bd0f4671ad35fdc0609fa675edcd17de5b3092cb55d03f1d9670a78611a41fb18f3"
  },
  "language_info": {
   "name": "python",
   "version": ""
  },
  "orig_nbformat": 2
 },
 "nbformat": 4,
 "nbformat_minor": 2
}