{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Manual data processing if issues"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy.core.fromnumeric import product\r\n",
    "from scipy.sparse import data\r\n",
    "import torch\r\n",
    "import torch.nn.functional as F\r\n",
    "from torch_scatter import scatter\r\n",
    "from torch_geometric.data import InMemoryDataset, DataLoader # , Data\r\n",
    "from torch_geometric.data.data import Data\r\n",
    "from rdkit import Chem\r\n",
    "from rdkit.Chem.rdchem import HybridizationType\r\n",
    "from rdkit.Chem.rdchem import BondType as BT\r\n",
    "from tqdm import tqdm\r\n",
    "\r\n",
    "def process_geometry_file(geometry_file, list = None):\r\n",
    "    \"\"\" Code mostly lifted from QM9 dataset creation https://pytorch-geometric.readthedocs.io/en/latest/_modules/torch_geometric/datasets/qm9.html \r\n",
    "        Transforms molecules to their atom features and adjacency lists.\r\n",
    "    \"\"\"\r\n",
    "    types = {'H': 0, 'C': 1, 'N': 2, 'O': 3, 'F': 4}\r\n",
    "    bonds = {BT.SINGLE: 0, BT.DOUBLE: 1, BT.TRIPLE: 2, BT.AROMATIC: 3}\r\n",
    "    limit = 100\r\n",
    "\r\n",
    "    data_list = list if list else []\r\n",
    "    full_path = r'data' + geometry_file\r\n",
    "    geometries = Chem.SDMolSupplier(full_path, removeHs=False, sanitize=False)\r\n",
    "\r\n",
    "    # get atom and edge features for each geometry\r\n",
    "    for i, mol in enumerate(tqdm(geometries)):\r\n",
    "\r\n",
    "        # temp soln cos of split edge memory issues\r\n",
    "        if i == limit:\r\n",
    "            break\r\n",
    "        \r\n",
    "        N = mol.GetNumAtoms()\r\n",
    "        # get atom positions as matrix w shape [num_nodes, num_dimensions] = [num_atoms, 3]\r\n",
    "        atom_data = geometries.GetItemText(i).split('\\n')[4:4 + N] \r\n",
    "        atom_positions = [[float(x) for x in line.split()[:3]] for line in atom_data]\r\n",
    "        atom_positions = torch.tensor(atom_positions, dtype=torch.float)\r\n",
    "        # all the features\r\n",
    "        type_idx = []\r\n",
    "        atomic_number = []\r\n",
    "        aromatic = []\r\n",
    "        sp = []\r\n",
    "        sp2 = []\r\n",
    "        sp3 = []\r\n",
    "        num_hs = []\r\n",
    "\r\n",
    "        # atom/node features\r\n",
    "        for atom in mol.GetAtoms():\r\n",
    "            type_idx.append(types[atom.GetSymbol()])\r\n",
    "            atomic_number.append(atom.GetAtomicNum())\r\n",
    "            aromatic.append(1 if atom.GetIsAromatic() else 0)\r\n",
    "            hybridisation = atom.GetHybridization()\r\n",
    "            sp.append(1 if hybridisation == HybridizationType.SP else 0)\r\n",
    "            sp2.append(1 if hybridisation == HybridizationType.SP2 else 0)\r\n",
    "            sp3.append(1 if hybridisation == HybridizationType.SP3 else 0)\r\n",
    "            # !!! should do the features that lucky does: whether bonded, 3d_rbf\r\n",
    "\r\n",
    "        # bond/edge features\r\n",
    "        row, col, edge_type = [], [], []\r\n",
    "        for bond in mol.GetBonds(): \r\n",
    "            start, end = bond.GetBeginAtomIdx(), bond.GetEndAtomIdx()\r\n",
    "            row += [start, end]\r\n",
    "            col += [end, start]\r\n",
    "            # edge type for each bond type; *2 because both ways\r\n",
    "            edge_type += 2 * [bonds[bond.GetBondType()]]\r\n",
    "        # edge_index is graph connectivity in COO format with shape [2, num_edges]\r\n",
    "        edge_index = torch.tensor([row, col], dtype=torch.long)\r\n",
    "        edge_type = torch.tensor(edge_type, dtype=torch.long)\r\n",
    "        # edge_attr is edge feature matrix with shape [num_edges, num_edge_features]\r\n",
    "        edge_attr = F.one_hot(edge_type, num_classes=len(bonds)).to(torch.float) \r\n",
    "\r\n",
    "        # order edges based on combined ascending order\r\n",
    "        perm = (edge_index[0] * N + edge_index[1]).argsort() # TODO\r\n",
    "        edge_index = edge_index[:, perm]\r\n",
    "        edge_type = edge_type[perm]\r\n",
    "        edge_attr = edge_attr[perm]\r\n",
    "\r\n",
    "        row, col = edge_index\r\n",
    "        z = torch.tensor(atomic_number, dtype=torch.long)\r\n",
    "        hs = (z == 1).to(torch.float) # hydrogens\r\n",
    "        num_hs = scatter(hs[row], col, dim_size=N).tolist() # scatter helps with one-hot\r\n",
    "        \r\n",
    "        x1 = F.one_hot(torch.tensor(type_idx), num_classes=len(types))\r\n",
    "        x2 = torch.tensor([atomic_number, aromatic, sp, sp2, sp3, num_hs], dtype=torch.float).t().contiguous()\r\n",
    "        x = torch.cat([x1.to(torch.float), x2], dim=-1)\r\n",
    "\r\n",
    "        data = Data(x=x, z=z, pos=atom_positions, edge_index=edge_index, edge_attr=edge_attr, idx=i)\r\n",
    "        \r\n",
    "        data_list.append(data)\r\n",
    "\r\n",
    "    return data_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|▏         | 100/6739 [00:00<00:23, 286.92it/s]\n",
      " 12%|█▏        | 100/842 [00:00<00:02, 268.14it/s]\n",
      "  1%|▏         | 100/6739 [00:00<00:16, 414.71it/s]\n",
      " 12%|█▏        | 100/842 [00:00<00:01, 404.30it/s]\n",
      "  1%|▏         | 100/6739 [00:00<00:12, 548.55it/s]\n",
      " 12%|█▏        | 100/842 [00:00<00:02, 314.45it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'torch_geometric.data.data.Data'> <class 'torch_geometric.data.data.Data'> <class 'torch_geometric.data.data.Data'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# concat train r and test r\r\n",
    "reactants = []\r\n",
    "reactants = process_geometry_file('/raw/train_reactants.sdf', reactants)\r\n",
    "reactants = process_geometry_file('/raw/test_reactants.sdf', reactants)\r\n",
    "\r\n",
    "# concat train ts and test ts\r\n",
    "ts = []\r\n",
    "ts = process_geometry_file('/raw/train_ts.sdf', ts)\r\n",
    "ts = process_geometry_file('/raw/test_ts.sdf', ts) \r\n",
    "\r\n",
    "# concat train p and test p\r\n",
    "products = []\r\n",
    "products = process_geometry_file('/raw/train_products.sdf', products)\r\n",
    "products = process_geometry_file('/raw/test_products.sdf', products) \r\n",
    "\r\n",
    "assert len(reactants) == len(ts) == len(products)\r\n",
    "\r\n",
    "print(type(reactants[0]), type(ts[0]), type(products[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ReactionTriple(Data):\r\n",
    "    def __init__(self, r = None, ts = None, p = None):\r\n",
    "        super(ReactionTriple, self).__init__()\r\n",
    "        self.r = r\r\n",
    "        self.ts = ts\r\n",
    "        self.p = p\r\n",
    "\r\n",
    "    def __inc__(self, key, value):\r\n",
    "        if key == 'r':\r\n",
    "            return self.r.edge_index.size(0)\r\n",
    "        elif key == 'ts':\r\n",
    "            return self.ts.edge_index.size(0)\r\n",
    "        elif key == 'p':\r\n",
    "            return self.p.edge_index.size(0)\r\n",
    "        else:\r\n",
    "            return super().__inc__(key, value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "rxns = []\r\n",
    "for rxn_id in range(len(reactants)):\r\n",
    "    rxn = ReactionTriple(reactants[rxn_id], ts[rxn_id], products[rxn_id])\r\n",
    "    rxns.append(rxn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Normal data processing from files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\r\n",
    "import torch.nn as nn\r\n",
    "from torch_geometric.nn import GCNConv, GAE\r\n",
    "from torch_geometric.data import DataLoader\r\n",
    "from ts_vae.data_processors.new_pyg_processor import ReactionDataset\r\n",
    "from ts_vae.gae import GAE, MolEncoder, InnerProductDecoder\r\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "rxns = ReactionDataset(r'data')\r\n",
    "\r\n",
    "num_rxns = len(rxns)\r\n",
    "train_ratio = 0.8\r\n",
    "num_train = int(np.floor(train_ratio * num_rxns))\r\n",
    "\r\n",
    "train_loader = DataLoader(rxns[: num_train], batch_size = 3, follow_batch = ['r', 'p'])\r\n",
    "test_loader = DataLoader(rxns[num_train:], batch_size = 3, follow_batch = ['r', 'p'])\r\n",
    "\r\n",
    "# batch = next(iter(train_loader))\r\n",
    "# batch.p\r\n",
    "# batch.r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "def edge2adj(z, edge_index, sigmoid = True):\r\n",
    "    value = (z[edge_index[0]] * z[edge_index[1]]).sum(dim = 1)\r\n",
    "    return torch.sigmoid(value) if sigmoid else value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch_geometric.utils import to_dense_adj\r\n",
    "\r\n",
    "node_fs = mol_graph.x\r\n",
    "edge_index = mol_graph.edge_index\r\n",
    "edge_attr = mol_graph.edge_attr\r\n",
    "n_nodes = len(mol_graph.z)\r\n",
    "latent_dim = 3\r\n",
    "\r\n",
    "max_num_nodes = 21\r\n",
    "\r\n",
    "adj = to_dense_adj(edge_index, edge_attr = edge_attr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reconstruction loss on adj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_gae(gae, opt, x, train_pos_edge_index):\r\n",
    "    gae.train()\r\n",
    "    opt.zero_grad()\r\n",
    "    print(\"train x shape: \", x.shape)\r\n",
    "    z = gae.encode(x, train_pos_edge_index)\r\n",
    "    print(\"train z shape: \", z.shape)\r\n",
    "    loss = gae.recon_loss(z, train_pos_edge_index)\r\n",
    "    loss.backward()\r\n",
    "    opt.step()\r\n",
    "    return float(loss)\r\n",
    "\r\n",
    "def test_gae(gae, x, train_pos_edge_index, test_pos_edge_index, test_neg_edge_index):\r\n",
    "    gae.eval()\r\n",
    "    with torch.no_grad():\r\n",
    "        z = gae.encode(x, train_pos_edge_index)\r\n",
    "    return gae.test(z, test_pos_edge_index, test_neg_edge_index)\r\n",
    "\r\n",
    "def new_test_gae(gae, x, edge_index):\r\n",
    "    # this just does recon loss again\r\n",
    "    gae.eval()\r\n",
    "    with torch.no_grad():\r\n",
    "        print(\"test x shape: \", x.shape)\r\n",
    "        z = gae.encode(x, edge_index)\r\n",
    "        print(\"test z shape: \", z.shape)\r\n",
    "    return gae.recon_loss(z, edge_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ts_vae.data_processors.grambow_processor import ReactionDataset\r\n",
    "\r\n",
    "# model data\r\n",
    "base_path = r'data/'\r\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\r\n",
    "\r\n",
    "# reactant train data\r\n",
    "r_dataset = ReactionDataset(base_path, geo_file = 'train_r', dataset_type= 'individual') \r\n",
    "r_data = r_dataset.data\r\n",
    "r_x = r_data.x.to(device)\r\n",
    "\r\n",
    "# reactant test data\r\n",
    "test_dataset = ReactionDataset(base_path, geo_file = 'test_r', dataset_type= 'individual') \r\n",
    "test_data = test_dataset.data\r\n",
    "test_x = test_data.x.to(device)\r\n",
    "\r\n",
    "# reactant encoder\r\n",
    "r_num_node_fs = r_data.num_node_features\r\n",
    "r_latent_dim = 2\r\n",
    "r_ae = GAE(MolEncoder(r_num_node_fs, r_latent_dim))\r\n",
    "r_opt = torch.optim.Adam(r_ae.parameters(), lr = 0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train x shape:  torch.Size([395, 11])\n",
      "train z shape:  torch.Size([395, 2])\n",
      "===== Training complete with loss: 3.6079, now testing ====\n",
      "test x shape:  torch.Size([394, 11])\n",
      "test z shape:  torch.Size([394, 2])\n",
      "===== Epoch: 001, Loss: 3.4965 ===== \n",
      "\n",
      "train x shape:  torch.Size([395, 11])\n",
      "train z shape:  torch.Size([395, 2])\n",
      "===== Training complete with loss: 3.4361, now testing ====\n",
      "test x shape:  torch.Size([394, 11])\n",
      "test z shape:  torch.Size([394, 2])\n",
      "===== Epoch: 002, Loss: 3.1556 ===== \n",
      "\n",
      "train x shape:  torch.Size([395, 11])\n",
      "train z shape:  torch.Size([395, 2])\n",
      "===== Training complete with loss: 3.1816, now testing ====\n",
      "test x shape:  torch.Size([394, 11])\n",
      "test z shape:  torch.Size([394, 2])\n",
      "===== Epoch: 003, Loss: 2.9096 ===== \n",
      "\n",
      "train x shape:  torch.Size([395, 11])\n",
      "train z shape:  torch.Size([395, 2])\n",
      "===== Training complete with loss: 2.9659, now testing ====\n",
      "test x shape:  torch.Size([394, 11])\n",
      "test z shape:  torch.Size([394, 2])\n",
      "===== Epoch: 004, Loss: 2.7989 ===== \n",
      "\n",
      "train x shape:  torch.Size([395, 11])\n",
      "train z shape:  torch.Size([395, 2])\n",
      "===== Training complete with loss: 2.7081, now testing ====\n",
      "test x shape:  torch.Size([394, 11])\n",
      "test z shape:  torch.Size([394, 2])\n",
      "===== Epoch: 005, Loss: 2.5394 ===== \n",
      "\n",
      "train x shape:  torch.Size([395, 11])\n",
      "train z shape:  torch.Size([395, 2])\n",
      "===== Training complete with loss: 2.5573, now testing ====\n",
      "test x shape:  torch.Size([394, 11])\n",
      "test z shape:  torch.Size([394, 2])\n",
      "===== Epoch: 006, Loss: 2.3111 ===== \n",
      "\n",
      "train x shape:  torch.Size([395, 11])\n",
      "train z shape:  torch.Size([395, 2])\n",
      "===== Training complete with loss: 2.2536, now testing ====\n",
      "test x shape:  torch.Size([394, 11])\n",
      "test z shape:  torch.Size([394, 2])\n",
      "===== Epoch: 007, Loss: 2.1001 ===== \n",
      "\n",
      "train x shape:  torch.Size([395, 11])\n",
      "train z shape:  torch.Size([395, 2])\n",
      "===== Training complete with loss: 2.1590, now testing ====\n",
      "test x shape:  torch.Size([394, 11])\n",
      "test z shape:  torch.Size([394, 2])\n",
      "===== Epoch: 008, Loss: 1.9850 ===== \n",
      "\n",
      "train x shape:  torch.Size([395, 11])\n",
      "train z shape:  torch.Size([395, 2])\n",
      "===== Training complete with loss: 1.9918, now testing ====\n",
      "test x shape:  torch.Size([394, 11])\n",
      "test z shape:  torch.Size([394, 2])\n",
      "===== Epoch: 009, Loss: 1.8339 ===== \n",
      "\n",
      "train x shape:  torch.Size([395, 11])\n",
      "train z shape:  torch.Size([395, 2])\n",
      "===== Training complete with loss: 1.8367, now testing ====\n",
      "test x shape:  torch.Size([394, 11])\n",
      "test z shape:  torch.Size([394, 2])\n",
      "===== Epoch: 010, Loss: 1.6751 ===== \n",
      "\n"
     ]
    }
   ],
   "source": [
    "r_ae.reset_parameters()\r\n",
    "\r\n",
    "epochs = 10\r\n",
    "for epoch in range(1, epochs + 1):\r\n",
    "\r\n",
    "    # value = (z[edge_index[0]] * z[edge_index[1]]).sum(dim = 1)\r\n",
    "    loss_train = train_gae(r_ae, r_opt, r_x, r_data.edge_index)\r\n",
    "    print(\"===== Training complete with loss: {:.4f}, now testing ====\".format(loss_train))\r\n",
    "    loss_test = new_test_gae(r_ae, test_x, test_data.edge_index)\r\n",
    "    if epoch % 1 == 0:\r\n",
    "        print('===== Epoch: {:03d}, Loss: {:.4f} ===== \\n'.format(epoch, loss_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class InnerProductDecoder(nn.Module):\r\n",
    "    def forward(self, z, edge_index, sigmoid = True):\r\n",
    "        value = (z[edge_index[0]] * z[edge_index[1]]).sum(dim = 1)\r\n",
    "        return torch.sigmoid(value) if sigmoid else value\r\n",
    "    \r\n",
    "    def forward_all(self, z, sigmoid = True):\r\n",
    "        \"\"\" Decode latent variables into probabilistic adj matrix. \"\"\"\r\n",
    "        adj = torch.matmul(z, z.t())\r\n",
    "        return torch.sigmoid(adj) if sigmoid else adj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "26"
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# their model \r\n",
    "# so they take their nodes, edges, edge_attr and actual adj\r\n",
    "# adj_pred, z = model(nodes, edges, edge_attr)\r\n",
    "# bce, kl = loss(adj_pred, adj_gt)\r\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "edge index:  torch.Size([26]) || edge index unsqueeze:  torch.Size([1, 26])\n",
      "i shape:  torch.Size([2, 26]) || v shape:  torch.Size([26]) || num nodes:  13\n"
     ]
    },
    {
     "data": {
      "text/plain": "tensor(indices=tensor([[ 0,  0,  1,  1,  1,  1,  2,  2,  2,  2,  3,  3,  3,  3,\n                         4,  4,  4,  4,  5,  6,  7,  8,  9, 10, 11, 12],\n                       [ 1,  5,  0,  2,  4,  6,  1,  3,  7,  8,  2,  4,  9, 10,\n                         1,  3, 11, 12,  0,  1,  2,  2,  3,  3,  4,  4]]),\n       values=tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.]),\n       size=(13, 13), nnz=26, layout=torch.sparse_coo)"
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "i = torch.cat([edge_index[0].unsqueeze(0), edge_index[1].unsqueeze(0)])\r\n",
    "v = torch.ones(i.size(1))\r\n",
    "\r\n",
    "print(\"edge index: \", edge_index[0].shape, \"|| edge index unsqueeze: \", edge_index[0].unsqueeze(0).shape)\r\n",
    "print(\"i shape: \", i.shape, \"|| v shape: \", v.shape, \"|| num nodes: \", n_nodes)\r\n",
    "\r\n",
    "#i = torch.cat([edges[0].unsqueeze(0), edges[1].unsqueeze(0)])\r\n",
    "#v = torch.ones(i.size(1))\r\n",
    "#adj_dense = torch.sparse.FloatTensor(i, v, torch.Size([n_nodes, n_nodes])).to_dense()\r\n",
    "# i.size(1)\r\n",
    "\r\n",
    "torch.sparse.FloatTensor(i, v, torch.Size([n_nodes, n_nodes]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch_geometric.utils import to_dense_adj\r\n",
    "\r\n",
    "node_fs = mol_graph.x\r\n",
    "edge_index = mol_graph.edge_index\r\n",
    "edge_attr = mol_graph.edge_attr\r\n",
    "num_nodes = len(mol_graph.z)\r\n",
    "latent_dim = 3\r\n",
    "max_num_nodes = 21\r\n",
    "\r\n",
    "def sparse_to_dense_adj(num_nodes, edge_index):\r\n",
    "    # edge_index is sparse_adj matrix (given in coo format for graph connectivity)\r\n",
    "    sparse_adj = torch.cat([edge_index[0].unsqueeze(0), edge_index[1].unsqueeze(0)])\r\n",
    "    # the values we put in at each tuple; that's why length of sparse_adj\r\n",
    "    ones = torch.ones(sparse_adj.size(1)) \r\n",
    "    # FloatTensor() creates sparse coo tensor in torch format, then to_dense()\r\n",
    "    dense_adj = torch.sparse.FloatTensor(sparse_adj, ones, torch.Size([num_nodes, num_nodes])).to_dense() # to_dense adds the zeroes needed\r\n",
    "    return dense_adj\r\n",
    "\r\n",
    "\r\n",
    "\r\n",
    "adj_egnn = sparse_to_dense_adj(num_nodes, edge_index)\r\n",
    "# with edge_attr, we get a [1, num_nodes, num_nodes] for each edge_type\r\n",
    "adj_pyg = to_dense_adj(edge_index, edge_attr = edge_attr, max_num_nodes = num_nodes)\r\n",
    "\r\n",
    "# get_dense_graph(): returns self.nodes, self.edges_dense, self.edge_attr_dense, self.adj\r\n",
    "# adj = sparse2dense(n_nodes, self.edges); adjust for loops\r\n",
    "\r\n",
    "# compare sparse2dense (egnn) vs to_dense_adj (pyg)\r\n",
    "\r\n",
    "# gcn = GCNConv(num_nodes, latent_dim)\r\n",
    "# z = gcn(node_fs, edge_index)\r\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "torch.Size([13, 13])"
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "adj_egnn.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "The size of tensor a (4) must match the size of tensor b (13) at non-singleton dimension 3",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-154-3c7d8079f191>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;33m(\u001b[0m\u001b[0madj_pyg\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0madj_egnn\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mall\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m: The size of tensor a (4) must match the size of tensor b (13) at non-singleton dimension 3"
     ]
    }
   ],
   "source": [
    "(adj_pyg == adj_egnn).all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "tensor([[0., 1., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.],\n        [1., 0., 1., 0., 1., 0., 1., 0., 0., 0., 0., 0., 0.],\n        [0., 1., 0., 1., 0., 0., 0., 1., 1., 0., 0., 0., 0.],\n        [0., 0., 1., 0., 1., 0., 0., 0., 0., 1., 1., 0., 0.],\n        [0., 1., 0., 1., 0., 0., 0., 0., 0., 0., 0., 1., 1.],\n        [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n        [0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n        [0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n        [0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n        [0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n        [0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n        [0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n        [0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.]])"
     },
     "execution_count": 160,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "adj_egnn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "tensor([[0.0877, 0.9180, 0.5504, 0.4741, 0.6862],\n        [0.6980, 0.5273, 0.1610, 0.9068, 0.8301]])"
     },
     "execution_count": 170,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t = torch.rand(2, 5)\r\n",
    "# b = t.view(2, 8)\r\n",
    "t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "tensor([[0.0877, 0.9180, 0.5504, 0.4741, 0.6862, 0.6980, 0.5273, 0.1610, 0.9068,\n         0.8301]])"
     },
     "execution_count": 172,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t.view(1, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "tensor([[0., 1., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.],\n        [1., 0., 1., 0., 1., 0., 1., 0., 0., 0., 0., 0., 0.],\n        [0., 1., 0., 1., 0., 0., 0., 1., 1., 0., 0., 0., 0.],\n        [0., 0., 1., 0., 1., 0., 0., 0., 0., 1., 1., 0., 0.],\n        [0., 1., 0., 1., 0., 0., 0., 0., 0., 0., 0., 1., 1.],\n        [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n        [0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n        [0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n        [0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n        [0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n        [0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n        [0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n        [0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.]])"
     },
     "execution_count": 161,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# adj_pred = adj_pred * (1 - torch.eye(num_nodes).to(self.device)) # removes self_loops\r\n",
    "\r\n",
    "# (1 - torch.eye(num_nodes)) gives [num_nodes, num_nodes] with all 1s except 0 on diag\r\n",
    "# * is hadamard product\r\n",
    "adj_egnn * (1 - torch.eye(13))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "h = 0\n"
     ]
    }
   ],
   "source": [
    "h = 0\r\n",
    "print(f'h = {h}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Data(edge_attr=[30, 4], edge_index=[2, 30], idx=48, pos=[15, 3], x=[15, 11], z=[15]), Data(edge_attr=[26, 4], edge_index=[2, 26], idx=49, pos=[14, 3], x=[14, 11], z=[14])]\n",
      "[Data(edge_attr=[30, 4], edge_index=[2, 30], idx=50, pos=[14, 3], x=[14, 11], z=[14]), Data(edge_attr=[38, 4], edge_index=[2, 38], idx=51, pos=[17, 3], x=[17, 11], z=[17])]\n",
      "[Data(edge_attr=[32, 4], edge_index=[2, 32], idx=52, pos=[15, 3], x=[15, 11], z=[15]), Data(edge_attr=[34, 4], edge_index=[2, 34], idx=53, pos=[17, 3], x=[17, 11], z=[17])]\n",
      "[Data(edge_attr=[30, 4], edge_index=[2, 30], idx=54, pos=[13, 3], x=[13, 11], z=[13]), Data(edge_attr=[36, 4], edge_index=[2, 36], idx=55, pos=[17, 3], x=[17, 11], z=[17])]\n",
      "[Data(edge_attr=[20, 4], edge_index=[2, 20], idx=56, pos=[10, 3], x=[10, 11], z=[10]), Data(edge_attr=[28, 4], edge_index=[2, 28], idx=57, pos=[15, 3], x=[15, 11], z=[15])]\n",
      "[Data(edge_attr=[26, 4], edge_index=[2, 26], idx=58, pos=[13, 3], x=[13, 11], z=[13]), Data(edge_attr=[30, 4], edge_index=[2, 30], idx=59, pos=[14, 3], x=[14, 11], z=[14])]\n"
     ]
    }
   ],
   "source": [
    "for batch_id, rxn_batch in enumerate(test_loader):\r\n",
    "    \r\n",
    "    reactants = rxn_batch.r\r\n",
    "    print(reactants)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "Data(edge_attr=[28, 4], edge_index=[2, 28], idx=0, pos=[15, 3], x=[15, 11], z=[15])"
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def train(epoch, loader):\r\n",
    "\r\n",
    "    model.train()\r\n",
    "\r\n",
    "    train_dict = {'epoch': epoch, 'loss': 0, 'bce': 0, 'adj_err': 0, 'coord_reg': 0}\r\n",
    "\r\n",
    "    # want to create b\r\n",
    "    for batch_id, rxn_batch in enumerate(loader):\r\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# coords always same, maybe node and edge features too? need to pad adj matrix\r\n",
    "\r\n",
    "# dataset dims\r\n",
    "elements = \"HCNO\"\r\n",
    "num_elements = len(elements)\r\n",
    "max_n_atoms = max([r.GetNumAtoms() for r,ts,p in data])\r\n",
    "num_coords = 3\r\n",
    "num_bond_fs\r\n",
    "\r\n",
    "# want to pad exist features\r\n",
    "\r\n",
    "def prepare_batch(batch_mols):\r\n",
    "\r\n",
    "    # initialise batch\r\n",
    "    batch_size = len(batch_mols)\r\n",
    "    atom_fs = torch.zeros((batch_size, max_n_atoms, num_elements + 1), dtype = torch.float32) # num_atoms, max_num_atoms, \r\n",
    "    bond_fs = torch.zeros((batch_size, max_n_atoms, max_n_atoms, num_bond_fs), dtype = torch.float32)\r\n",
    "    sizes = torch.zeros(batch_size, dtype = torch.float32)\r\n",
    "    coords = torch.zeros((batch_size, max_size, num_coords), dtype = torch.float32)\r\n",
    "    \r\n",
    "    pass\r\n",
    "\r\n",
    "def pad_sequence(sequences: List[torch.Tensor], max_length: int, padding_value=0) -> torch.Tensor:\r\n",
    "    # assuming trailing dimensions and type of all the Tensors\r\n",
    "    # in sequences are same and fetching those from sequences[0]\r\n",
    "    max_size = sequences[0].size()\r\n",
    "    trailing_dims = max_size[1:]\r\n",
    "    out_dims = (len(sequences), max_length) + trailing_dims\r\n",
    "\r\n",
    "    out_tensor = sequences[0].data.new(*out_dims).fill_(padding_value)  # type: ignore\r\n",
    "    for i, tensor in enumerate(sequences):\r\n",
    "        length = tensor.size(0)\r\n",
    "        # use index notation to prevent duplicate references to the tensor\r\n",
    "        out_tensor[i, :length, ...] = tensor\r\n",
    "\r\n",
    "    return out_tensor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# have to convert the training scheme: no more edge sampling and now use batches\r\n",
    "# TODO: create data, opt, model; data and model to device\r\n",
    "\r\n",
    "# simple R->R GAE, then build up\r\n",
    "def train_gae(gae, opt, loader):\r\n",
    "    # singular batch train loop\r\n",
    "\r\n",
    "    model.train() # set flags\r\n",
    "\r\n",
    "    batch_loss = 0\r\n",
    "\r\n",
    "    # one iteration over different batches\r\n",
    "    for i, rxn_batch in enumerate(loader):\r\n",
    "        \r\n",
    "        reactants = rxn_batch.r\r\n",
    "        # pad mols for batch/maybe just pad all with max_num_atoms\r\n",
    "        \r\n",
    "        # zero gradients\r\n",
    "        opt.zero_grad() \r\n",
    "\r\n",
    "        # encode reactant batch and calculate loss\r\n",
    "        z_r = gae.encode(reactants)\r\n",
    "        loss = gae.recon_loss(z_r)\r\n",
    "        \r\n",
    "        # modify gradients\r\n",
    "        loss.backward()\r\n",
    "        opt.step()\r\n",
    "        \r\n",
    "        # add batch loss\r\n",
    "        batch_loss += loss.item()\r\n",
    "\r\n",
    "        print(\"Loss: {:.3f}\".format(loss.item() / len(reactants)))\r\n",
    "\r\n",
    "    agg['Train_Loss'].append(batch_loss / len(loader.dataset))\r\n",
    "    print('===> Epoch: {:03d}, Train Loss: {:.4f}'.format(epoch, agg['Train_Loss'][-1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\r\n",
    "# my train has automatic train-test edge split but this is what i was going for before [mmvae]\r\n",
    "def train(epoch, agg):\r\n",
    "    model.train()\r\n",
    "    b_loss = 0\r\n",
    "    for i, dataT in enumerate(train_loader):\r\n",
    "        data = unpack_data(dataT, device=device)\r\n",
    "        optimizer.zero_grad()\r\n",
    "        loss = - objective(model, data, K=args.K)\r\n",
    "        loss.backward()\r\n",
    "        optimizer.step()\r\n",
    "        b_loss += loss.item()\r\n",
    "        if args.print_freq > 0 and i % args.print_freq == 0:\r\n",
    "            print(\"iteration {:04d}: loss: {:6.3f}\".format(i, loss.item() / args.batch_size))\r\n",
    "    agg['train_loss'].append(b_loss / len(train_loader.dataset))\r\n",
    "    print('====> Epoch: {:03d} Train loss: {:.4f}'.format(epoch, agg['train_loss'][-1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_gae(gae, opt, x, train_pos_edge_index):\r\n",
    "    gae.train()\r\n",
    "    opt.zero_grad()\r\n",
    "    z = gae.encode(x, train_pos_edge_index)\r\n",
    "    loss = gae.recon_loss(z, train_pos_edge_index)\r\n",
    "    loss.backward()\r\n",
    "    opt.step()\r\n",
    "    return float(loss)\r\n",
    "\r\n",
    "def test_gae(gae, x, train_pos_edge_index, test_pos_edge_index, test_neg_edge_index):\r\n",
    "    gae.eval()\r\n",
    "    with torch.no_grad():\r\n",
    "        z = gae.encode(x, train_pos_edge_index)\r\n",
    "    return gae.test(z, test_pos_edge_index, test_neg_edge_index)\r\n",
    "\r\n",
    "r_ae.reset_parameters()\r\n",
    "\r\n",
    "epochs = 100\r\n",
    "for epoch in range(1, epochs + 1):\r\n",
    "    loss = train_gae(r_ae, r_opt, r_x, r_data.train_pos_edge_index)\r\n",
    "    auc, ap = test_gae(r_ae, r_x, r_data.train_pos_edge_index, r_data.test_pos_edge_index, r_data.test_neg_edge_index)\r\n",
    "    if epoch % 10 == 0:\r\n",
    "        print('Epoch: {:03d}, AUC: {:.4f}, AP: {:.4f}'.format(epoch, auc, ap))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# my train has automatic train-test edge split but this is what i was going for before [mmvae]\r\n",
    "def train(epoch, agg):\r\n",
    "    model.train()\r\n",
    "    b_loss = 0\r\n",
    "    for i, dataT in enumerate(train_loader):\r\n",
    "        data = unpack_data(dataT, device=device)\r\n",
    "        optimizer.zero_grad()\r\n",
    "        loss = - objective(model, data, K=args.K)\r\n",
    "        loss.backward()\r\n",
    "        optimizer.step()\r\n",
    "        b_loss += loss.item()\r\n",
    "        if args.print_freq > 0 and i % args.print_freq == 0:\r\n",
    "            print(\"iteration {:04d}: loss: {:6.3f}\".format(i, loss.item() / args.batch_size))\r\n",
    "    agg['train_loss'].append(b_loss / len(train_loader.dataset))\r\n",
    "    print('====> Epoch: {:03d} Train loss: {:.4f}'.format(epoch, agg['train_loss'][-1]))\r\n",
    "\r\n",
    "\r\n",
    "# Loop over epochs\r\n",
    "for epoch in range(max_epochs):\r\n",
    "    # Training\r\n",
    "    for batch, labels in loader:\r\n",
    "        # Transfer to GPU if available\r\n",
    "        batch, labels = batch.to(device), labels.to(device)\r\n",
    "        # Model computations\r\n",
    "        [...]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.6.13 64-bit (conda)",
   "name": "3d-rdkit"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  },
  "orig_nbformat": 2
 },
 "nbformat": 4,
 "nbformat_minor": 2
}