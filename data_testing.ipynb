{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Manual data processing if issues"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy.core.fromnumeric import product\r\n",
    "from scipy.sparse import data\r\n",
    "import torch\r\n",
    "import torch.nn.functional as F\r\n",
    "from torch_scatter import scatter\r\n",
    "from torch_geometric.data import InMemoryDataset, DataLoader # , Data\r\n",
    "from torch_geometric.data.data import Data\r\n",
    "from rdkit import Chem\r\n",
    "from rdkit.Chem.rdchem import HybridizationType\r\n",
    "from rdkit.Chem.rdchem import BondType as BT\r\n",
    "from tqdm import tqdm\r\n",
    "\r\n",
    "def process_geometry_file(geometry_file, list = None):\r\n",
    "    \"\"\" Code mostly lifted from QM9 dataset creation https://pytorch-geometric.readthedocs.io/en/latest/_modules/torch_geometric/datasets/qm9.html \r\n",
    "        Transforms molecules to their atom features and adjacency lists.\r\n",
    "    \"\"\"\r\n",
    "    types = {'H': 0, 'C': 1, 'N': 2, 'O': 3, 'F': 4}\r\n",
    "    bonds = {BT.SINGLE: 0, BT.DOUBLE: 1, BT.TRIPLE: 2, BT.AROMATIC: 3}\r\n",
    "    limit = 100\r\n",
    "\r\n",
    "    data_list = list if list else []\r\n",
    "    full_path = r'data' + geometry_file\r\n",
    "    geometries = Chem.SDMolSupplier(full_path, removeHs=False, sanitize=False)\r\n",
    "\r\n",
    "    # get atom and edge features for each geometry\r\n",
    "    for i, mol in enumerate(tqdm(geometries)):\r\n",
    "\r\n",
    "        # temp soln cos of split edge memory issues\r\n",
    "        if i == limit:\r\n",
    "            break\r\n",
    "        \r\n",
    "        N = mol.GetNumAtoms()\r\n",
    "        # get atom positions as matrix w shape [num_nodes, num_dimensions] = [num_atoms, 3]\r\n",
    "        atom_data = geometries.GetItemText(i).split('\\n')[4:4 + N] \r\n",
    "        atom_positions = [[float(x) for x in line.split()[:3]] for line in atom_data]\r\n",
    "        atom_positions = torch.tensor(atom_positions, dtype=torch.float)\r\n",
    "        # all the features\r\n",
    "        type_idx = []\r\n",
    "        atomic_number = []\r\n",
    "        aromatic = []\r\n",
    "        sp = []\r\n",
    "        sp2 = []\r\n",
    "        sp3 = []\r\n",
    "        num_hs = []\r\n",
    "\r\n",
    "        # atom/node features\r\n",
    "        for atom in mol.GetAtoms():\r\n",
    "            type_idx.append(types[atom.GetSymbol()])\r\n",
    "            atomic_number.append(atom.GetAtomicNum())\r\n",
    "            aromatic.append(1 if atom.GetIsAromatic() else 0)\r\n",
    "            hybridisation = atom.GetHybridization()\r\n",
    "            sp.append(1 if hybridisation == HybridizationType.SP else 0)\r\n",
    "            sp2.append(1 if hybridisation == HybridizationType.SP2 else 0)\r\n",
    "            sp3.append(1 if hybridisation == HybridizationType.SP3 else 0)\r\n",
    "            # !!! should do the features that lucky does: whether bonded, 3d_rbf\r\n",
    "\r\n",
    "        # bond/edge features\r\n",
    "        row, col, edge_type = [], [], []\r\n",
    "        for bond in mol.GetBonds(): \r\n",
    "            start, end = bond.GetBeginAtomIdx(), bond.GetEndAtomIdx()\r\n",
    "            row += [start, end]\r\n",
    "            col += [end, start]\r\n",
    "            # edge type for each bond type; *2 because both ways\r\n",
    "            edge_type += 2 * [bonds[bond.GetBondType()]]\r\n",
    "        # edge_index is graph connectivity in COO format with shape [2, num_edges]\r\n",
    "        edge_index = torch.tensor([row, col], dtype=torch.long)\r\n",
    "        edge_type = torch.tensor(edge_type, dtype=torch.long)\r\n",
    "        # edge_attr is edge feature matrix with shape [num_edges, num_edge_features]\r\n",
    "        edge_attr = F.one_hot(edge_type, num_classes=len(bonds)).to(torch.float) \r\n",
    "\r\n",
    "        # order edges based on combined ascending order\r\n",
    "        perm = (edge_index[0] * N + edge_index[1]).argsort() # TODO\r\n",
    "        edge_index = edge_index[:, perm]\r\n",
    "        edge_type = edge_type[perm]\r\n",
    "        edge_attr = edge_attr[perm]\r\n",
    "\r\n",
    "        row, col = edge_index\r\n",
    "        z = torch.tensor(atomic_number, dtype=torch.long)\r\n",
    "        hs = (z == 1).to(torch.float) # hydrogens\r\n",
    "        num_hs = scatter(hs[row], col, dim_size=N).tolist() # scatter helps with one-hot\r\n",
    "        \r\n",
    "        x1 = F.one_hot(torch.tensor(type_idx), num_classes=len(types))\r\n",
    "        x2 = torch.tensor([atomic_number, aromatic, sp, sp2, sp3, num_hs], dtype=torch.float).t().contiguous()\r\n",
    "        x = torch.cat([x1.to(torch.float), x2], dim=-1)\r\n",
    "\r\n",
    "        data = Data(x=x, z=z, pos=atom_positions, edge_index=edge_index, edge_attr=edge_attr, idx=i)\r\n",
    "        \r\n",
    "        data_list.append(data)\r\n",
    "\r\n",
    "    return data_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|▏         | 100/6739 [00:00<00:23, 286.92it/s]\n",
      " 12%|█▏        | 100/842 [00:00<00:02, 268.14it/s]\n",
      "  1%|▏         | 100/6739 [00:00<00:16, 414.71it/s]\n",
      " 12%|█▏        | 100/842 [00:00<00:01, 404.30it/s]\n",
      "  1%|▏         | 100/6739 [00:00<00:12, 548.55it/s]\n",
      " 12%|█▏        | 100/842 [00:00<00:02, 314.45it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'torch_geometric.data.data.Data'> <class 'torch_geometric.data.data.Data'> <class 'torch_geometric.data.data.Data'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# concat train r and test r\r\n",
    "reactants = []\r\n",
    "reactants = process_geometry_file('/raw/train_reactants.sdf', reactants)\r\n",
    "reactants = process_geometry_file('/raw/test_reactants.sdf', reactants)\r\n",
    "\r\n",
    "# concat train ts and test ts\r\n",
    "ts = []\r\n",
    "ts = process_geometry_file('/raw/train_ts.sdf', ts)\r\n",
    "ts = process_geometry_file('/raw/test_ts.sdf', ts) \r\n",
    "\r\n",
    "# concat train p and test p\r\n",
    "products = []\r\n",
    "products = process_geometry_file('/raw/train_products.sdf', products)\r\n",
    "products = process_geometry_file('/raw/test_products.sdf', products) \r\n",
    "\r\n",
    "assert len(reactants) == len(ts) == len(products)\r\n",
    "\r\n",
    "print(type(reactants[0]), type(ts[0]), type(products[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ReactionTriple(Data):\r\n",
    "    def __init__(self, r = None, ts = None, p = None):\r\n",
    "        super(ReactionTriple, self).__init__()\r\n",
    "        self.r = r\r\n",
    "        self.ts = ts\r\n",
    "        self.p = p\r\n",
    "\r\n",
    "    def __inc__(self, key, value):\r\n",
    "        if key == 'r':\r\n",
    "            return self.r.edge_index.size(0)\r\n",
    "        elif key == 'ts':\r\n",
    "            return self.ts.edge_index.size(0)\r\n",
    "        elif key == 'p':\r\n",
    "            return self.p.edge_index.size(0)\r\n",
    "        else:\r\n",
    "            return super().__inc__(key, value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "rxns = []\r\n",
    "for rxn_id in range(len(reactants)):\r\n",
    "    rxn = ReactionTriple(reactants[rxn_id], ts[rxn_id], products[rxn_id])\r\n",
    "    rxns.append(rxn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Normal data processing from files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\r\n",
    "import torch.nn as nn\r\n",
    "from torch_geometric.nn import GCNConv, GAE\r\n",
    "from torch_geometric.data import DataLoader\r\n",
    "from ts_vae.data_processors.new_pyg_processor import ReactionDataset\r\n",
    "from ts_vae.gae import GAE, MolEncoder, InnerProductDecoder\r\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "rxns = ReactionDataset(r'data')\r\n",
    "\r\n",
    "num_rxns = len(rxns)\r\n",
    "train_ratio = 0.8\r\n",
    "num_train = int(np.floor(train_ratio * num_rxns))\r\n",
    "\r\n",
    "train_loader = DataLoader(rxns[: num_train], batch_size = 2, follow_batch = ['r', 'p'])\r\n",
    "test_loader = DataLoader(rxns[num_train:], batch_size = 3, follow_batch = ['r', 'p'])\r\n",
    "\r\n",
    "# batch = next(iter(train_loader))\r\n",
    "# batch.p\r\n",
    "# batch.r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Data(edge_attr=[30, 4], edge_index=[2, 30], idx=48, pos=[15, 3], x=[15, 11], z=[15]), Data(edge_attr=[26, 4], edge_index=[2, 26], idx=49, pos=[14, 3], x=[14, 11], z=[14]), Data(edge_attr=[30, 4], edge_index=[2, 30], idx=50, pos=[14, 3], x=[14, 11], z=[14])]\n",
      "[Data(edge_attr=[38, 4], edge_index=[2, 38], idx=51, pos=[17, 3], x=[17, 11], z=[17]), Data(edge_attr=[32, 4], edge_index=[2, 32], idx=52, pos=[15, 3], x=[15, 11], z=[15]), Data(edge_attr=[34, 4], edge_index=[2, 34], idx=53, pos=[17, 3], x=[17, 11], z=[17])]\n"
     ]
    }
   ],
   "source": [
    "for i, b in enumerate(test_loader):\r\n",
    "    if i < 2:\r\n",
    "        print(b.r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# have to convert the training scheme: no more edge sampling and now use batches\r\n",
    "# TODO: create data, opt, model; data and model to device\r\n",
    "\r\n",
    "# simple R->R GAE, then build up\r\n",
    "\r\n",
    "def train_gae(gae, opt, loader):\r\n",
    "    # singular batch train loop\r\n",
    "\r\n",
    "    model.train() # set flags\r\n",
    "\r\n",
    "    batch_loss = 0\r\n",
    "\r\n",
    "    # one iteration over different batches\r\n",
    "    for i, rxn_batch in enumerate(loader):\r\n",
    "        reactants = rxn_batch.r\r\n",
    "        \r\n",
    "        opt.zero_grad() # zero gradients\r\n",
    "\r\n",
    "        # pad mols for batch/maybe just pad all with max_num_atoms\r\n",
    "\r\n",
    "        # encode reactant batch and calculate loss\r\n",
    "        z_r = gae.encode(reactants)\r\n",
    "        loss = gae.recon_loss(z_r)\r\n",
    "        \r\n",
    "        # modify gradients\r\n",
    "        loss.backward()\r\n",
    "        opt.step()\r\n",
    "        \r\n",
    "        return float(loss)\r\n",
    "        \r\n",
    "    \r\n",
    "    pass\r\n",
    "\r\n",
    "\r\n",
    "# my train has automatic train-test edge split but this is what i was going for before [mmvae]\r\n",
    "def train(epoch, agg):\r\n",
    "    model.train()\r\n",
    "    b_loss = 0\r\n",
    "    for i, dataT in enumerate(train_loader):\r\n",
    "        data = unpack_data(dataT, device=device)\r\n",
    "        optimizer.zero_grad()\r\n",
    "        loss = - objective(model, data, K=args.K)\r\n",
    "        loss.backward()\r\n",
    "        optimizer.step()\r\n",
    "        b_loss += loss.item()\r\n",
    "        if args.print_freq > 0 and i % args.print_freq == 0:\r\n",
    "            print(\"iteration {:04d}: loss: {:6.3f}\".format(i, loss.item() / args.batch_size))\r\n",
    "    agg['train_loss'].append(b_loss / len(train_loader.dataset))\r\n",
    "    print('====> Epoch: {:03d} Train loss: {:.4f}'.format(epoch, agg['train_loss'][-1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_gae(gae, opt, x, train_pos_edge_index):\r\n",
    "    gae.train()\r\n",
    "    opt.zero_grad()\r\n",
    "    z = gae.encode(x, train_pos_edge_index)\r\n",
    "    loss = gae.recon_loss(z, train_pos_edge_index)\r\n",
    "    loss.backward()\r\n",
    "    opt.step()\r\n",
    "    return float(loss)\r\n",
    "\r\n",
    "def test_gae(gae, x, train_pos_edge_index, test_pos_edge_index, test_neg_edge_index):\r\n",
    "    gae.eval()\r\n",
    "    with torch.no_grad():\r\n",
    "        z = gae.encode(x, train_pos_edge_index)\r\n",
    "    return gae.test(z, test_pos_edge_index, test_neg_edge_index)\r\n",
    "\r\n",
    "r_ae.reset_parameters()\r\n",
    "\r\n",
    "epochs = 100\r\n",
    "for epoch in range(1, epochs + 1):\r\n",
    "    loss = train_gae(r_ae, r_opt, r_x, r_data.train_pos_edge_index)\r\n",
    "    auc, ap = test_gae(r_ae, r_x, r_data.train_pos_edge_index, r_data.test_pos_edge_index, r_data.test_neg_edge_index)\r\n",
    "    if epoch % 10 == 0:\r\n",
    "        print('Epoch: {:03d}, AUC: {:.4f}, AP: {:.4f}'.format(epoch, auc, ap))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# my train has automatic train-test edge split but this is what i was going for before [mmvae]\r\n",
    "def train(epoch, agg):\r\n",
    "    model.train()\r\n",
    "    b_loss = 0\r\n",
    "    for i, dataT in enumerate(train_loader):\r\n",
    "        data = unpack_data(dataT, device=device)\r\n",
    "        optimizer.zero_grad()\r\n",
    "        loss = - objective(model, data, K=args.K)\r\n",
    "        loss.backward()\r\n",
    "        optimizer.step()\r\n",
    "        b_loss += loss.item()\r\n",
    "        if args.print_freq > 0 and i % args.print_freq == 0:\r\n",
    "            print(\"iteration {:04d}: loss: {:6.3f}\".format(i, loss.item() / args.batch_size))\r\n",
    "    agg['train_loss'].append(b_loss / len(train_loader.dataset))\r\n",
    "    print('====> Epoch: {:03d} Train loss: {:.4f}'.format(epoch, agg['train_loss'][-1]))\r\n",
    "\r\n",
    "\r\n",
    "# Loop over epochs\r\n",
    "for epoch in range(max_epochs):\r\n",
    "    # Training\r\n",
    "    for batch, labels in loader:\r\n",
    "        # Transfer to GPU if available\r\n",
    "        batch, labels = batch.to(device), labels.to(device)\r\n",
    "        # Model computations\r\n",
    "        [...]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.6.13 64-bit (conda)",
   "name": "3d-rdkit"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  },
  "orig_nbformat": 2
 },
 "nbformat": 4,
 "nbformat_minor": 2
}