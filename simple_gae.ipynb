{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# atom features, bond type, graph connectivity, (x,y,z) coordinates  \r\n",
    "#   - when we encode the graph, we're doing it through atom features, bond types, and connectivitity (i.e. which atoms are connected to each other and how?)\r\n",
    "#   - the coordinate-based representation is particularly useful \r\n",
    "#   - for reaction centre, find adjacency matrix differences then map to 3D matrix\r\n",
    "\r\n",
    "# convert MLP to GNN by swapping torch.nn.linear with PyG's GNN operators e.g. GCN layer\r\n",
    "\r\n",
    "# lucky's work\r\n",
    "# PairFeatures: a manual MP I think. it has to be otherwise what he's doing isn't a GNN at all.\r\n",
    "\r\n",
    "# set edges\r\n",
    "#   iterate:\r\n",
    "#       compute features (i.e. MP) -> MLP(features) -> update edges\r\n",
    "#       compute features (i.e. MP) -> MLP(MLP(edges)) -> update vertices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\r\n",
    "import torch.nn as nn\r\n",
    "from torch_geometric.nn import GCNConv, GAE\r\n",
    "from torch_geometric.utils import train_test_split_edges\r\n",
    "\r\n",
    "#import sys\r\n",
    "#sys.path.insert(0, \"Users/rmhavij/3d-reactions/\") # azure again\r\n",
    "from ts_vae.data_processors.grambow_processor import ReactionDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# normal:\r\n",
    "base_path = r'data/'\r\n",
    "# azure base_path = r'Users/rmhavij/3d-reactions/data/'\r\n",
    "r_dataset = ReactionDataset(base_path, geo_file = 'train_r') \r\n",
    "\r\n",
    "data = r_dataset.data\r\n",
    "data.train_mask = data.val_mask = data.test_mask = data.y = None\r\n",
    "data = train_test_split_edges(data = data, val_ratio = 0, test_ratio = 0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LinearEncoder(nn.Module):\r\n",
    "    def __init__(self, in_channels, out_channels):\r\n",
    "        super(LinearEncoder, self).__init__()\r\n",
    "        # use single GC to get embeddings for nodes here\r\n",
    "        self.conv = GCNConv(in_channels, out_channels)\r\n",
    "    \r\n",
    "    def forward(self, x, edge_index):\r\n",
    "        # no relu for linearity\r\n",
    "        return self.conv(x, edge_index)\r\n",
    "    \r\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_node_fs = r_dataset.data.num_node_features # = 11\r\n",
    "out_channels = 2\r\n",
    "\r\n",
    "# build model and optimiser\r\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\r\n",
    "model = GAE(LinearEncoder(num_node_fs, out_channels))\r\n",
    "model = model.to(device)\r\n",
    "x = data.x.to(device)\r\n",
    "train_pos_edge_index = data.train_pos_edge_index.to(device)\r\n",
    "opt = torch.optim.Adam(model.parameters(), lr=0.01)\r\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 001, AUC: 0.6880, AP: 0.5868\n",
      "Epoch: 002, AUC: 0.6871, AP: 0.5864\n",
      "Epoch: 003, AUC: 0.6802, AP: 0.5822\n",
      "Epoch: 004, AUC: 0.6801, AP: 0.5822\n",
      "Epoch: 005, AUC: 0.6804, AP: 0.5824\n",
      "Epoch: 006, AUC: 0.6806, AP: 0.5825\n",
      "Epoch: 007, AUC: 0.6802, AP: 0.5823\n",
      "Epoch: 008, AUC: 0.6814, AP: 0.5819\n",
      "Epoch: 009, AUC: 0.6813, AP: 0.5810\n",
      "Epoch: 010, AUC: 0.6803, AP: 0.5797\n"
     ]
    }
   ],
   "source": [
    "def train():\r\n",
    "    model.train() # sets training flag and params (doesn't actually train model!)\r\n",
    "    opt.zero_grad()\r\n",
    "    z = model.encode(x, train_pos_edge_index)\r\n",
    "    loss = model.recon_loss(z, train_pos_edge_index)\r\n",
    "    loss.backward()\r\n",
    "    opt.step()\r\n",
    "    return float(loss)\r\n",
    "\r\n",
    "def test(pos_edge_index, neg_edge_index):\r\n",
    "    model.eval()\r\n",
    "    with torch.no_grad():\r\n",
    "        z = model.encode(x, train_pos_edge_index)\r\n",
    "    return model.test(z, pos_edge_index, neg_edge_index)\r\n",
    "\r\n",
    "epochs = 10\r\n",
    "for epoch in range(1, epochs + 1):\r\n",
    "    loss = train()\r\n",
    "    auc, ap = test(data.test_pos_edge_index, data.test_neg_edge_index)\r\n",
    "    print('Epoch: {:03d}, AUC: {:.4f}, AP: {:.4f}'.format(epoch, auc, ap))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TSDecoder(torch.nn.Module):\r\n",
    "    \"\"\" Take TS embedding (i.e. combined R-P embedding) and decode to TS geometry. \"\"\"\r\n",
    "    # ref: right now, just using InnerProductDecoder\r\n",
    "\r\n",
    "    def __init__(self, latent_dim, geometry_dim):\r\n",
    "        super(TSDecoder, self).__init__()\r\n",
    "        self.ts_data = ts_data\r\n",
    "\r\n",
    "    def forward(self, ts_z, ts_edge_index, sigmoid=True):\r\n",
    "        \"\"\" Decode TS embedding into edge probabilities for the given node-pairs of TS edge_index. \"\"\"\r\n",
    "        value = (ts_z[ts_edge_index[0]] * ts_z[ts_edge_index[1]]).sum(dim=1)\r\n",
    "        return torch.sigmoid(value) if sigmoid else value\r\n",
    "\r\n",
    "    def forward_all(self, z, sigmoid=True):\r\n",
    "        \"\"\" Decode latent embeddings into probabilistic adjacency matrix. \"\"\"\r\n",
    "        adj = torch.matmul(z, z.t())\r\n",
    "        return torch.sigmoid(adj) if sigmoid else adj\r\n",
    "\r\n",
    "class MolEncoder(nn.Module):\r\n",
    "    \"\"\" Takes in geometry data and creates embedding. Used for reactants OR products, not both. \"\"\"\r\n",
    "    # based off LinearEncoder\r\n",
    "\r\n",
    "    def __init__(self, in_channels, out_channels, geometry_data):\r\n",
    "        super(MolEncoder, self).__init__()\r\n",
    "        self.geometry_data = geometry_data\r\n",
    "        # single GC to get embeddings for nodes here\r\n",
    "        self.conv = GCNConv(in_channels, out_channels)\r\n",
    "    \r\n",
    "    def forward(self, x, edge_index):\r\n",
    "        # no relu for linearity\r\n",
    "        return self.conv(x, edge_index)\r\n",
    "\r\n",
    "    # TODO: try these funcs; may need to pass in other args later; add these to decoder and TSVAE too\r\n",
    "    def save(self, path):\r\n",
    "        \"\"\" Save model to the path specified. \"\"\"\r\n",
    "        torch.save(self.state_dict(), path)\r\n",
    "    \r\n",
    "    def load(self, path):\r\n",
    "        \"\"\" Load model from path specified. \"\"\"\r\n",
    "        model_weights = torch.load(path)\r\n",
    "        self.load_state_dict(model_weights)\r\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_auc_score, average_precision_score\r\n",
    "from torch_geometric.utils import (negative_sampling, remove_self_loops, add_self_loops)\r\n",
    "\r\n",
    "EPS = 1e-15\r\n",
    "\r\n",
    "class TSGAE(nn.Module):\r\n",
    "    \"\"\" Takes in reactant encoder, product encoder, transition state decoder.\r\n",
    "        Creates embeddings for reactants and products. \r\n",
    "        Combines these reactant and product embeddings to create a transition state.\r\n",
    "        TODO: do I pass in data here?\r\n",
    "    \"\"\"\r\n",
    "\r\n",
    "    def __init__(self, r_encoder, p_encoder, ts_decoder, r_data, p_data, ts_data):\r\n",
    "        super(TSGAE, self).__init__()\r\n",
    "        \r\n",
    "        # encoder and decoders\r\n",
    "        self.r_encoder = r_encoder\r\n",
    "        self.p_encoder = p_encoder\r\n",
    "        self.ts_decoder = ts_decoder\r\n",
    "\r\n",
    "        # not sure if following needed\r\n",
    "        self.r_data = r_data\r\n",
    "        self.p_data = p_data\r\n",
    "        self.ts_data = ts_data\r\n",
    "\r\n",
    "    def encode_reactant(self):\r\n",
    "        return self.r_encoder()\r\n",
    "\r\n",
    "    def encode_product(self):\r\n",
    "        return self.p_encoder()\r\n",
    "\r\n",
    "    def combine_reactant_and_product(self, r_z, p_z):\r\n",
    "        \"\"\" Encode reactant and product, then combine their embeddings to get TS embedding.\r\n",
    "            Each encoder produces an embedding for each node of the input molecule.\r\n",
    "            TODO: different combination methods (e.g. concat z vectors so have dim=2d, multiply?) \r\n",
    "            TODO: confused here about whether I return encoder or z from encoder?\r\n",
    "            TODO: take in data?\r\n",
    "        \"\"\"\r\n",
    "        ### first go\r\n",
    "        # encode reactant and product\r\n",
    "        #r_z = self.r_encoder(*args, **kwargs)\r\n",
    "        #p_z = self.p_encoder(*args, **kwargs)\r\n",
    "        # trying first with simpler linear combination\r\n",
    "        #ts_z = r_z + p_z\r\n",
    "        \r\n",
    "        ### second go\r\n",
    "        ts_z = r_z + p_z\r\n",
    "        return ts_z\r\n",
    "        \r\n",
    "    def decode(self, generated_ts_latent, ts_data):\r\n",
    "        \"\"\" Runs the TS decoder to decode to TS (as probabilistic adjacency matrix) and computes edge probabilities. \r\n",
    "            TODO: decode to actual TS geometry. Can start with NL-WLS from MIT, then add in coordinate features, etc.\r\n",
    "        \"\"\"\r\n",
    "        return self.ts_decoder(generated_ts_latent, ts_data)\r\n",
    "\r\n",
    "    def ts_construction_loss(self, ts_z, ts_pos_edge_index, ts_neg_edge_index = None):\r\n",
    "        \"\"\" Compute BCE for positive edges and, optionally, for negative sampled edges. \r\n",
    "            If negative edges not given, uses negative sampling to calculate.\r\n",
    "            TODO: more specific loss func?\r\n",
    "        \"\"\"\r\n",
    "        pos_loss = - torch.log(self.ts_decoder(ts_z, ts_pos_edge_index, sigmoid = True) + EPS).mean()\r\n",
    "        \r\n",
    "        # don't include self-loops in neg samples\r\n",
    "        ts_pos_edge_index, _ = remove_self_loops(ts_pos_edge_index)\r\n",
    "        ts_pos_edge_index, _ = add_self_loops(ts_pos_edge_index)\r\n",
    "        if ts_neg_edge_index is None:\r\n",
    "            ts_neg_edge_index = negative_sampling(ts_pos_edge_index, ts_z.size(0))\r\n",
    "        neg_loss = - torch.log(1 - self.ts_decoder(ts_z, ts_neg_edge_index, sigmoid = True) + EPS).mean()\r\n",
    "\r\n",
    "        return pos_loss + neg_loss\r\n",
    "\r\n",
    "    def test(self, ts_z, ts_pos_edge_index, ts_neg_edge_index):\r\n",
    "        \"\"\" Compute ROC-AUC and average precision (AP) scores. \r\n",
    "            TODO: what is y here?\r\n",
    "        \"\"\"\r\n",
    "        pos_y = ts_z.new_ones(ts_pos_edge_index.size(1))\r\n",
    "        neg_y = ts_z.new_zeros(ts_neg_edge_index.size(1))\r\n",
    "        y = torch.cat([pos_y, neg_y], dim = 0)\r\n",
    "\r\n",
    "        pos_pred = self.ts_decoder(ts_z, ts_pos_edge_index, sigmoid = True)\r\n",
    "        neg_pred = self.ts_decoder(ts_z, ts_neg_edge_index, sigmoid = True)\r\n",
    "        pred = torch.cat([pos_pred, neg_pred], dim = 0)\r\n",
    "\r\n",
    "        y, pred = y.detach().cpu().numpy(), pred.detach().cpu().numpy()\r\n",
    "\r\n",
    "        return roc_auc_score(y, pred), average_precision_score(y, pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: should I just have to encoders rather than GAEs for reactant and product here?\r\n",
    "#       am I trying to learn the latent space for each and combine OR combine them in a way to create TS?\r\n",
    "\r\n",
    "# build models and optimiser\r\n",
    "# base_path = r'Users/rmhavij/3d-reactions/data/'\r\n",
    "base_path = r'data/'\r\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\r\n",
    "val_ratio = 0\r\n",
    "test_ratio = 0.2 # TODO: combine train and test .sdf files for each geom then split (as works better with PyG)\r\n",
    "r_latent_dim = p_latent_dim = ts_latent_dim = 2 # fine for now. may have to include more later.\r\n",
    "\r\n",
    "# reactant data\r\n",
    "r_dataset = ReactionDataset(base_path, geo_file = 'train_r') \r\n",
    "r_data = r_dataset.data\r\n",
    "r_data.train_mask = r_data.val_mask = r_data.test_mask = r_data.y = None\r\n",
    "r_data = train_test_split_edges(data = r_data, val_ratio = val_ratio, test_ratio = test_ratio)\r\n",
    "r_x = r_data.x.to(device)\r\n",
    "r_train_pos_edge_index = r_data.train_pos_edge_index.to(device)\r\n",
    "# reactant encoder\r\n",
    "r_num_node_fs = r_data.num_node_features # = 11\r\n",
    "r_encoder = GAE(LinearEncoder(r_num_node_fs, r_latent_dim))\r\n",
    "r_opt = torch.optim.Adam(r_encoder.parameters(), lr = 0.01)\r\n",
    "\r\n",
    "# product data\r\n",
    "p_dataset = ReactionDataset(base_path, geo_file = 'train_p') \r\n",
    "p_data = p_dataset.data\r\n",
    "p_data.train_mask = p_data.val_mask = p_data.test_mask = p_data.y = None\r\n",
    "p_data = train_test_split_edges(data = p_data, val_ratio = val_ratio, test_ratio = test_ratio)\r\n",
    "p_x = p_data.x.to(device)\r\n",
    "p_train_pos_edge_index = p_data.train_pos_edge_index.to(device)\r\n",
    "# product encoder\r\n",
    "p_num_node_fs = r_data.num_node_features # = 11\r\n",
    "p_encoder = GAE(LinearEncoder(p_num_node_fs, p_latent_dim))\r\n",
    "p_opt = torch.optim.Adam(p_encoder.parameters(), lr = 0.01)\r\n",
    "\r\n",
    "# ts data\r\n",
    "ts_dataset = ReactionDataset(base_path, geo_file = 'train_ts') \r\n",
    "ts_data = ts_dataset.data\r\n",
    "ts_data.train_mask = ts_data.val_mask = ts_data.test_mask = ts_data.y = None\r\n",
    "ts_data = train_test_split_edges(data = ts_data, val_ratio = val_ratio, test_ratio = test_ratio)\r\n",
    "ts_x = ts_data.x.to(device)\r\n",
    "ts_train_pos_edge_index = ts_data.train_pos_edge_index.to(device)\r\n",
    "# ts decoder (no opt)\r\n",
    "ts_num_node_fs = ts_data.num_node_features # = 11\r\n",
    "ts_decoder = TSDecoder(ts_latent_dim, ts_num_node_fs)\r\n",
    "\r\n",
    "# ts gae\r\n",
    "ts_gae = TSGAE(r_encoder = r_encoder, p_encoder = p_encoder, ts_decoder = ts_decoder,\r\n",
    "                r_data = r_data, p_data = p_data, ts_data = ts_data)\r\n",
    "ts_gae = ts_gae.to(device)\r\n",
    "gae_opt = torch.optim.Adam(ts_gae.parameters(), lr = 0.01)\r\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_individual_encoder(encoder, opt, train_pos_edge_index, data):\r\n",
    "    \"\"\" Use this for reactant or product encoder training. \"\"\"\r\n",
    "    encoder.train()\r\n",
    "    opt.zero_grad()\r\n",
    "    z = encoder.encode(data, train_pos_edge_index)\r\n",
    "    loss = encoder.recon_loss(z, train_pos_edge_index)\r\n",
    "    loss.backward()\r\n",
    "    opt.step()\r\n",
    "    return z, float(loss)\r\n",
    "\r\n",
    "def train_ts_gae(ts_gae, gae_opt, ts_train_pos_edge_index, r_x, p_x, ts_x):\r\n",
    "    \"\"\" Train TSGAE.\r\n",
    "        Training this model trains the individual R and P encoders.\r\n",
    "        TODO: how to use R and P encoder losses?\r\n",
    "    \"\"\"\r\n",
    "    ts_gae.train() \r\n",
    "    gae_opt.zero_grad()\r\n",
    "\r\n",
    "    # train r and p encoder\r\n",
    "    r_z, _ = train_individual_encoder(r_encoder, r_opt, r_pos_edge_index, r_x)\r\n",
    "    p_z, _ = train_individual_encoder(p_encoder, p_opt, p_pos_edge_index, p_x)\r\n",
    "\r\n",
    "    # combine for ts_z\r\n",
    "    ts_z = ts_gae.combine_reactant_and_product(r_z, p_z)\r\n",
    "    gae_loss = ts_gae.ts_construction_loss(ts_z, ts_train_pos_edge_index)\r\n",
    "    gae_loss.backward()\r\n",
    "    gae_opt.step()\r\n",
    "    \r\n",
    "    return float(gae_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Trying to backward through the graph a second time, but the saved intermediate results have already been freed. Specify retain_graph=True when calling .backward() or autograd.grad() the first time.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-44-cb376ce75be7>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[0mepochs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m4\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepochs\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 10\u001b[1;33m     \u001b[0mloss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain_ts_gae\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mts_gae\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgae_opt\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mts_train_pos_edge_index\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mr_x\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mp_x\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mts_x\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     11\u001b[0m     \u001b[0mauc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0map\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtest\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mts_data\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtest_pos_edge_index\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mts_data\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtest_neg_edge_index\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Epoch: {:03d}, AUC: {:.4f}, AP: {:.4f}'\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mauc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0map\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-38-15c2bcf3ca99>\u001b[0m in \u001b[0;36mtrain_ts_gae\u001b[1;34m(ts_gae, gae_opt, ts_train_pos_edge_index, r_x, p_x, ts_x)\u001b[0m\n\u001b[0;32m     23\u001b[0m     \u001b[0mts_z\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mts_gae\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcombine_reactant_and_product\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mr_z\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mp_z\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     24\u001b[0m     \u001b[0mgae_loss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mts_gae\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mts_construction_loss\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mts_z\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mts_train_pos_edge_index\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 25\u001b[1;33m     \u001b[0mgae_loss\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     26\u001b[0m     \u001b[0mgae_opt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     27\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\miniconda3\\envs\\3d-rdkit\\lib\\site-packages\\torch\\tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[1;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[0;32m    243\u001b[0m                 \u001b[0mcreate_graph\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcreate_graph\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    244\u001b[0m                 inputs=inputs)\n\u001b[1;32m--> 245\u001b[1;33m         \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    246\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    247\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\miniconda3\\envs\\3d-rdkit\\lib\\site-packages\\torch\\autograd\\__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[1;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[0;32m    145\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[0;32m    146\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgrad_tensors_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 147\u001b[1;33m         allow_unreachable=True, accumulate_grad=True)  # allow_unreachable flag\n\u001b[0m\u001b[0;32m    148\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    149\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: Trying to backward through the graph a second time, but the saved intermediate results have already been freed. Specify retain_graph=True when calling .backward() or autograd.grad() the first time."
     ]
    }
   ],
   "source": [
    "def test_ts_gae(ts_gae, ts_train_pos_edge_index, ts_test_pos_edge_index, ts_test_neg_edge_index):\r\n",
    "    ts_gae.eval()\r\n",
    "    with torch.no_grad():\r\n",
    "        ts_z = ts_gae.combine_reactant_and_product(x, ts_train_pos_edge_index)\r\n",
    "    return ts_gae.test(ts_z, ts_test_pos_edge_index, ts_test_neg_edge_index)\r\n",
    "\r\n",
    "epochs = 4\r\n",
    "for epoch in range(1, epochs + 1):\r\n",
    "    loss = train_ts_gae(ts_gae, gae_opt, ts_train_pos_edge_index, r_x, p_x, ts_x)\r\n",
    "    auc, ap = test(ts_data.test_pos_edge_index, ts_data.test_neg_edge_index)\r\n",
    "    print('Epoch: {:03d}, AUC: {:.4f}, AP: {:.4f}'.format(epoch, auc, ap))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.6.13 64-bit (conda)",
   "name": "python3613jvsc74a57bd0f4671ad35fdc0609fa675edcd17de5b3092cb55d03f1d9670a78611a41fb18f3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  },
  "orig_nbformat": 2
 },
 "nbformat": 4,
 "nbformat_minor": 2
}