{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# atom features, bond type, graph connectivity, (x,y,z) coordinates  \n",
    "#   - when we encode the graph, we're doing it through atom features, bond types, and connectivitity (i.e. which atoms are connected to each other and how?)\n",
    "#   - the coordinate-based representation is particularly useful \n",
    "#   - for reaction centre, find adjacency matrix differences then map to 3D matrix\n",
    "\n",
    "# convert MLP to GNN by swapping torch.nn.linear with PyG's GNN operators e.g. GCN layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch_geometric.nn import GCNConv, GAE\n",
    "from torch_geometric.utils import train_test_split_edges\n",
    "\n",
    "import sys\n",
    "sys.path.insert(0, \"Users/rmhavij/3d-reactions/\") # azure again\n",
    "from ts_vae.data_processors.grambow_processor import ReactionDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# normal: base_path = r'data/'\n",
    "# azure\n",
    "base_path = r'Users/rmhavij/3d-reactions/data/'\n",
    "r_dataset = ReactionDataset(base_path, geo_file = 'train_r') \n",
    "\n",
    "data = r_dataset.data\n",
    "data.train_mask = data.val_mask = data.test_mask = data.y = None\n",
    "data = train_test_split_edges(data = data, val_ratio = 0, test_ratio = 0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# should rename this like molecule encoder\n",
    "\n",
    "class LinearEncoder(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super(LinearEncoder, self).__init__()\n",
    "\n",
    "        # use single GC to get embeddings for nodes here\n",
    "        self.conv = GCNConv(in_channels, out_channels)\n",
    "    \n",
    "    def forward(self, x, edge_index):\n",
    "        # no relu for linearity\n",
    "        return self.conv(x, edge_index)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_node_fs = r_dataset.data.num_node_features # = 11\n",
    "out_channels = 2\n",
    "\n",
    "# build model and optimiser\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "model = GAE(LinearEncoder(num_node_fs, out_channels))\n",
    "model = model.to(device)\n",
    "x = data.x.to(device)\n",
    "train_pos_edge_index = data.train_pos_edge_index.to(device)\n",
    "opt = torch.optim.Adam(model.parameters(), lr=0.01)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train():\n",
    "    model.train()\n",
    "    opt.zero_grad()\n",
    "    z = model.encode(x, train_pos_edge_index)\n",
    "    loss = model.recon_loss(z, train_pos_edge_index)\n",
    "    loss.backward()\n",
    "    opt.step()\n",
    "    return float(loss)\n",
    "\n",
    "def test(pos_edge_index, neg_edge_index):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        z = model.encode(x, train_pos_edge_index)\n",
    "    return model.test(z, pos_edge_index, neg_edge_index)\n",
    "\n",
    "epochs = 10\n",
    "for epoch in range(1, epochs + 1):\n",
    "    loss = train()\n",
    "    auc, ap = test(data.test_pos_edge_index, data.test_neg_edge_index)\n",
    "    print('Epoch: {:03d}, AUC: {:.4f}, AP: {:.4f}'.format(epoch, auc, ap))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# build models and optimiser\n",
    "base_path = r'Users/rmhavij/3d-reactions/data/'\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# reactant data\n",
    "r_dataset = ReactionDataset(base_path, geo_file = 'train_r') \n",
    "reactant_data = r_dataset.data\n",
    "reactant_data.train_mask = reactant_data.val_mask = reactant_data.test_mask = reactant_data.y = None\n",
    "reactant_data = train_test_split_edges(data = reactant_data, val_ratio = 0, test_ratio = 0.2)\n",
    "\n",
    "# reactant encoder dimensions\n",
    "num_node_fs = r_dataset.data.num_node_features # = 11\n",
    "out_channels = 2\n",
    "\n",
    "# reactant encoder\n",
    "reactant_encoder = GAE(LinearEncoder(num_node_fs, out_channels))\n",
    "reactant_encoder = reactant_encoder.to(device)\n",
    "x = reactant_data.x.to(device)\n",
    "reactant_pos_edges = reactant_data.train_pos_edge_index.to(device)\n",
    "reactant_opt = torch.optim.Adam(reactant_encoder.parameters(), lr=0.01)\n",
    "\n",
    "# product data\n",
    "p_dataset = ReactionDataset(base_path, geo_file = 'train_p') \n",
    "product_data = p_dataset.data\n",
    "product_data.train_mask = product_data.val_mask = product_data.test_mask = product_data.y = None\n",
    "product_data = train_test_split_edges(data = product_data, val_ratio = 0, test_ratio = 0.2)\n",
    "\n",
    "# product data dimensions\n",
    "num_node_fs = p_dataset.data.num_node_features # = 11 (this is same as reactants here but useful anyway)\n",
    "out_channels = 2\n",
    "\n",
    "# product encoder\n",
    "product_encoder = GAE(LinearEncoder(num_node_fs, out_channels))\n",
    "product_encoder = product_encoder.to(device)\n",
    "x = product_data.x.to(device)\n",
    "product_pos_edges = product_data.train_pos_edge_index.to(device)\n",
    "product_opt = torch.optim.Adam(product_encoder.parameters(), lr=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TSDecoder(torch.nn.Module):\n",
    "    # Decoder for TS\n",
    "    # takes reactant and product z's, combines them, then decodes to TS\n",
    "\n",
    "    def forward(self, reactant_z, product_z, reactant_edge_index, product_edge_index, sigmoid=True):\n",
    "        # ref: inner product decoder\n",
    "        \n",
    "        \"\"\" Decode combined reactant and product latent embeddings into edge probabilities\n",
    "            for the given node-pairs of (reactant and product) edge_index.\n",
    "        \"\"\"\n",
    "        \n",
    "        value = (z[edge_index[0]] * z[edge_index[1]]).sum(dim=1)\n",
    "        return torch.sigmoid(value) if sigmoid else value\n",
    "\n",
    "    def forward_all(self, reactant_z, product_z, sigmoid=True):\n",
    "        \"\"\" Decode latent embeddings into probabilistic adjacenecy matrix. \"\"\"\n",
    "        adj = torch.matmul(z, z.t())\n",
    "        return torch.sigmoid(adj) if sigmoid else adj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: does TS need its own GAE: encoder for R and P, then decodes to TS\n",
    "\n",
    "class TSGAE(nn.Module):\n",
    "    # TS GAE\n",
    "\n",
    "    def __init__(self, reactant_encoder, product_encoder, ts_decoder, in_channels, out_channels):\n",
    "\n",
    "        super(TSGAE, self).__init__()\n",
    "\n",
    "        self.reactant_encoder = reactant_encoder\n",
    "        self.product_encoder = product_encoder\n",
    "        self.ts_decoder = ts_decoder\n",
    "\n",
    "        TSGAE.reset_parameters(self)\n",
    "\n",
    "    def reset_parameters(self):\n",
    "        reset(self.reactant_encoder)\n",
    "        reset(self.product_encoder)\n",
    "        reset(self.ts_decoder)\n",
    "\n",
    "    def combine_reactant_and_product(self, *args, **kwargs):\n",
    "        \"\"\" Run reactant and product encoders to compute node-wise latent variables. \"\"\"\n",
    "        \n",
    "        # run encoders for reactant and product, then combine\n",
    "\n",
    "        # TODO: should this be the combine function instead? probably, yeah\n",
    "\n",
    "        # return self.encoder(*args, **kwargs)\n",
    "        return \n",
    "        \n",
    "\n",
    "    def decode(self, *args, **kwargs):\n",
    "        \"\"\"Runs the TS decoder to decode to  and computes edge probabilities.\"\"\"\n",
    "        return self.ts_decoder(*args, **kwargs)\n",
    "\n",
    "    def ts_creation_loss(self, reactant_z, reactant_pos_edges, reactant_neg_edges=None, product_z, product_pos_edges, product_neg_edges=None):\n",
    "        \"\"\" Compute BCE for positive edges and negative sampled (optional) edges. \"\"\"\n",
    "\n",
    "        \n",
    "\n",
    "        pos_loss = -torch.log(self.decoder(z, pos_edge_index, sigmoid=True) + EPS).mean()\n",
    "\n",
    "        # Do not include self-loops in negative samples\n",
    "        pos_edge_index, _ = remove_self_loops(pos_edge_index)\n",
    "        pos_edge_index, _ = add_self_loops(pos_edge_index)\n",
    "        if neg_edge_index is None:\n",
    "            neg_edge_index = negative_sampling(pos_edge_index, z.size(0))\n",
    "        neg_loss = -torch.log(1 - self.decoder(z, neg_edge_index, sigmoid=True) + EPS).mean()\n",
    "\n",
    "        return pos_loss + neg_loss\n",
    "\n",
    "\n",
    "    def test(self, z, pos_edge_index, neg_edge_index):\n",
    "        \"\"\" Compute area under ROC curve (AUC) and average precision (AP) scores. \"\"\"\n",
    "\n",
    "        pos_y = z.new_ones(pos_edge_index.size(1))\n",
    "        neg_y = z.new_zeros(neg_edge_index.size(1))\n",
    "        y = torch.cat([pos_y, neg_y], dim=0)\n",
    "\n",
    "        pos_pred = self.decoder(z, pos_edge_index, sigmoid=True)\n",
    "        neg_pred = self.decoder(z, neg_edge_index, sigmoid=True)\n",
    "        pred = torch.cat([pos_pred, neg_pred], dim=0)\n",
    "\n",
    "        y, pred = y.detach().cpu().numpy(), pred.detach().cpu().numpy()\n",
    "\n",
    "        return roc_auc_score(y, pred), average_precision_score(y, pred)\n",
    "\n",
    "\n",
    "def reset(nn):\n",
    "    def _reset(item):\n",
    "        if hasattr(item, 'reset_parameters'):\n",
    "            item.reset_parameters()\n",
    "\n",
    "    if nn is not None:\n",
    "        if hasattr(nn, 'children') and len(list(nn.children())) > 0:\n",
    "            for item in nn.children():\n",
    "                _reset(item)\n",
    "        else:\n",
    "            _reset(nn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_individual_geometry(geometry_encoder, opt, pos_edge_indices):\n",
    "    # use this on reactant or product\n",
    "    geometry_encoder.train()\n",
    "    opt.zero_grad()\n",
    "    z = geometry_encoder.encode(x, pos_edge_indices)\n",
    "    loss = geometry_encoder.recon_loss(z, pos_edge_indices)\n",
    "    loss.backward()\n",
    "    opt.step()\n",
    "    return z, float(loss)\n",
    "\n",
    "def train_reaction():\n",
    "    # train reactant and product together and decode to TS\n",
    "    # TODO: pass in encoders, etc.?\n",
    "\n",
    "    reactant_z, reactant_loss = train_individual_geometry(reactant_encoder, reactant_opt, reactant_pos_edges)\n",
    "    product_z, product_loss = train_individual_geometry(product_encoder, product_opt, product_pos_edges)\n",
    "    # TODO: how to use the losses?\n",
    "\n",
    "    # combine latent representation of reactant and product\n",
    "    ts_initialisation = combine(reactant_z, product_z)\n",
    "    \n",
    "    # need some index in order to reconstruct the TS from this\n",
    "    \n",
    "\n",
    "    return\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lucky's work\n",
    "# PairFeatures: a manual MP I think. it has to be otherwise what he's doing isn't a GNN at all.\n",
    "\n",
    "# set edges\n",
    "#   iterate:\n",
    "#       compute features (i.e. MP) -> MLP(features) -> update edges\n",
    "#       compute features (i.e. MP) -> MLP(MLP(edges)) -> update vertices"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (3d-rdkit)",
   "language": "python",
   "name": "3d-rdkit"
  },
  "language_info": {
   "name": "python",
   "version": ""
  },
  "orig_nbformat": 2
 },
 "nbformat": 4,
 "nbformat_minor": 2
}