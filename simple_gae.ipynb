{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Atom features, bond type, graph connectivity, xyz coordinates\r\n",
    "- When we encode the graph, we're doing it through atom features, bond types, and connectivity (i.e. which atoms are connected to each other and how?)\r\n",
    "- The coordinate-based representation is particularly useful\r\n",
    "- For reaction centre, find adjacency matrix difference then map to 3D matrix\r\n",
    "\r\n",
    "Convert MLP to GNN by swapping torch.nn.Linear with PyG's GNN operators e.g. GCN layer\r\n",
    "Lucky's work\r\n",
    "- PairFeatures: a manual MP I think. it has to be otherwise what he's doing isn't a GNN.\r\n",
    "- set edges: iterate: \r\n",
    "    - compute features (i.e. MP) -> MLP(features) -> update edges\r\n",
    "    - compute features (i.e. MP) -> MLP(MLP(edges)) -> update vertices\r\n",
    "\r\n",
    "Loose notes\r\n",
    "- Can define data class for parameters e.g. \r\n",
    "    - @dataclass\r\n",
    "      class GNNParams:\r\n",
    "        input_dim: int\r\n",
    "        output_dim: int\r\n",
    "        ... (hidden_sizes, dropout, batchnorm, activation)\r\n",
    "- Could also have enum for different representations\r\n",
    "- Loose note: could have classes for each type of reaction, uni vs bimolecular, etc.\r\n",
    "- Should I normalise the targets to mean=0, std=1 like in qm9_nn_conv.py?\r\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\r\n",
    "import torch.nn as nn\r\n",
    "from torch_geometric.nn import GCNConv, GAE\r\n",
    "from torch_geometric.utils import train_test_split_edges\r\n",
    "\r\n",
    "#import sys\r\n",
    "#sys.path.insert(0, \"Users/rmhavij/3d-reactions/\") # azure again\r\n",
    "from ts_vae.data_processors.grambow_processor import ReactionDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# normal:\r\n",
    "base_path = r'data/'\r\n",
    "# azure base_path = r'Users/rmhavij/3d-reactions/data/'\r\n",
    "r_dataset = ReactionDataset(base_path, geo_file = 'train_r') \r\n",
    "\r\n",
    "data = r_dataset.data\r\n",
    "data.train_mask = data.val_mask = data.test_mask = data.y = None\r\n",
    "data = train_test_split_edges(data = data, val_ratio = 0, test_ratio = 0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LinearEncoder(nn.Module):\r\n",
    "    def __init__(self, in_channels, out_channels):\r\n",
    "        super(LinearEncoder, self).__init__()\r\n",
    "        # use single GC to get embeddings for nodes here\r\n",
    "        self.conv = GCNConv(in_channels, out_channels)\r\n",
    "    \r\n",
    "    def forward(self, x, edge_index):\r\n",
    "        # no relu for linearity\r\n",
    "        return self.conv(x, edge_index)\r\n",
    "    \r\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_node_fs = r_dataset.data.num_node_features # = 11\r\n",
    "out_channels = 2\r\n",
    "\r\n",
    "# build model and optimiser\r\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\r\n",
    "model = GAE(LinearEncoder(num_node_fs, out_channels))\r\n",
    "model = model.to(device)\r\n",
    "x = data.x.to(device)\r\n",
    "train_pos_edge_index = data.train_pos_edge_index.to(device)\r\n",
    "opt = torch.optim.Adam(model.parameters(), lr=0.01)\r\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 001, AUC: 0.6880, AP: 0.5868\n",
      "Epoch: 002, AUC: 0.6871, AP: 0.5864\n",
      "Epoch: 003, AUC: 0.6802, AP: 0.5822\n",
      "Epoch: 004, AUC: 0.6801, AP: 0.5822\n",
      "Epoch: 005, AUC: 0.6804, AP: 0.5824\n",
      "Epoch: 006, AUC: 0.6806, AP: 0.5825\n",
      "Epoch: 007, AUC: 0.6802, AP: 0.5823\n",
      "Epoch: 008, AUC: 0.6814, AP: 0.5819\n",
      "Epoch: 009, AUC: 0.6813, AP: 0.5810\n",
      "Epoch: 010, AUC: 0.6803, AP: 0.5797\n"
     ]
    }
   ],
   "source": [
    "def train():\r\n",
    "    model.train() # sets training flag and params (doesn't actually train model!)\r\n",
    "    opt.zero_grad()\r\n",
    "    z = model.encode(x, train_pos_edge_index)\r\n",
    "    loss = model.recon_loss(z, train_pos_edge_index)\r\n",
    "    loss.backward()\r\n",
    "    opt.step()\r\n",
    "    return float(loss)\r\n",
    "\r\n",
    "def test(pos_edge_index, neg_edge_index):\r\n",
    "    model.eval()\r\n",
    "    with torch.no_grad():\r\n",
    "        z = model.encode(x, train_pos_edge_index)\r\n",
    "    return model.test(z, pos_edge_index, neg_edge_index)\r\n",
    "\r\n",
    "epochs = 10\r\n",
    "for epoch in range(1, epochs + 1):\r\n",
    "    loss = train()\r\n",
    "    auc, ap = test(data.test_pos_edge_index, data.test_neg_edge_index)\r\n",
    "    print('Epoch: {:03d}, AUC: {:.4f}, AP: {:.4f}'.format(epoch, auc, ap))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: save, load, reset funcs\r\n",
    "\r\n",
    "class TSDecoder(torch.nn.Module):\r\n",
    "    \"\"\" Take TS embedding (i.e. combined R-P embedding) and decode to TS geometry. \"\"\"\r\n",
    "    # ref: right now, just using InnerProductDecoder\r\n",
    "\r\n",
    "    def __init__(self, latent_dim, geometry_dim):\r\n",
    "        super(TSDecoder, self).__init__()\r\n",
    "        self.ts_data = ts_data\r\n",
    "\r\n",
    "    def forward(self, ts_z, ts_edge_index, sigmoid=True):\r\n",
    "        \"\"\" Decode TS embedding into edge probabilities for the given node-pairs of TS edge_index. \"\"\"\r\n",
    "        value = (ts_z[ts_edge_index[0]] * ts_z[ts_edge_index[1]]).sum(dim=1)\r\n",
    "        return torch.sigmoid(value) if sigmoid else value\r\n",
    "\r\n",
    "    def forward_all(self, z, sigmoid=True):\r\n",
    "        \"\"\" Decode latent embeddings into probabilistic adjacency matrix. \"\"\"\r\n",
    "        adj = torch.matmul(z, z.t())\r\n",
    "        return torch.sigmoid(adj) if sigmoid else adj\r\n",
    "\r\n",
    "class MolEncoder(nn.Module):\r\n",
    "    \"\"\" Takes in geometry data and creates embedding. Used for reactants OR products, not both. \"\"\"\r\n",
    "    # based off LinearEncoder\r\n",
    "\r\n",
    "    def __init__(self, in_channels, out_channels):\r\n",
    "        super(MolEncoder, self).__init__()\r\n",
    "        # single GC to get embeddings for nodes here\r\n",
    "        self.conv = GCNConv(in_channels, out_channels)\r\n",
    "        \r\n",
    "    def forward(self, x, edge_index):\r\n",
    "        # no relu for linearity\r\n",
    "        return self.conv(x, edge_index)   \r\n",
    "\r\n",
    "class InnerProductDecoder(nn.Module):\r\n",
    "    def forward(self, z, edge_index, sigmoid = True):\r\n",
    "        value = (z[edge_index[0]] * z[edge_index[1]]).sum(dim = 1)\r\n",
    "        return torch.sigmoid(value) if sigmoid else value\r\n",
    "    \r\n",
    "    def forward_all(self, z, sigmoid = True):\r\n",
    "        adj = torch.matmul(z, z.t())\r\n",
    "        return torch.sigmoid(adj) if sigmoid else adj\r\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GAE(torch.nn.Module):\r\n",
    "    def __init__(self, encoder, decoder=None):\r\n",
    "        super(GAE, self).__init__()\r\n",
    "        self.encoder = encoder\r\n",
    "        self.decoder = InnerProductDecoder() # same as my TSDecoder\r\n",
    "\r\n",
    "    def encode(self, *args, **kwargs):\r\n",
    "        return self.encoder(*args, **kwargs)\r\n",
    "\r\n",
    "    def decode(self, *args, **kwargs):\r\n",
    "        return self.decoder(*args, **kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_auc_score, average_precision_score\r\n",
    "from torch_geometric.utils import (negative_sampling, remove_self_loops, add_self_loops)\r\n",
    "\r\n",
    "EPS = 1e-15\r\n",
    "\r\n",
    "class TSGAE(nn.Module):\r\n",
    "    \"\"\" Takes in reactant encoder, product encoder, transition state decoder.\r\n",
    "        Creates embeddings for reactants and products. \r\n",
    "        Combines these reactant and product embeddings to create a transition state.\r\n",
    "        TODO: do I pass in data here?\r\n",
    "    \"\"\"\r\n",
    "\r\n",
    "    def __init__(self, r_encoder, p_encoder, ts_decoder):\r\n",
    "        super(TSGAE, self).__init__()\r\n",
    "        # encoder and decoders\r\n",
    "        self.r_encoder = r_encoder\r\n",
    "        self.p_encoder = p_encoder\r\n",
    "        self.ts_decoder = ts_decoder\r\n",
    "\r\n",
    "    def combine_reactant_and_product(self, r_x, p_x, r_pos_edge_index, p_pos_edge_index):\r\n",
    "        \"\"\" Encode reactant and product, then combine their embeddings to get TS embedding.\r\n",
    "            Each encoder produces an embedding for each node of the input molecule.\r\n",
    "            TODO: different combination methods (e.g. concat z vectors so have dim=2d, multiply?) \r\n",
    "        \"\"\"\r\n",
    "        # encode reactant and product\r\n",
    "        r_z = self.r_encoder(r_x, r_pos_edge_index)\r\n",
    "        p_z = self.p_encoder(p_x, p_pos_edge_index)\r\n",
    "        \r\n",
    "        # print(r_z.shape, p_z.shape)\r\n",
    "        \r\n",
    "        # linear comb\r\n",
    "        ts_z = r_z + p_z\r\n",
    "\r\n",
    "        return ts_z\r\n",
    "        \r\n",
    "    def decode(self, ts_z):\r\n",
    "        \"\"\" Runs the TS decoder to decode to TS (as probabilistic adjacency matrix) and computes edge probabilities. \r\n",
    "            TODO: decode to actual TS geometry. Can start with NL-WLS from MIT, then add in coordinate features, etc.\r\n",
    "        \"\"\"\r\n",
    "        return self.ts_decoder(ts_z)\r\n",
    "\r\n",
    "    def ts_construction_loss(self, ts_z, ts_pos_edge_index, ts_neg_edge_index = None):\r\n",
    "        \"\"\" Compute BCE for positive edges and, optionally, for negative sampled edges. \r\n",
    "            If negative edges not given, uses negative sampling to calculate.\r\n",
    "            TODO: more specific loss func?\r\n",
    "        \"\"\"\r\n",
    "        pos_loss = - torch.log(self.ts_decoder(ts_z, ts_pos_edge_index, sigmoid = True) + EPS).mean()\r\n",
    "        \r\n",
    "        # don't include self-loops in neg samples\r\n",
    "        ts_pos_edge_index, _ = remove_self_loops(ts_pos_edge_index)\r\n",
    "        ts_pos_edge_index, _ = add_self_loops(ts_pos_edge_index)\r\n",
    "        if ts_neg_edge_index is None:\r\n",
    "            ts_neg_edge_index = negative_sampling(ts_pos_edge_index, ts_z.size(0))\r\n",
    "        neg_loss = - torch.log(1 - self.ts_decoder(ts_z, ts_neg_edge_index, sigmoid = True) + EPS).mean()\r\n",
    "\r\n",
    "        return pos_loss + neg_loss\r\n",
    "\r\n",
    "    def test(self, ts_z, ts_pos_edge_index, ts_neg_edge_index):\r\n",
    "        \"\"\" Compute ROC-AUC and average precision (AP) scores. \r\n",
    "            TODO: what is y here?\r\n",
    "        \"\"\"\r\n",
    "        pos_y = ts_z.new_ones(ts_pos_edge_index.size(1))\r\n",
    "        neg_y = ts_z.new_zeros(ts_neg_edge_index.size(1))\r\n",
    "        y = torch.cat([pos_y, neg_y], dim = 0)\r\n",
    "\r\n",
    "        pos_pred = self.ts_decoder(ts_z, ts_pos_edge_index, sigmoid = True)\r\n",
    "        neg_pred = self.ts_decoder(ts_z, ts_neg_edge_index, sigmoid = True)\r\n",
    "        pred = torch.cat([pos_pred, neg_pred], dim = 0)\r\n",
    "\r\n",
    "        y, pred = y.detach().cpu().numpy(), pred.detach().cpu().numpy()\r\n",
    "\r\n",
    "        return roc_auc_score(y, pred), average_precision_score(y, pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: should I just have to encoders rather than GAEs for reactant and product here?\r\n",
    "#       am I trying to learn the latent space for each and combine OR combine them in a way to create TS?\r\n",
    "\r\n",
    "# build models and optimiser\r\n",
    "# base_path = r'Users/rmhavij/3d-reactions/data/'\r\n",
    "base_path = r'data/'\r\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\r\n",
    "val_ratio = 0\r\n",
    "test_ratio = 0.2 # TODO: combine train and test .sdf files for each geom then split (as works better with PyG)\r\n",
    "r_latent_dim = p_latent_dim = ts_latent_dim = 2 # fine for now. may have to include more later.\r\n",
    "\r\n",
    "# reactant data\r\n",
    "r_dataset = ReactionDataset(base_path, geo_file = 'train_r') \r\n",
    "r_data = r_dataset.data\r\n",
    "r_data.train_mask = r_data.val_mask = r_data.test_mask = r_data.y = None\r\n",
    "r_data = train_test_split_edges(data = r_data, val_ratio = val_ratio, test_ratio = test_ratio)\r\n",
    "r_x = r_data.x.to(device)\r\n",
    "r_train_pos_edge_index = r_data.train_pos_edge_index.to(device)\r\n",
    "# reactant encoder\r\n",
    "r_num_node_fs = r_data.num_node_features # = 11\r\n",
    "r_encoder = GAE(MolEncoder(r_num_node_fs, r_latent_dim))\r\n",
    "\r\n",
    "# product data\r\n",
    "p_dataset = ReactionDataset(base_path, geo_file = 'train_p') \r\n",
    "p_data = p_dataset.data\r\n",
    "p_data.train_mask = p_data.val_mask = p_data.test_mask = p_data.y = None\r\n",
    "p_data = train_test_split_edges(data = p_data, val_ratio = val_ratio, test_ratio = test_ratio)\r\n",
    "p_x = p_data.x.to(device)\r\n",
    "p_train_pos_edge_index = p_data.train_pos_edge_index.to(device)\r\n",
    "# product encoder\r\n",
    "p_num_node_fs = r_data.num_node_features # = 11\r\n",
    "p_encoder = GAE(MolEncoder(p_num_node_fs, p_latent_dim))\r\n",
    "\r\n",
    "# ts data\r\n",
    "ts_dataset = ReactionDataset(base_path, geo_file = 'train_ts') \r\n",
    "ts_data = ts_dataset.data\r\n",
    "ts_data.train_mask = ts_data.val_mask = ts_data.test_mask = ts_data.y = None\r\n",
    "ts_data = train_test_split_edges(data = ts_data, val_ratio = val_ratio, test_ratio = test_ratio)\r\n",
    "ts_x = ts_data.x.to(device)\r\n",
    "ts_train_pos_edge_index = ts_data.train_pos_edge_index.to(device)\r\n",
    "# ts decoder\r\n",
    "ts_num_node_fs = ts_data.num_node_features # = 11\r\n",
    "ts_decoder = TSDecoder(ts_latent_dim, ts_num_node_fs)\r\n",
    "\r\n",
    "# ts gae\r\n",
    "ts_gae = TSGAE(r_encoder = r_encoder, p_encoder = p_encoder, ts_decoder = ts_decoder)\r\n",
    "ts_gae = ts_gae.to(device)\r\n",
    "gae_opt = torch.optim.Adam(ts_gae.parameters(), lr = 0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_individual_encoder(encoder, opt, train_pos_edge_index, data):\r\n",
    "    \"\"\" Use this for reactant or product encoder training. \"\"\"\r\n",
    "    encoder.train()\r\n",
    "    opt.zero_grad()\r\n",
    "    z = encoder.encode(data, train_pos_edge_index)\r\n",
    "    loss = encoder.recon_loss(z, train_pos_edge_index)\r\n",
    "    loss.backward(retain_graph = True)\r\n",
    "    opt.step()\r\n",
    "    return z, float(loss)\r\n",
    "\r\n",
    "def train_ts_gae(ts_gae, gae_opt, ts_train_pos_edge_index, r_x, p_x): # pass in ts_x?\r\n",
    "    \"\"\" Train TSGAE.\r\n",
    "        Training this model trains the individual R and P encoders.\r\n",
    "        TODO: how to use R and P encoder losses?\r\n",
    "    \"\"\"\r\n",
    "    ts_gae.train() \r\n",
    "    gae_opt.zero_grad()\r\n",
    "\r\n",
    "    # train r and p encoder\r\n",
    "    #r_z, _ = train_individual_encoder(r_encoder, r_opt, r_pos_edge_index, r_x)\r\n",
    "    #p_z, _ = train_individual_encoder(p_encoder, p_opt, p_pos_edge_index, p_x)\r\n",
    "\r\n",
    "    # combine for ts_z\r\n",
    "    ts_z = ts_gae.combine_reactant_and_product(r_x, p_x, r_train_pos_edge_index, p_train_pos_edge_index)\r\n",
    "    gae_loss = ts_gae.ts_construction_loss(ts_z, ts_train_pos_edge_index)\r\n",
    "    gae_loss.backward(retain_graph = True)\r\n",
    "    gae_opt.step()\r\n",
    "    \r\n",
    "    return float(gae_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    },
    {
     "ename": "NotImplementedError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNotImplementedError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-125-b2e08cbcc37c>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepochs\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 12\u001b[1;33m     \u001b[0mloss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain_ts_gae\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mts_gae\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgae_opt\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mts_train_pos_edge_index\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mr_x\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mp_x\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     13\u001b[0m     \u001b[0mauc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0map\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtest_ts_gae\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mts_gae\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mts_train_pos_edge_index\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mts_data\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtest_pos_edge_index\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mts_data\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtest_neg_edge_index\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Epoch: {:03d}, AUC: {:.4f}, AP: {:.4f}'\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mauc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0map\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-124-1b2b347476b7>\u001b[0m in \u001b[0;36mtrain_ts_gae\u001b[1;34m(ts_gae, gae_opt, ts_train_pos_edge_index, r_x, p_x)\u001b[0m\n\u001b[0;32m     22\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     23\u001b[0m     \u001b[1;31m# combine for ts_z\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 24\u001b[1;33m     \u001b[0mts_z\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mts_gae\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcombine_reactant_and_product\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mr_x\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mp_x\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mr_train_pos_edge_index\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mp_train_pos_edge_index\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     25\u001b[0m     \u001b[0mgae_loss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mts_gae\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mts_construction_loss\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mts_z\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mts_train_pos_edge_index\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     26\u001b[0m     \u001b[0mgae_loss\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mretain_graph\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-118-70955192a929>\u001b[0m in \u001b[0;36mcombine_reactant_and_product\u001b[1;34m(self, r_x, p_x, r_pos_edge_index, p_pos_edge_index)\u001b[0m\n\u001b[0;32m     24\u001b[0m         \"\"\"\n\u001b[0;32m     25\u001b[0m         \u001b[1;31m# encode reactant and product\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 26\u001b[1;33m         \u001b[0mr_z\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mr_encoder\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mr_x\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mr_pos_edge_index\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     27\u001b[0m         \u001b[0mp_z\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mp_encoder\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mp_x\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mp_pos_edge_index\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     28\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\miniconda3\\envs\\3d-rdkit\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    887\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    888\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 889\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    890\u001b[0m         for hook in itertools.chain(\n\u001b[0;32m    891\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\miniconda3\\envs\\3d-rdkit\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_forward_unimplemented\u001b[1;34m(self, *input)\u001b[0m\n\u001b[0;32m    199\u001b[0m         \u001b[0mregistered\u001b[0m \u001b[0mhooks\u001b[0m \u001b[1;32mwhile\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mlatter\u001b[0m \u001b[0msilently\u001b[0m \u001b[0mignores\u001b[0m \u001b[0mthem\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    200\u001b[0m     \"\"\"\n\u001b[1;32m--> 201\u001b[1;33m     \u001b[1;32mraise\u001b[0m \u001b[0mNotImplementedError\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    202\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    203\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNotImplementedError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "def test_ts_gae(ts_gae, ts_train_pos_edge_index, ts_test_pos_edge_index, ts_test_neg_edge_index):\r\n",
    "    ts_gae.eval()\r\n",
    "    with torch.no_grad():\r\n",
    "        #r_z, _ = train_individual_encoder(r_encoder, r_opt, r_pos_edge_index, r_x)\r\n",
    "        #p_z, _ = train_individual_encoder(p_encoder, p_opt, p_pos_edge_index, p_x)\r\n",
    "        ts_z = ts_gae.combine_reactant_and_product(r_x, p_x, r_data.test_pos_edge_index, p_data.test_pos_edge_index)\r\n",
    "    return ts_gae.test(ts_z, ts_test_pos_edge_index, ts_test_neg_edge_index)\r\n",
    "\r\n",
    "epochs = 4\r\n",
    "for epoch in range(1, epochs + 1):\r\n",
    "    print(epoch)\r\n",
    "    loss = train_ts_gae(ts_gae, gae_opt, ts_train_pos_edge_index, r_x, p_x)\r\n",
    "    auc, ap = test_ts_gae(ts_gae, ts_train_pos_edge_index, ts_data.test_pos_edge_index, ts_data.test_neg_edge_index)\r\n",
    "    print('Epoch: {:03d}, AUC: {:.4f}, AP: {:.4f}'.format(epoch, auc, ap))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.6.13 64-bit (conda)",
   "name": "python3613jvsc74a57bd0f4671ad35fdc0609fa675edcd17de5b3092cb55d03f1d9670a78611a41fb18f3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  },
  "orig_nbformat": 2
 },
 "nbformat": 4,
 "nbformat_minor": 2
}