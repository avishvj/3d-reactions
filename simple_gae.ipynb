{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# atom features, bond type, graph connectivity, (x,y,z) coordinates  \n",
    "#   - when we encode the graph, we're doing it through atom features, bond types, and connectivitity (i.e. which atoms are connected to each other and how?)\n",
    "#   - the coordinate-based representation is particularly useful \n",
    "#   - for reaction centre, find adjacency matrix differences then map to 3D matrix\n",
    "\n",
    "# convert MLP to GNN by swapping torch.nn.linear with PyG's GNN operators e.g. GCN layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\r\n",
    "import torch.nn as nn\r\n",
    "from torch_geometric.nn import GCNConv, GAE\r\n",
    "from torch_geometric.utils import train_test_split_edges\r\n",
    "\r\n",
    "#import sys\r\n",
    "#sys.path.insert(0, \"Users/rmhavij/3d-reactions/\") # azure again\r\n",
    "from ts_vae.data_processors.grambow_processor import ReactionDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# normal:\r\n",
    "base_path = r'data/'\r\n",
    "# azure base_path = r'Users/rmhavij/3d-reactions/data/'\r\n",
    "r_dataset = ReactionDataset(base_path, geo_file = 'train_r') \r\n",
    "\r\n",
    "data = r_dataset.data\r\n",
    "data.train_mask = data.val_mask = data.test_mask = data.y = None\r\n",
    "data = train_test_split_edges(data = data, val_ratio = 0, test_ratio = 0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LinearEncoder(nn.Module):\r\n",
    "    def __init__(self, in_channels, out_channels):\r\n",
    "        super(LinearEncoder, self).__init__()\r\n",
    "        # use single GC to get embeddings for nodes here\r\n",
    "        self.conv = GCNConv(in_channels, out_channels)\r\n",
    "    \r\n",
    "    def forward(self, x, edge_index):\r\n",
    "        # no relu for linearity\r\n",
    "        return self.conv(x, edge_index)\r\n",
    "    \r\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_node_fs = r_dataset.data.num_node_features # = 11\r\n",
    "out_channels = 2\r\n",
    "\r\n",
    "# build model and optimiser\r\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\r\n",
    "model = GAE(LinearEncoder(num_node_fs, out_channels))\r\n",
    "model = model.to(device)\r\n",
    "x = data.x.to(device)\r\n",
    "train_pos_edge_index = data.train_pos_edge_index.to(device)\r\n",
    "opt = torch.optim.Adam(model.parameters(), lr=0.01)\r\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 001, AUC: 0.7729, AP: 0.6303\n",
      "Epoch: 002, AUC: 0.7727, AP: 0.6303\n",
      "Epoch: 003, AUC: 0.7730, AP: 0.6306\n",
      "Epoch: 004, AUC: 0.7732, AP: 0.6309\n",
      "Epoch: 005, AUC: 0.7728, AP: 0.6305\n",
      "Epoch: 006, AUC: 0.7729, AP: 0.6306\n",
      "Epoch: 007, AUC: 0.7735, AP: 0.6312\n",
      "Epoch: 008, AUC: 0.7737, AP: 0.6315\n",
      "Epoch: 009, AUC: 0.7743, AP: 0.6321\n",
      "Epoch: 010, AUC: 0.7747, AP: 0.6327\n"
     ]
    }
   ],
   "source": [
    "def train():\r\n",
    "    model.train() # sets training flag and params (doesn't actually train model!)\r\n",
    "    opt.zero_grad()\r\n",
    "    z = model.encode(x, train_pos_edge_index)\r\n",
    "    loss = model.recon_loss(z, train_pos_edge_index)\r\n",
    "    loss.backward()\r\n",
    "    opt.step()\r\n",
    "    return float(loss)\r\n",
    "\r\n",
    "def test(pos_edge_index, neg_edge_index):\r\n",
    "    model.eval()\r\n",
    "    with torch.no_grad():\r\n",
    "        z = model.encode(x, train_pos_edge_index)\r\n",
    "    return model.test(z, pos_edge_index, neg_edge_index)\r\n",
    "\r\n",
    "epochs = 10\r\n",
    "for epoch in range(1, epochs + 1):\r\n",
    "    loss = train()\r\n",
    "    auc, ap = test(data.test_pos_edge_index, data.test_neg_edge_index)\r\n",
    "    print('Epoch: {:03d}, AUC: {:.4f}, AP: {:.4f}'.format(epoch, auc, ap))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "__init__() missing 1 required positional argument: 'ts_data'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-20-c4ba8399a52d>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     42\u001b[0m \u001b[1;31m# ts decoder\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     43\u001b[0m \u001b[0mts_num_node_fs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mts_data\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnum_node_features\u001b[0m \u001b[1;31m# = 11\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 44\u001b[1;33m \u001b[0mts_decoder\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mTSDecoder\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mts_latent_dim\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mts_num_node_fs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     45\u001b[0m \u001b[0mts_decoder\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mts_decoder\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     46\u001b[0m \u001b[0mts_opt\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptim\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mAdam\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mts_encoder\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0.01\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: __init__() missing 1 required positional argument: 'ts_data'"
     ]
    }
   ],
   "source": [
    "# build models and optimiser\r\n",
    "# base_path = r'Users/rmhavij/3d-reactions/data/'\r\n",
    "base_path = r'data/'\r\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\r\n",
    "val_ratio = 0\r\n",
    "test_ratio = 0.2 # TODO: combine train and test .sdf files for each geom then split (as works better with PyG)\r\n",
    "r_latent_dim = p_latent_dim = ts_latent_dim = 2 # fine for now. may have to include more later.\r\n",
    "\r\n",
    "# reactant data\r\n",
    "r_dataset = ReactionDataset(base_path, geo_file = 'train_r') \r\n",
    "r_data = r_dataset.data\r\n",
    "r_data.train_mask = r_data.val_mask = r_data.test_mask = r_data.y = None\r\n",
    "r_data = train_test_split_edges(data = r_data, val_ratio = val_ratio, test_ratio = test_ratio)\r\n",
    "r_x = r_data.x.to(device)\r\n",
    "r_pos_edge_index = r_data.train_pos_edge_index.to(device)\r\n",
    "# reactant encoder\r\n",
    "r_num_node_fs = r_data.num_node_features # = 11\r\n",
    "r_encoder = GAE(LinearEncoder(r_num_node_fs, r_latent_dim))\r\n",
    "r_encoder = r_encoder.to(device)\r\n",
    "r_opt = torch.optim.Adam(r_encoder.parameters(), lr = 0.01)\r\n",
    "\r\n",
    "# product data\r\n",
    "p_dataset = ReactionDataset(base_path, geo_file = 'train_p') \r\n",
    "p_data = p_dataset.data\r\n",
    "p_data.train_mask = p_data.val_mask = p_data.test_mask = p_data.y = None\r\n",
    "p_data = train_test_split_edges(data = p_data, val_ratio = val_ratio, test_ratio = test_ratio)\r\n",
    "p_x = p_data.x.to(device)\r\n",
    "p_pos_edge_index = p_data.train_pos_edge_index.to(device)\r\n",
    "# product encoder\r\n",
    "p_num_node_fs = r_data.num_node_features # = 11\r\n",
    "p_encoder = GAE(LinearEncoder(p_num_node_fs, p_latent_dim))\r\n",
    "p_encoder = p_encoder.to(device)\r\n",
    "p_opt = torch.optim.Adam(p_encoder.parameters(), lr = 0.01)\r\n",
    "\r\n",
    "# ts data\r\n",
    "ts_dataset = ReactionDataset(base_path, geo_file = 'train_ts') \r\n",
    "ts_data = ts_dataset.data\r\n",
    "ts_data.train_mask = ts_data.val_mask = ts_data.test_mask = ts_data.y = None\r\n",
    "ts_data = train_test_split_edges(data = ts_data, val_ratio = val_ratio, test_ratio = test_ratio)\r\n",
    "ts_x = ts_data.x.to(device)\r\n",
    "ts_pos_edge_index = ts_data.train_pos_edge_index.to(device)\r\n",
    "# ts decoder\r\n",
    "ts_num_node_fs = ts_data.num_node_features # = 11\r\n",
    "ts_decoder = TSDecoder(ts_latent_dim, ts_num_node_fs)\r\n",
    "ts_decoder = ts_decoder.to(device)\r\n",
    "ts_opt = torch.optim.Adam(ts_encoder.parameters(), lr = 0.01)\r\n",
    "\r\n",
    "# note: I have GAEs for LinearEncoder here. not for ts decoder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TSDecoder(torch.nn.Module):\r\n",
    "    \"\"\" Take TS embedding (i.e. combined R-P embedding) and decode to TS geometry. \"\"\"\r\n",
    "    # ref: right now, just using InnerProductDecoder\r\n",
    "\r\n",
    "    def __init__(self, latent_dim, geometry_dim):\r\n",
    "        super(TSDecoder, self).__init__()\r\n",
    "        self.ts_data = ts_data\r\n",
    "\r\n",
    "    def forward(self, ts_z, ts_edge_index, sigmoid=True):\r\n",
    "        \"\"\" Decode TS embedding into edge probabilities for the given node-pairs of TS edge_index. \"\"\"\r\n",
    "        value = (ts_z[ts_edge_index[0]] * ts_z[ts_edge_index[1]]).sum(dim=1)\r\n",
    "        return torch.sigmoid(value) if sigmoid else value\r\n",
    "\r\n",
    "    def forward_all(self, z, sigmoid=True):\r\n",
    "        \"\"\" Decode latent embeddings into probabilistic adjacency matrix. \"\"\"\r\n",
    "        adj = torch.matmul(z, z.t())\r\n",
    "        return torch.sigmoid(adj) if sigmoid else adj\r\n",
    "\r\n",
    "class MolEncoder(nn.Module):\r\n",
    "    \"\"\" Takes in geometry data and creates embedding. Used for reactants OR products, not both. \"\"\"\r\n",
    "    # based off LinearEncoder\r\n",
    "\r\n",
    "    def __init__(self, in_channels, out_channels, geometry_data):\r\n",
    "        super(MolEncoder, self).__init__()\r\n",
    "        self.geometry_data = geometry_data\r\n",
    "        # single GC to get embeddings for nodes here\r\n",
    "        self.conv = GCNConv(in_channels, out_channels)\r\n",
    "    \r\n",
    "    def forward(self, x, edge_index):\r\n",
    "        # no relu for linearity\r\n",
    "        return self.conv(x, edge_index)\r\n",
    "\r\n",
    "    # TODO: try these funcs; may need to pass in other args later; add these to decoder and TSVAE too\r\n",
    "    def save(self, path):\r\n",
    "        \"\"\" Save model to the path specified. \"\"\"\r\n",
    "        torch.save(self.state_dict(), path)\r\n",
    "    \r\n",
    "    def load(self, path):\r\n",
    "        \"\"\" Load model from path specified. \"\"\"\r\n",
    "        model_weights = torch.load(path)\r\n",
    "        self.load_state_dict(model_weights)\r\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_auc_score, average_precision_score\r\n",
    "from torch_geometric.utils import (negative_sampling, remove_self_loops, add_self_loops)\r\n",
    "\r\n",
    "EPS = 1e-15\r\n",
    "\r\n",
    "class TSGAE(nn.Module):\r\n",
    "    \"\"\" Takes in reactant encoder, product encoder, transition state decoder.\r\n",
    "        Creates embeddings for reactants and products. \r\n",
    "        Combines these reactant and product embeddings to create a transition state.\r\n",
    "        TODO: do I pass in data here?\r\n",
    "    \"\"\"\r\n",
    "\r\n",
    "    def __init__(self, r_encoder, p_encoder, ts_decoder, r_data, p_data, ts_data):\r\n",
    "        super(TSGAE, self).__init__()\r\n",
    "        self.r_encoder = r_encoder\r\n",
    "        self.p_encoder = p_encoder\r\n",
    "        self.ts_decoder = ts_decoder\r\n",
    "        self.r_data = r_data\r\n",
    "        self.p_data = p_data\r\n",
    "        self.ts_data = ts_data\r\n",
    "        TSGAE.reset_parameters(self)\r\n",
    "\r\n",
    "    def reset_parameters(self):\r\n",
    "        self.reset_model()\r\n",
    "        self.reset_data()\r\n",
    "\r\n",
    "    def reset_model(self):\r\n",
    "        reset(self.r_encoder)\r\n",
    "        reset(self.p_encoder)\r\n",
    "        reset(self.ts_decoder)\r\n",
    "\r\n",
    "    def reset_data(self):\r\n",
    "        reset(self.r_data)\r\n",
    "        reset(self.p_data)\r\n",
    "        reset(self.ts_data)\r\n",
    "\r\n",
    "    def encode_reactant(self):\r\n",
    "        return self.r_encoder()\r\n",
    "\r\n",
    "    def encode_product(self):\r\n",
    "        return self.p_encoder()\r\n",
    "\r\n",
    "    def combine_reactant_and_product(self, r_z, p_z):\r\n",
    "        \"\"\" Encode reactant and product, then combine their embeddings to get TS embedding.\r\n",
    "            Each encoder produces an embedding for each node of the input molecule.\r\n",
    "            TODO: different combination methods (e.g. concat z vectors so have dim=2d, multiply?) \r\n",
    "            TODO: confused here about whether I return encoder or z from encoder?\r\n",
    "            TODO: take in data?\r\n",
    "        \"\"\"\r\n",
    "        ### first go\r\n",
    "        # encode reactant and product\r\n",
    "        #r_z = self.r_encoder(*args, **kwargs)\r\n",
    "        #p_z = self.p_encoder(*args, **kwargs)\r\n",
    "        # trying first with simpler linear combination\r\n",
    "        #ts_z = r_z + p_z\r\n",
    "        \r\n",
    "        ### second go\r\n",
    "        ts_z = r_z + p_z\r\n",
    "        return ts_z\r\n",
    "        \r\n",
    "    def decode(self, generated_ts_latent, ts_data):\r\n",
    "        \"\"\" Runs the TS decoder to decode to TS (as probabilistic adjacency matrix) and computes edge probabilities. \r\n",
    "            TODO: decode to actual TS geometry. Can start with NL-WLS from MIT, then add in coordinate features, etc.\r\n",
    "        \"\"\"\r\n",
    "        return self.ts_decoder(generated_ts_latent, ts_data)\r\n",
    "\r\n",
    "    def ts_construction_loss(self, ts_z, ts_pos_edge_index, ts_neg_edge_index = None):\r\n",
    "        \"\"\" Compute BCE for positive edges and, optionally, for negative sampled edges. \r\n",
    "            If negative edges not given, uses negative sampling to calculate.\r\n",
    "            TODO: more specific loss func?\r\n",
    "        \"\"\"\r\n",
    "        pos_loss = - torch.log(self.ts_decoder(ts_z, ts_pos_edge_index, sigmoid = True) + EPS).mean()\r\n",
    "        \r\n",
    "        # don't include self-loops in neg samples\r\n",
    "        ts_pos_edge_index, _ = remove_self_loops(ts_pos_edge_index)\r\n",
    "        ts_pos_edge_index, _ = add_self_loops(ts_pos_edge_index)\r\n",
    "        if ts_neg_edge_index is None:\r\n",
    "            ts_neg_edge_index = negative_sampling(ts_pos_edge_index, ts_z.size(0))\r\n",
    "        neg_loss = - torch.log(1 - self.ts_decoder(ts_z, ts_neg_edge_index, sigmoid = True) + EPS).mean()\r\n",
    "\r\n",
    "        return pos_loss + neg_loss\r\n",
    "\r\n",
    "    def test(self, ts_z, ts_pos_edge_index, ts_neg_edge_index):\r\n",
    "        \"\"\" Compute ROC-AUC and average precision (AP) scores. \r\n",
    "            TODO: what is y here?\r\n",
    "        \"\"\"\r\n",
    "        pos_y = ts_z.new_ones(ts_pos_edge_index.size(1))\r\n",
    "        neg_y = ts_z.new_zeros(ts_neg_edge_index.size(1))\r\n",
    "        y = torch.cat([pos_y, neg_y], dim = 0)\r\n",
    "\r\n",
    "        pos_pred = self.ts_decoder(ts_z, ts_pos_edge_index, sigmoid = True)\r\n",
    "        neg_pred = self.ts_decoder(ts_z, ts_neg_edge_index, sigmoid = True)\r\n",
    "        pred = torch.cat([pos_pred, neg_pred], dim = 0)\r\n",
    "\r\n",
    "        y, pred = y.detach().cpu().numpy(), pred.detach().cpu().numpy()\r\n",
    "\r\n",
    "        return roc_auc_score(y, pred), average_precision_score(y, pred)\r\n",
    "\r\n",
    "def reset(nn):\r\n",
    "    def _reset(item):\r\n",
    "        if hasattr(item, 'reset_parameters'):\r\n",
    "            item.reset_parameters()\r\n",
    "\r\n",
    "    if nn is not None:\r\n",
    "        if hasattr(nn, 'children') and len(list(nn.children())) > 0:\r\n",
    "            for item in nn.children():\r\n",
    "                _reset(item)\r\n",
    "        else:\r\n",
    "            _reset(nn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: should I just have to encoders rather than GAEs for reactant and product here?\r\n",
    "#       am I trying to learn the latent space for each and combine or combine them in a way to create TS?\r\n",
    "\r\n",
    "# build models and optimiser\r\n",
    "# base_path = r'Users/rmhavij/3d-reactions/data/'\r\n",
    "base_path = r'data/'\r\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\r\n",
    "val_ratio = 0\r\n",
    "test_ratio = 0.2 # TODO: combine train and test .sdf files for each geom then split (as works better with PyG)\r\n",
    "r_latent_dim = p_latent_dim = ts_latent_dim = 2 # fine for now. may have to include more later.\r\n",
    "\r\n",
    "# reactant data\r\n",
    "r_dataset = ReactionDataset(base_path, geo_file = 'train_r') \r\n",
    "r_data = r_dataset.data\r\n",
    "r_data.train_mask = r_data.val_mask = r_data.test_mask = r_data.y = None\r\n",
    "r_data = train_test_split_edges(data = r_data, val_ratio = val_ratio, test_ratio = test_ratio)\r\n",
    "r_x = r_data.x.to(device)\r\n",
    "r_train_pos_edge_index = r_data.train_pos_edge_index.to(device)\r\n",
    "# reactant encoder\r\n",
    "r_num_node_fs = r_data.num_node_features # = 11\r\n",
    "r_encoder = GAE(LinearEncoder(r_num_node_fs, r_latent_dim))\r\n",
    "r_opt = torch.optim.Adam(r_encoder.parameters(), lr = 0.01)\r\n",
    "\r\n",
    "# product data\r\n",
    "p_dataset = ReactionDataset(base_path, geo_file = 'train_p') \r\n",
    "p_data = p_dataset.data\r\n",
    "p_data.train_mask = p_data.val_mask = p_data.test_mask = p_data.y = None\r\n",
    "p_data = train_test_split_edges(data = p_data, val_ratio = val_ratio, test_ratio = test_ratio)\r\n",
    "p_x = p_data.x.to(device)\r\n",
    "p_train_pos_edge_index = p_data.train_pos_edge_index.to(device)\r\n",
    "# product encoder\r\n",
    "p_num_node_fs = r_data.num_node_features # = 11\r\n",
    "p_encoder = GAE(LinearEncoder(p_num_node_fs, p_latent_dim))\r\n",
    "p_opt = torch.optim.Adam(p_encoder.parameters(), lr = 0.01)\r\n",
    "\r\n",
    "# ts data\r\n",
    "ts_dataset = ReactionDataset(base_path, geo_file = 'train_ts') \r\n",
    "ts_data = ts_dataset.data\r\n",
    "ts_data.train_mask = ts_data.val_mask = ts_data.test_mask = ts_data.y = None\r\n",
    "ts_data = train_test_split_edges(data = ts_data, val_ratio = val_ratio, test_ratio = test_ratio)\r\n",
    "ts_x = ts_data.x.to(device)\r\n",
    "ts_train_pos_edge_index = ts_data.train_pos_edge_index.to(device)\r\n",
    "# ts decoder (no opt)\r\n",
    "ts_num_node_fs = ts_data.num_node_features # = 11\r\n",
    "ts_decoder = TSDecoder(ts_latent_dim, ts_num_node_fs)\r\n",
    "\r\n",
    "# ts gae\r\n",
    "ts_gae = TSGAE(r_encoder = r_encoder, p_encoder = p_encoder, ts_decoder = ts_decoder,\r\n",
    "                r_data = r_data, p_data = p_data, ts_data = ts_data)\r\n",
    "ts_gae = ts_gae.to(device)\r\n",
    "gae_opt = torch.optim.Adam(model.parameters(), lr=0.01)\r\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_individual_encoder(encoder, opt, train_pos_edge_index, data):\r\n",
    "    \"\"\" Use this for reactant or product encoder training. \"\"\"\r\n",
    "    encoder.train()\r\n",
    "    opt.zero_grad()\r\n",
    "    z = encoder.encode(data, train_pos_edge_index)\r\n",
    "    loss = encoder.recon_loss(z, train_pos_edge_index)\r\n",
    "    loss.backward()\r\n",
    "    opt.step()\r\n",
    "    return z, float(loss)\r\n",
    "\r\n",
    "def train_ts_gae(ts_gae, gae_opt, ts_train_pos_edge_index):\r\n",
    "    \"\"\" Train TSGAE.\r\n",
    "        Training this model trains the individual R and P encoders.\r\n",
    "    \"\"\"\r\n",
    "    ts_gae.train() \r\n",
    "    gae_opt.zero_grad()\r\n",
    "    ts_z = ts_gae.combine_reactant_and_product()\r\n",
    "    gae_loss = ts_gae.ts_construction_loss(ts_z, ts_train_pos_edge_index)\r\n",
    "    gae_loss.backward()\r\n",
    "    gae_opt.step()\r\n",
    "    # r_z, r_loss = train_individual_encoder(r_encoder, r_opt, r_pos_edge_index, r_data)\r\n",
    "    # p_z, p_loss = train_individual_encoder(p_encoder, p_opt, p_pos_edge_index, p_data)\r\n",
    "    return float(gae_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "ename": "NotImplementedError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNotImplementedError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-33-a3dd5e69d925>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[0mepochs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m10\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepochs\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 9\u001b[1;33m     \u001b[0mloss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain_ts_gae\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mts_gae\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgae_opt\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mts_train_pos_edge_index\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     10\u001b[0m     \u001b[0mauc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0map\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtest\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mts_data\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtest_pos_edge_index\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mts_data\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtest_neg_edge_index\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Epoch: {:03d}, AUC: {:.4f}, AP: {:.4f}'\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mauc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0map\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-30-701e5763d072>\u001b[0m in \u001b[0;36mtrain_ts_gae\u001b[1;34m(ts_gae, gae_opt, ts_pos_edge_index)\u001b[0m\n\u001b[0;32m     15\u001b[0m     \u001b[0mts_gae\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     16\u001b[0m     \u001b[0mgae_opt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 17\u001b[1;33m     \u001b[0mts_z\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mts_gae\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcombine_reactant_and_product\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     18\u001b[0m     \u001b[0mgae_loss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mts_gae\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mts_construction_loss\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mts_z\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mts_pos_edge_index\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     19\u001b[0m     \u001b[0mgae_loss\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-27-01ef5c0fbf08>\u001b[0m in \u001b[0;36mcombine_reactant_and_product\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m     43\u001b[0m         \"\"\"\n\u001b[0;32m     44\u001b[0m         \u001b[1;31m# encode reactant and product\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 45\u001b[1;33m         \u001b[0mr_z\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mr_encoder\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     46\u001b[0m         \u001b[0mp_z\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mp_encoder\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     47\u001b[0m         \u001b[1;31m# trying first with simpler linear combination\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\miniconda3\\envs\\3d-rdkit\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    887\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    888\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 889\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    890\u001b[0m         for hook in itertools.chain(\n\u001b[0;32m    891\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\miniconda3\\envs\\3d-rdkit\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_forward_unimplemented\u001b[1;34m(self, *input)\u001b[0m\n\u001b[0;32m    199\u001b[0m         \u001b[0mregistered\u001b[0m \u001b[0mhooks\u001b[0m \u001b[1;32mwhile\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mlatter\u001b[0m \u001b[0msilently\u001b[0m \u001b[0mignores\u001b[0m \u001b[0mthem\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    200\u001b[0m     \"\"\"\n\u001b[1;32m--> 201\u001b[1;33m     \u001b[1;32mraise\u001b[0m \u001b[0mNotImplementedError\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    202\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    203\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNotImplementedError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "def test_ts_gae(ts_gae, ts_train_pos_edge_index, ts_test_pos_edge_index, ts_test_neg_edge_index):\r\n",
    "    ts_gae.eval()\r\n",
    "    with torch.no_grad():\r\n",
    "        ts_z = ts_gae.combine_reactant_and_product(x, ts_train_pos_edge_index)\r\n",
    "    return ts_gae.test(ts_z, ts_test_pos_edge_index, ts_test_neg_edge_index)\r\n",
    "\r\n",
    "epochs = 10\r\n",
    "for epoch in range(1, epochs + 1):\r\n",
    "    loss = train_ts_gae(ts_gae, gae_opt, ts_train_pos_edge_index)\r\n",
    "    auc, ap = test(ts_data.test_pos_edge_index, ts_data.test_neg_edge_index)\r\n",
    "    print('Epoch: {:03d}, AUC: {:.4f}, AP: {:.4f}'.format(epoch, auc, ap))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_individual_geometry(geometry_encoder, opt, pos_edge_indices):\r\n",
    "    # use this on reactant or product\r\n",
    "    # TODO: where is this meant to be???\r\n",
    "    geometry_encoder.train()\r\n",
    "    opt.zero_grad()\r\n",
    "    z = geometry_encoder.encode(x, pos_edge_indices)\r\n",
    "    loss = geometry_encoder.recon_loss(z, pos_edge_indices)\r\n",
    "    loss.backward()\r\n",
    "    opt.step()\r\n",
    "    return z, float(loss)\r\n",
    "\r\n",
    "def train_reaction(ts_gae, ts_opt, ts_pos_edge_index):\r\n",
    "    \"\"\" Train reactant and product together then decode to TS. \"\"\"\r\n",
    "    ts_gae.train() # training this model should train the individual encoders\r\n",
    "    ts_opt.zero_grad()\r\n",
    "    ts_embedding = ts_gae.combine_reactant_and_product() # atm, pass in r and p data to this func\r\n",
    "    ts_loss = ts_gae.recon_loss(ts_embedding, ts_pos_edge_index)\r\n",
    "    ts_loss.backward()\r\n",
    "    ts_opt.step()\r\n",
    "    return float(loss)\r\n",
    "\r\n",
    "def test_reaction(ts_gae, ts_test_pos_edges, ts_test_neg_edges):\r\n",
    "    ts_gae.eval()\r\n",
    "    with torch.no_grad():\r\n",
    "        ts_embedding = model.encode(ts_data, ts_train_pos_edges)\r\n",
    "    return ts_gae.test(ts_embedding, ts_test_pos_edges, ts_test_neg_edges)\r\n",
    "\r\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lucky's work\n",
    "# PairFeatures: a manual MP I think. it has to be otherwise what he's doing isn't a GNN at all.\n",
    "\n",
    "# set edges\n",
    "#   iterate:\n",
    "#       compute features (i.e. MP) -> MLP(features) -> update edges\n",
    "#       compute features (i.e. MP) -> MLP(MLP(edges)) -> update vertices"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.6.13 64-bit (conda)",
   "name": "python3613jvsc74a57bd0f4671ad35fdc0609fa675edcd17de5b3092cb55d03f1d9670a78611a41fb18f3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  },
  "orig_nbformat": 2
 },
 "nbformat": 4,
 "nbformat_minor": 2
}