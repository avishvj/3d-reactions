{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# atom features, bond type, graph connectivity, (x,y,z) coordinates  \n",
    "#   - when we encode the graph, we're doing it through atom features, bond types, and connectivitity (i.e. which atoms are connected to each other and how?)\n",
    "#   - the coordinate-based representation is particularly useful \n",
    "#   - for reaction centre, find adjacency matrix differences then map to 3D matrix\n",
    "\n",
    "# convert MLP to GNN by swapping torch.nn.linear with PyG's GNN operators e.g. GCN layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\r\n",
    "import torch.nn as nn\r\n",
    "from torch_geometric.nn import GCNConv, GAE\r\n",
    "from torch_geometric.utils import train_test_split_edges\r\n",
    "\r\n",
    "#import sys\r\n",
    "#sys.path.insert(0, \"Users/rmhavij/3d-reactions/\") # azure again\r\n",
    "from ts_vae.data_processors.grambow_processor import ReactionDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# normal:\r\n",
    "base_path = r'data/'\r\n",
    "# azure base_path = r'Users/rmhavij/3d-reactions/data/'\r\n",
    "r_dataset = ReactionDataset(base_path, geo_file = 'train_r') \r\n",
    "\r\n",
    "data = r_dataset.data\r\n",
    "data.train_mask = data.val_mask = data.test_mask = data.y = None\r\n",
    "data = train_test_split_edges(data = data, val_ratio = 0, test_ratio = 0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LinearEncoder(nn.Module):\r\n",
    "    def __init__(self, in_channels, out_channels):\r\n",
    "        super(LinearEncoder, self).__init__()\r\n",
    "        # use single GC to get embeddings for nodes here\r\n",
    "        self.conv = GCNConv(in_channels, out_channels)\r\n",
    "    \r\n",
    "    def forward(self, x, edge_index):\r\n",
    "        # no relu for linearity\r\n",
    "        return self.conv(x, edge_index)\r\n",
    "    \r\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_node_fs = r_dataset.data.num_node_features # = 11\r\n",
    "out_channels = 2\r\n",
    "\r\n",
    "# build model and optimiser\r\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\r\n",
    "model = GAE(LinearEncoder(num_node_fs, out_channels))\r\n",
    "model = model.to(device)\r\n",
    "x = data.x.to(device)\r\n",
    "train_pos_edge_index = data.train_pos_edge_index.to(device)\r\n",
    "opt = torch.optim.Adam(model.parameters(), lr=0.01)\r\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 001, AUC: 0.7729, AP: 0.6303\n",
      "Epoch: 002, AUC: 0.7727, AP: 0.6303\n",
      "Epoch: 003, AUC: 0.7730, AP: 0.6306\n",
      "Epoch: 004, AUC: 0.7732, AP: 0.6309\n",
      "Epoch: 005, AUC: 0.7728, AP: 0.6305\n",
      "Epoch: 006, AUC: 0.7729, AP: 0.6306\n",
      "Epoch: 007, AUC: 0.7735, AP: 0.6312\n",
      "Epoch: 008, AUC: 0.7737, AP: 0.6315\n",
      "Epoch: 009, AUC: 0.7743, AP: 0.6321\n",
      "Epoch: 010, AUC: 0.7747, AP: 0.6327\n"
     ]
    }
   ],
   "source": [
    "def train():\n",
    "    model.train()\n",
    "    opt.zero_grad()\n",
    "    z = model.encode(x, train_pos_edge_index)\n",
    "    loss = model.recon_loss(z, train_pos_edge_index)\n",
    "    loss.backward()\n",
    "    opt.step()\n",
    "    return float(loss)\n",
    "\n",
    "def test(pos_edge_index, neg_edge_index):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        z = model.encode(x, train_pos_edge_index)\n",
    "    return model.test(z, pos_edge_index, neg_edge_index)\n",
    "\n",
    "epochs = 10\n",
    "for epoch in range(1, epochs + 1):\n",
    "    loss = train()\n",
    "    auc, ap = test(data.test_pos_edge_index, data.test_neg_edge_index)\n",
    "    print('Epoch: {:03d}, AUC: {:.4f}, AP: {:.4f}'.format(epoch, auc, ap))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# build models and optimiser\r\n",
    "# base_path = r'Users/rmhavij/3d-reactions/data/'\r\n",
    "base_path = r'data/'\r\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\r\n",
    "\r\n",
    "# reactant data\r\n",
    "r_dataset = ReactionDataset(base_path, geo_file = 'train_r') \r\n",
    "reactant_data = r_dataset.data\r\n",
    "reactant_data.train_mask = reactant_data.val_mask = reactant_data.test_mask = reactant_data.y = None\r\n",
    "reactant_data = train_test_split_edges(data = reactant_data, val_ratio = 0, test_ratio = 0.2)\r\n",
    "\r\n",
    "# reactant encoder dimensions\r\n",
    "num_node_fs = r_dataset.data.num_node_features # = 11\r\n",
    "out_channels = 2\r\n",
    "\r\n",
    "# reactant encoder\r\n",
    "reactant_encoder = GAE(LinearEncoder(num_node_fs, out_channels))\r\n",
    "reactant_encoder = reactant_encoder.to(device)\r\n",
    "x = reactant_data.x.to(device)\r\n",
    "reactant_pos_edges = reactant_data.train_pos_edge_index.to(device)\r\n",
    "reactant_opt = torch.optim.Adam(reactant_encoder.parameters(), lr=0.01)\r\n",
    "\r\n",
    "# product data\r\n",
    "p_dataset = ReactionDataset(base_path, geo_file = 'train_p') \r\n",
    "product_data = p_dataset.data\r\n",
    "product_data.train_mask = product_data.val_mask = product_data.test_mask = product_data.y = None\r\n",
    "product_data = train_test_split_edges(data = product_data, val_ratio = 0, test_ratio = 0.2)\r\n",
    "\r\n",
    "# product data dimensions\r\n",
    "num_node_fs = p_dataset.data.num_node_features # = 11 (this is same as reactants here but useful anyway)\r\n",
    "out_channels = 2\r\n",
    "\r\n",
    "# product encoder\r\n",
    "product_encoder = GAE(LinearEncoder(num_node_fs, out_channels))\r\n",
    "product_encoder = product_encoder.to(device)\r\n",
    "x = product_data.x.to(device)\r\n",
    "product_pos_edges = product_data.train_pos_edge_index.to(device)\r\n",
    "product_opt = torch.optim.Adam(product_encoder.parameters(), lr=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_auc_score, average_precision_score\r\n",
    "\r\n",
    "class TSGAE(nn.Module):\r\n",
    "    \"\"\" Takes in reactant encoder, product encoder, transition state decoder.\r\n",
    "        Creates embeddings for reactants and products. \r\n",
    "        Combines these reactant and product embeddings to create a transition state.\r\n",
    "        TODO: do I pass in data here?\r\n",
    "    \"\"\"\r\n",
    "\r\n",
    "    def __init__(self, reactant_encoder, product_encoder, ts_decoder, in_channels, out_channels):\r\n",
    "\r\n",
    "        super(TSGAE, self).__init__()\r\n",
    "\r\n",
    "        self.reactant_encoder = reactant_encoder\r\n",
    "        self.product_encoder = product_encoder\r\n",
    "        self.ts_decoder = ts_decoder\r\n",
    "\r\n",
    "        TSGAE.reset_parameters(self)\r\n",
    "\r\n",
    "    # not sure if this func needed\r\n",
    "    def reset_parameters(self):\r\n",
    "        reset(self.reactant_encoder)\r\n",
    "        reset(self.product_encoder)\r\n",
    "        reset(self.ts_decoder)\r\n",
    "\r\n",
    "    def combine_reactant_and_product(self, reactant_data, product_data):\r\n",
    "        \"\"\" Encode reactant and product, then combine their embeddings to get TS embedding.\r\n",
    "            TODO: different combination methods (e.g. concat z vectors so have dim=2d, multiply?) \r\n",
    "            TODO: confused here about whether I return encoder or z from encoder?\r\n",
    "        \"\"\"\r\n",
    "        # encode reactant and product. TODO: make them take data and return embeddings!\r\n",
    "        r_embedding = self.reactant_encoder(reactant_data)\r\n",
    "        p_embedding = self.product_encoder(product_data)\r\n",
    "\r\n",
    "        # trying first with simpler linear combination\r\n",
    "        linear_comb = r_embedding + p_embedding\r\n",
    "\r\n",
    "        # return self.encoder(*args, **kwargs)\r\n",
    "        return linear_comb\r\n",
    "        \r\n",
    "\r\n",
    "    def decode(self, ts_data):\r\n",
    "        \"\"\" Runs the TS decoder to decode to TS (as probabilistic adjacency matrix) and computes edge probabilities. \r\n",
    "            TODO: decode to actual TS geometry. Can start with NL-WLS from MIT, then add in coordinate features, etc.\r\n",
    "        \"\"\"\r\n",
    "        return self.ts_decoder(ts_data)\r\n",
    "\r\n",
    "    def ts_creation_loss(self, reactant_z, reactant_pos_edges, reactant_neg_edges=None, product_z, product_pos_edges, product_neg_edges=None):\r\n",
    "        \"\"\" Compute BCE for positive edges and negative sampled (optional) edges. \"\"\"\r\n",
    "\r\n",
    "        pos_loss = -torch.log(self.decoder(z, pos_edge_index, sigmoid=True) + EPS).mean()\r\n",
    "\r\n",
    "        # Do not include self-loops in negative samples\r\n",
    "        pos_edge_index, _ = remove_self_loops(pos_edge_index)\r\n",
    "        pos_edge_index, _ = add_self_loops(pos_edge_index)\r\n",
    "        if neg_edge_index is None:\r\n",
    "            neg_edge_index = negative_sampling(pos_edge_index, z.size(0))\r\n",
    "        neg_loss = -torch.log(1 - self.decoder(z, neg_edge_index, sigmoid=True) + EPS).mean()\r\n",
    "\r\n",
    "        return pos_loss + neg_loss\r\n",
    "\r\n",
    "\r\n",
    "    def test(self, ts_z, pos_edge_index, neg_edge_index):\r\n",
    "        \"\"\" Compute area under ROC curve (AUC) and average precision (AP) scores. \"\"\"\r\n",
    "\r\n",
    "        pos_y = ts_z.new_ones(pos_edge_index.size(1))\r\n",
    "        neg_y = ts_z.new_zeros(neg_edge_index.size(1))\r\n",
    "        y = torch.cat([pos_y, neg_y], dim=0)\r\n",
    "\r\n",
    "        pos_pred = self.decoder(ts_z, pos_edge_index, sigmoid=True)\r\n",
    "        neg_pred = self.decoder(ts_z, neg_edge_index, sigmoid=True)\r\n",
    "        pred = torch.cat([pos_pred, neg_pred], dim=0)\r\n",
    "\r\n",
    "        y, pred = y.detach().cpu().numpy(), pred.detach().cpu().numpy()\r\n",
    "\r\n",
    "        return roc_auc_score(y, pred), average_precision_score(y, pred)\r\n",
    "\r\n",
    "\r\n",
    "def reset(nn):\r\n",
    "    def _reset(item):\r\n",
    "        if hasattr(item, 'reset_parameters'):\r\n",
    "            item.reset_parameters()\r\n",
    "\r\n",
    "    if nn is not None:\r\n",
    "        if hasattr(nn, 'children') and len(list(nn.children())) > 0:\r\n",
    "            for item in nn.children():\r\n",
    "                _reset(item)\r\n",
    "        else:\r\n",
    "            _reset(nn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TSDecoder(torch.nn.Module):\r\n",
    "    \"\"\" Take TS embedding (i.e. combined R-P embedding) and decode to TS geometry. \"\"\"\r\n",
    "    # ref: right now, just using InnerProductDecoder\r\n",
    "\r\n",
    "    def __init__(self, in_channels, out_channels, ts_data):\r\n",
    "        super(TSDecoder, self).__init__()\r\n",
    "        self.ts_data = ts_data\r\n",
    "\r\n",
    "    def forward(self, ts_z, ts_edge_index, sigmoid=True):\r\n",
    "        \"\"\" Decode TS embedding into edge probabilities for the given node-pairs of TS edge_index. \"\"\"\r\n",
    "        value = (ts_z[ts_edge_index[0]] * ts_z[ts_edge_index[1]]).sum(dim=1)\r\n",
    "        return torch.sigmoid(value) if sigmoid else value\r\n",
    "\r\n",
    "    def forward_all(self, z, sigmoid=True):\r\n",
    "        \"\"\" Decode latent embeddings into probabilistic adjacency matrix. \"\"\"\r\n",
    "        adj = torch.matmul(z, z.t())\r\n",
    "        return torch.sigmoid(adj) if sigmoid else adj\r\n",
    "\r\n",
    "class MolEncoder(nn.Module):\r\n",
    "    \"\"\" Takes in geometry data and creates embedding. Used for reactants OR products, not both. \"\"\"\r\n",
    "    # based off LinearEncoder\r\n",
    "\r\n",
    "    def __init__(self, in_channels, out_channels, geometry_data):\r\n",
    "        super(MolEncoder, self).__init__()\r\n",
    "        self.geometry_data = geometry_data\r\n",
    "        # use single GC to get embeddings for nodes here\r\n",
    "        self.conv = GCNConv(in_channels, out_channels)\r\n",
    "    \r\n",
    "    def forward(self, x, edge_index):\r\n",
    "        # no relu for linearity\r\n",
    "        return self.conv(x, edge_index)\r\n",
    "\r\n",
    "    # TODO: try these funcs; may need to pass in other args later; add these to decoder and TSVAE too\r\n",
    "    def save(self, path):\r\n",
    "        \"\"\" Save model to the path specified. \"\"\"\r\n",
    "        torch.save(self.state_dict(), path)\r\n",
    "    \r\n",
    "    def load(self, path):\r\n",
    "        \"\"\" Load model from path specified. \"\"\"\r\n",
    "        model_weights = torch.load(path)\r\n",
    "        self.load_state_dict(model_weights)\r\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_individual_geometry(geometry_encoder, opt, pos_edge_indices):\r\n",
    "    # use this on reactant or product\r\n",
    "    # TODO: where is this meant to be???\r\n",
    "    geometry_encoder.train()\r\n",
    "    opt.zero_grad()\r\n",
    "    z = geometry_encoder.encode(x, pos_edge_indices)\r\n",
    "    loss = geometry_encoder.recon_loss(z, pos_edge_indices)\r\n",
    "    loss.backward()\r\n",
    "    opt.step()\r\n",
    "    return z, float(loss)\r\n",
    "\r\n",
    "def train_reaction(ts_gae, ts_opt, ts_pos_edge_index):\r\n",
    "    \"\"\" Train reactant and product together then decode to TS. \"\"\"\r\n",
    "    ts_gae.train() # training this model should train the individual encoders\r\n",
    "    ts_opt.zero_grad()\r\n",
    "    ts_embedding = ts_gae.combine_reactant_and_product() # atm, pass in r and p data to this func\r\n",
    "    ts_loss = ts_gae.recon_loss(ts_embedding, ts_pos_edge_index)\r\n",
    "    ts_loss.backward()\r\n",
    "    ts_opt.step()\r\n",
    "    return float(loss)\r\n",
    "\r\n",
    "def test_reaction(ts_gae, ts_test_pos_edges, ts_test_neg_edges):\r\n",
    "    ts_gae.eval()\r\n",
    "    with torch.no_grad():\r\n",
    "        ts_embedding = model.encode(ts_data, ts_train_pos_edges)\r\n",
    "    return ts_gae.test(ts_embedding, ts_test_pos_edges, ts_test_neg_edges)\r\n",
    "\r\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lucky's work\n",
    "# PairFeatures: a manual MP I think. it has to be otherwise what he's doing isn't a GNN at all.\n",
    "\n",
    "# set edges\n",
    "#   iterate:\n",
    "#       compute features (i.e. MP) -> MLP(features) -> update edges\n",
    "#       compute features (i.e. MP) -> MLP(MLP(edges)) -> update vertices"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.6.13 64-bit (conda)",
   "name": "python3613jvsc74a57bd0f4671ad35fdc0609fa675edcd17de5b3092cb55d03f1d9670a78611a41fb18f3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  },
  "orig_nbformat": 2
 },
 "nbformat": 4,
 "nbformat_minor": 2
}