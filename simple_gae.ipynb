{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# atom features, bond type, graph connectivity, (x,y,z) coordinates  \n",
    "#   - when we encode the graph, we're doing it through atom features, bond types, and connectivitity (i.e. which atoms are connected to each other and how?)\n",
    "#   - the coordinate-based representation is particularly useful \n",
    "#   - for reaction centre, find adjacency matrix differences then map to 3D matrix\n",
    "\n",
    "# convert MLP to GNN by swapping torch.nn.linear with PyG's GNN operators e.g. GCN layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch_geometric.nn import GCNConv, GAE\n",
    "from torch_geometric.utils import train_test_split_edges\n",
    "\n",
    "import sys\n",
    "sys.path.insert(0, \"Users/rmhavij/3d-reactions/\") # azure again\n",
    "from ts_vae.data_processors.grambow_processor import ReactionDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# normal: base_path = r'data/'\n",
    "# azure\n",
    "base_path = r'Users/rmhavij/3d-reactions/data/'\n",
    "r_dataset = ReactionDataset(base_path, geo_file = 'train_r') \n",
    "\n",
    "data = r_dataset.data\n",
    "data.train_mask = data.val_mask = data.test_mask = data.y = None\n",
    "data = train_test_split_edges(data = data, val_ratio = 0, test_ratio = 0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LinearEncoder(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super(LinearEncoder, self).__init__()\n",
    "\n",
    "        # use single GC to get embeddings for nodes here\n",
    "        self.conv = GCNConv(in_channels, out_channels)\n",
    "    \n",
    "    def forward(self, x, edge_index):\n",
    "        # no relu for linearity\n",
    "        return self.conv(x, edge_index)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_node_fs = r_dataset.data.num_node_features # = 11\n",
    "out_channels = 2\n",
    "\n",
    "# build model and optimiser\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "model = GAE(LinearEncoder(num_node_fs, out_channels))\n",
    "model = model.to(device)\n",
    "x = data.x.to(device)\n",
    "train_pos_edge_index = data.train_pos_edge_index.to(device)\n",
    "opt = torch.optim.Adam(model.parameters(), lr=0.01)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train():\n",
    "    model.train()\n",
    "    opt.zero_grad()\n",
    "    z = model.encode(x, train_pos_edge_index)\n",
    "    loss = model.recon_loss(z, train_pos_edge_index)\n",
    "    loss.backward()\n",
    "    opt.step()\n",
    "    return float(loss)\n",
    "\n",
    "def test(pos_edge_index, neg_edge_index):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        z = model.encode(x, train_pos_edge_index)\n",
    "    return model.test(z, pos_edge_index, neg_edge_index)\n",
    "\n",
    "epochs = 10\n",
    "for epoch in range(1, epochs + 1):\n",
    "    loss = train()\n",
    "    auc, ap = test(data.test_pos_edge_index, data.test_neg_edge_index)\n",
    "    print('Epoch: {:03d}, AUC: {:.4f}, AP: {:.4f}'.format(epoch, auc, ap))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# build models and optimiser\n",
    "base_path = r'Users/rmhavij/3d-reactions/data/'\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# reactant data\n",
    "r_dataset = ReactionDataset(base_path, geo_file = 'train_r') \n",
    "reactant_data = r_dataset.data\n",
    "reactant_data.train_mask = reactant_data.val_mask = reactant_data.test_mask = reactant_data.y = None\n",
    "reactant_data = train_test_split_edges(data = reactant_data, val_ratio = 0, test_ratio = 0.2)\n",
    "\n",
    "# reactant encoder dimensions\n",
    "num_node_fs = r_dataset.data.num_node_features # = 11\n",
    "out_channels = 2\n",
    "\n",
    "# reactant encoder\n",
    "reactant_encoder = GAE(LinearEncoder(num_node_fs, out_channels))\n",
    "reactant_encoder = reactant_encoder.to(device)\n",
    "x = reactant_data.x.to(device)\n",
    "reactant_pos_edges = reactant_data.train_pos_edge_index.to(device)\n",
    "reactant_opt = torch.optim.Adam(reactant_encoder.parameters(), lr=0.01)\n",
    "\n",
    "# product data\n",
    "p_dataset = ReactionDataset(base_path, geo_file = 'train_p') \n",
    "product_data = p_dataset.data\n",
    "product_data.train_mask = product_data.val_mask = product_data.test_mask = product_data.y = None\n",
    "product_data = train_test_split_edges(data = product_data, val_ratio = 0, test_ratio = 0.2)\n",
    "\n",
    "# product data dimensions\n",
    "num_node_fs = p_dataset.data.num_node_features # = 11 (this is same as reactants here but useful anyway)\n",
    "out_channels = 2\n",
    "\n",
    "# product encoder\n",
    "product_encoder = GAE(LinearEncoder(num_node_fs, out_channels))\n",
    "product_encoder = product_encoder.to(device)\n",
    "x = product_data.x.to(device)\n",
    "product_pos_edges = product_data.train_pos_edge_index.to(device)\n",
    "product_opt = torch.optim.Adam(product_encoder.parameters(), lr=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_individual_geometry(geometry_encoder, opt, pos_edge_indices):\n",
    "    # use this on reactant or product\n",
    "    geometry_encoder.train()\n",
    "    opt.zero_grad()\n",
    "    z = geometry_encoder.encode(x, pos_edge_indices)\n",
    "    loss = geometry_encoder.recon_loss(z, pos_edge_indices)\n",
    "    loss.backward()\n",
    "    opt.step()\n",
    "    return float(loss)\n",
    "\n",
    "def train_reaction():\n",
    "    # train reactant and product together and decode to TS\n",
    "\n",
    "    return\n",
    "\n",
    "def train():\n",
    "    reactant_encoder.train()\n",
    "    reactant_opt.zero_grad()\n",
    "    reactant_z = reactant_encoder.encode(x, train_pos_edge_index)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lucky's work\n",
    "# PairFeatures: a manual MP I think. it has to be otherwise what he's doing isn't a GNN at all.\n",
    "\n",
    "# set edges\n",
    "#   iterate:\n",
    "#       compute features (i.e. MP) -> MLP(features) -> update edges\n",
    "#       compute features (i.e. MP) -> MLP(MLP(edges)) -> update vertices"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (3d-rdkit)",
   "language": "python",
   "name": "3d-rdkit"
  },
  "language_info": {
   "name": "python",
   "version": ""
  },
  "orig_nbformat": 2
 },
 "nbformat": 4,
 "nbformat_minor": 2
}