{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3613jvsc74a57bd0f4671ad35fdc0609fa675edcd17de5b3092cb55d03f1d9670a78611a41fb18f3",
   "display_name": "Python 3.6.13 64-bit (conda)"
  },
  "metadata": {
   "interpreter": {
    "hash": "f4671ad35fdc0609fa675edcd17de5b3092cb55d03f1d9670a78611a41fb18f3"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "# from numpy import exp, sqrt\n",
    "from numpy.random import normal\n",
    "from torch import exp, sqrt, randn_like\n",
    "from rdkit import Chem\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch_geometric.datasets import Planetoid\n",
    "import os.path as osp\n",
    "import inspect\n",
    "import torch_geometric.transforms as T\n",
    "src_file_path = inspect.getfile(lambda: None)\n",
    "path = osp.join(osp.dirname(osp.realpath(src_file_path)), '..', 'data', 'Planetoid')\n",
    "dataset = Planetoid(path, 'Cora', transform=T.NormalizeFeatures())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "tensor([[   0,    0,    0,  ..., 2707, 2707, 2707],\n",
       "        [ 633, 1862, 2582,  ...,  598, 1473, 2706]])"
      ]
     },
     "metadata": {},
     "execution_count": 85
    }
   ],
   "source": [
    "from torch_geometric.utils import train_test_split_edges\n",
    "\n",
    "cora = dataset[0]\n",
    "cora.train_mask = cora.val_mask = cora.test_mask = None\n",
    "cora = train_test_split_edges(cora)\n",
    "cora.train_pos_edge_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "torch_geometric.data.data.Data"
      ]
     },
     "metadata": {},
     "execution_count": 6
    }
   ],
   "source": [
    "type(dataset[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# runs out of memory, will need CPU for full set\n",
    "data = train_r_data.data\n",
    "data.train_mask = data.val_mask = data.test_mask = None\n",
    "data = train_test_split_edges(data=data, val_ratio=0.05, test_ratio=0.05)\n",
    "data.train_pos_edge_index\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ts_vae.data_processors.grambow_processor import ReactionDataset\n",
    "\n",
    "base_path = r'data/'\n",
    "\n",
    "train_r_data = ReactionDataset(base_path, geo_file = 'train_r') \n",
    "train_ts_data = ReactionDataset(base_path, geo_file = 'train_ts')\n",
    "train_p_data = ReactionDataset(base_path, geo_file = 'train_p')  \n",
    "\n",
    "test_r_data = ReactionDataset(base_path, geo_file = 'test_r') \n",
    "test_ts_data = ReactionDataset(base_path, geo_file = 'test_ts')\n",
    "test_p_data = ReactionDataset(base_path, geo_file = 'test_p')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "# simple GCN VAE\n",
    "\n",
    "# right now, using the edge features, but will need node positions (data.pos) later on\n",
    "import torch\n",
    "from torch_geometric.nn import GCNConv\n",
    "from torch_geometric.nn import VGAE\n",
    "from torch_geometric.data import DataLoader\n",
    "\n",
    "# simple VariationalGCNEncoder\n",
    "class VariationalGCNEncoder(torch.nn.Module):\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super(VariationalGCNEncoder, self).__init__()\n",
    "        self.conv1 = GCNConv(in_channels, 2 * out_channels, cached=True)\n",
    "        self.conv_mu = GCNConv(2 * out_channels, out_channels, cached=True)\n",
    "        self.conv_log_var = GCNConv(2 * out_channels, out_channels, cached=True)\n",
    "    \n",
    "    def forward(self, x, edge_index):\n",
    "        x = self.conv1(x, edge_index).relu()\n",
    "        return self.conv_mu(x, edge_index), self.conv_log_var(x, edge_index)\n",
    "\n",
    "# set up model\n",
    "num_features = train_r_data.num_features\n",
    "out_channels = 4\n",
    "vgae_model = VGAE(VariationalGCNEncoder(num_features, out_channels))\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "vgae_model = model.to(device)\n",
    "\n",
    "# data = train_r_data.data\n",
    "# x = data.x.to(device)\n",
    "# train_pos_edge_index = data.train_pos_edge_index.to(device) # not working rn\n",
    "optimiser = torch.optim.Adam(model.parameters(), lr=0.01)\n",
    "\n",
    "# create loader\n",
    "train_r_loader = DataLoader(train_r_data, batch_size=1, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "tensor([ 0,  0,  0,  ..., 10, 11, 12])"
      ]
     },
     "metadata": {},
     "execution_count": 82
    }
   ],
   "source": [
    "data.edge_index[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "IndexError",
     "evalue": "Dimension out of range (expected to be in range of [-1, 0], but got 1)",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-92-f03a82873a0c>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mtrain_pos_edge_index\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0medge_index\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mz\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mz\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m \u001b[0mvgae_model\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mencode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mz\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\miniconda3\\envs\\3d-rdkit\\lib\\site-packages\\torch_geometric\\nn\\models\\autoencoder.py\u001b[0m in \u001b[0;36mencode\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    153\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mencode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    154\u001b[0m         \u001b[1;34m\"\"\"\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 155\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__mu__\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__logstd__\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mencoder\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    156\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__logstd__\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__logstd__\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclamp\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmax\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mMAX_LOGSTD\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    157\u001b[0m         \u001b[0mz\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreparametrize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__mu__\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__logstd__\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\miniconda3\\envs\\3d-rdkit\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    887\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    888\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 889\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    890\u001b[0m         for hook in itertools.chain(\n\u001b[0;32m    891\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-23-d6ec7df26723>\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, x, edge_index)\u001b[0m\n\u001b[0;32m     14\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     15\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0medge_index\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 16\u001b[1;33m         \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconv1\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0medge_index\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     17\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconv_mu\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0medge_index\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconv_log_var\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0medge_index\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     18\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\miniconda3\\envs\\3d-rdkit\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    887\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    888\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 889\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    890\u001b[0m         for hook in itertools.chain(\n\u001b[0;32m    891\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\miniconda3\\envs\\3d-rdkit\\lib\\site-packages\\torch_geometric\\nn\\conv\\gcn_conv.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, x, edge_index, edge_weight)\u001b[0m\n\u001b[0;32m    160\u001b[0m                     edge_index, edge_weight = gcn_norm(  # yapf: disable\n\u001b[0;32m    161\u001b[0m                         \u001b[0medge_index\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0medge_weight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnode_dim\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 162\u001b[1;33m                         self.improved, self.add_self_loops)\n\u001b[0m\u001b[0;32m    163\u001b[0m                     \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcached\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    164\u001b[0m                         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_cached_edge_index\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0medge_index\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0medge_weight\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\miniconda3\\envs\\3d-rdkit\\lib\\site-packages\\torch_geometric\\nn\\conv\\gcn_conv.py\u001b[0m in \u001b[0;36mgcn_norm\u001b[1;34m(edge_index, edge_weight, num_nodes, improved, add_self_loops, dtype)\u001b[0m\n\u001b[0;32m     50\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     51\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0medge_weight\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 52\u001b[1;33m             edge_weight = torch.ones((edge_index.size(1), ), dtype=dtype,\n\u001b[0m\u001b[0;32m     53\u001b[0m                                      device=edge_index.device)\n\u001b[0;32m     54\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mIndexError\u001b[0m: Dimension out of range (expected to be in range of [-1, 0], but got 1)"
     ]
    }
   ],
   "source": [
    "data = train_r_data.data\n",
    "x = data.x.to(device)\n",
    "train_pos_edge_index = data.edge_index[0]\n",
    "z = data.z\n",
    "vgae_model.encode(x, z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "torch.Size([89300, 11])"
      ]
     },
     "metadata": {},
     "execution_count": 97
    }
   ],
   "source": [
    "# z.shape\n",
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "torch.Size([89300, 11])"
      ]
     },
     "metadata": {},
     "execution_count": 90
    }
   ],
   "source": [
    "x.shape\n",
    "# z.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "Data(edge_attr=[173336, 4], edge_index=[2, 173336], idx=[6739], pos=[89300, 3], x=[89300, 11], z=[89300])"
      ]
     },
     "metadata": {},
     "execution_count": 86
    }
   ],
   "source": [
    "train_r_data.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "torch.Size([173336])"
      ]
     },
     "metadata": {},
     "execution_count": 83
    }
   ],
   "source": [
    "train_pos_edge_index.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "torch.Size([89300, 11])"
      ]
     },
     "metadata": {},
     "execution_count": 84
    }
   ],
   "source": [
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_geometry_encoder(model, train_loader, optimiser): \n",
    "    # TODO: scheduler: for epochs and loss rate max, etc.\n",
    "    # TODO: standardiser?\n",
    "    \n",
    "    model.train()\n",
    "    loss_total = 0\n",
    "\n",
    "    # this iterates through each molecule of dataset (as its PTG graph features)\n",
    "    for data in tqdm(train_loader, total=len(train_loader)):\n",
    "        \n",
    "        # x = node feature matrix -> do with data = data.to(device) later?\n",
    "        x = data.x\n",
    "        # pos_edge_index is just forward indices; neg is backwards\n",
    "        pos_edge_index = data.edge_index[0]\n",
    "        \n",
    "        # compute reconstruction + KL loss\n",
    "        # here you want to use the training edges\n",
    "        z = model.encode(x, pos_edge_index)\n",
    "        loss = model.recon_loss(z, pos_edge_index)\n",
    "        loss = loss + (1 / data.num_nodes) * model.kl_loss()\n",
    "        \n",
    "        # update weights\n",
    "        optimiser.zero_grad()\n",
    "        loss.backward()\n",
    "        optimiser.step()\n",
    "        \n",
    "        loss_total += float(loss)\n",
    "    \n",
    "    return loss_total\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "  0%|          | 0/6739 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "output_type": "error",
     "ename": "IndexError",
     "evalue": "Dimension out of range (expected to be in range of [-1, 0], but got 1)",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-78-fdadaaa4495c>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     14\u001b[0m \u001b[0mepochs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m3\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     15\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepochs\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 16\u001b[1;33m     \u001b[0mloss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain_geometry_encoder\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvgae_model\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain_r_loader\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moptimiser\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-76-69d69f00a055>\u001b[0m in \u001b[0;36mtrain_geometry_encoder\u001b[1;34m(model, train_loader, optimiser)\u001b[0m\n\u001b[0;32m     16\u001b[0m         \u001b[1;31m# compute reconstruction + KL loss\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     17\u001b[0m         \u001b[1;31m# here you want to use the training edges\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 18\u001b[1;33m         \u001b[0mz\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mencode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpos_edge_index\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     19\u001b[0m         \u001b[0mloss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrecon_loss\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mz\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpos_edge_index\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     20\u001b[0m         \u001b[0mloss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mloss\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m \u001b[1;33m/\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnum_nodes\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkl_loss\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\miniconda3\\envs\\3d-rdkit\\lib\\site-packages\\torch_geometric\\nn\\models\\autoencoder.py\u001b[0m in \u001b[0;36mencode\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    153\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mencode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    154\u001b[0m         \u001b[1;34m\"\"\"\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 155\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__mu__\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__logstd__\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mencoder\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    156\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__logstd__\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__logstd__\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclamp\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmax\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mMAX_LOGSTD\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    157\u001b[0m         \u001b[0mz\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreparametrize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__mu__\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__logstd__\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\miniconda3\\envs\\3d-rdkit\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    887\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    888\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 889\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    890\u001b[0m         for hook in itertools.chain(\n\u001b[0;32m    891\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-23-d6ec7df26723>\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, x, edge_index)\u001b[0m\n\u001b[0;32m     14\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     15\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0medge_index\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 16\u001b[1;33m         \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconv1\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0medge_index\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     17\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconv_mu\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0medge_index\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconv_log_var\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0medge_index\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     18\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\miniconda3\\envs\\3d-rdkit\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    887\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    888\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 889\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    890\u001b[0m         for hook in itertools.chain(\n\u001b[0;32m    891\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\miniconda3\\envs\\3d-rdkit\\lib\\site-packages\\torch_geometric\\nn\\conv\\gcn_conv.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, x, edge_index, edge_weight)\u001b[0m\n\u001b[0;32m    160\u001b[0m                     edge_index, edge_weight = gcn_norm(  # yapf: disable\n\u001b[0;32m    161\u001b[0m                         \u001b[0medge_index\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0medge_weight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnode_dim\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 162\u001b[1;33m                         self.improved, self.add_self_loops)\n\u001b[0m\u001b[0;32m    163\u001b[0m                     \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcached\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    164\u001b[0m                         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_cached_edge_index\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0medge_index\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0medge_weight\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\miniconda3\\envs\\3d-rdkit\\lib\\site-packages\\torch_geometric\\nn\\conv\\gcn_conv.py\u001b[0m in \u001b[0;36mgcn_norm\u001b[1;34m(edge_index, edge_weight, num_nodes, improved, add_self_loops, dtype)\u001b[0m\n\u001b[0;32m     50\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     51\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0medge_weight\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 52\u001b[1;33m             edge_weight = torch.ones((edge_index.size(1), ), dtype=dtype,\n\u001b[0m\u001b[0;32m     53\u001b[0m                                      device=edge_index.device)\n\u001b[0;32m     54\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mIndexError\u001b[0m: Dimension out of range (expected to be in range of [-1, 0], but got 1)"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "# set up model\n",
    "num_features = train_r_data.num_features\n",
    "out_channels = 4\n",
    "vgae_model = VGAE(VariationalGCNEncoder(num_features, out_channels))\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "vgae_model = model.to(device)\n",
    "\n",
    "# optimiser, loader\n",
    "optimiser = torch.optim.Adam(model.parameters(), lr=0.01)\n",
    "train_r_loader = DataLoader(train_r_data, batch_size=1, shuffle=False)\n",
    "\n",
    "epochs = 3\n",
    "for epoch in range(1, epochs + 1):\n",
    "    loss = train_geometry_encoder(vgae_model, train_r_loader, optimiser)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "173336"
      ]
     },
     "metadata": {},
     "execution_count": 80
    }
   ],
   "source": [
    "train_r_data.data.edge_index.size(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def val_geometry_encoder(model, test_loader, loss, device):\n",
    "    \"\"\" Need to split pos_edge_index into train and test and then feed test in here.\n",
    "    \"\"\"\n",
    "    \n",
    "    # notifies all layers that are in eval model so that batchnorm or dropout layers can work which wouldn't normally in training mode\n",
    "    model.eval()\n",
    "\n",
    "    error = 0\n",
    "    # preds = []\n",
    "\n",
    "    # no_grad() deactivates the autograd engine to prevent backprop (for efficiency)\n",
    "    with torch.no_grad():\n",
    "        for data in tqdm(test_loader, total=len(test_loader)):\n",
    "            x = data.x.to(device)\n",
    "            pos_edge_index = data.edge_index[0].to(device)\n",
    "            # training edges here? i'm using test currently\n",
    "            z = model.encode(x, pos_edge_index)\n",
    "    # have to test against positive and negative edge indices\n",
    "    return model.test(z, )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "NameError",
     "evalue": "name 'train_pos_edge_index' is not defined",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-82-cc8f37f7fc35>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     17\u001b[0m \u001b[0mepochs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m3\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     18\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepochs\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 19\u001b[1;33m     \u001b[0mloss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     20\u001b[0m     \u001b[0mauc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0map\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtest\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtest_pos_edge_index\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtest_neg_edge_index\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     21\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Epoch: {:03d}, AUC: {:.4f}, AP: {:.4f}'\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mauc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0map\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-82-cc8f37f7fc35>\u001b[0m in \u001b[0;36mtrain\u001b[1;34m()\u001b[0m\n\u001b[0;32m      2\u001b[0m     \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m     \u001b[0moptimiser\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m     \u001b[0mz\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mencode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain_pos_edge_index\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m     \u001b[0mloss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrecon_loss\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mz\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain_pos_edge_index\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m     \u001b[0mloss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mloss\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m \u001b[1;33m/\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnum_nodes\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkl_loss\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'train_pos_edge_index' is not defined"
     ]
    }
   ],
   "source": [
    "def train():\n",
    "    model.train()\n",
    "    optimiser.zero_grad()\n",
    "    z = model.encode(x, train_pos_edge_index)\n",
    "    loss = model.recon_loss(z, train_pos_edge_index)\n",
    "    loss = loss + (1 / data.num_nodes) * model.kl_loss()\n",
    "    loss.backward()\n",
    "    optimiser.step()\n",
    "    return float(loss)\n",
    "\n",
    "def test(pos_edge_index, neg_edge_index):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        z = model.encode(x, train_pos_edge_index)\n",
    "    return model.test(z, pos_edge_index, neg_edge_index)\n",
    "\n",
    "epochs = 3\n",
    "for epoch in range(1, epochs + 1):\n",
    "    loss = train()\n",
    "    auc, ap = test(data.test_pos_edge_index, data.test_neg_edge_index)\n",
    "    print('Epoch: {:03d}, AUC: {:.4f}, AP: {:.4f}'.format(epoch, auc, ap))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "Data(edge_attr=[173336, 4], edge_index=[2, 173336], idx=[6739], pos=[89300, 3], x=[89300, 11], z=[89300])"
      ]
     },
     "metadata": {},
     "execution_count": 75
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "tensor([[0., 1., 0.,  ..., 0., 0., 3.],\n",
       "        [0., 1., 0.,  ..., 0., 0., 2.],\n",
       "        [0., 1., 0.,  ..., 0., 0., 0.],\n",
       "        ...,\n",
       "        [1., 0., 0.,  ..., 0., 0., 0.],\n",
       "        [1., 0., 0.,  ..., 0., 0., 0.],\n",
       "        [1., 0., 0.,  ..., 0., 0., 0.]])"
      ]
     },
     "metadata": {},
     "execution_count": 71
    }
   ],
   "source": [
    "train_r_data.data.x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lucky way\n",
    "\n",
    "from torch_geometric.nn import MessagePassing\n",
    "\n",
    "class GCNConv(MessagePassing):\n",
    "    def __init__(self, args):\n",
    "        super(GCNConv, self).__init__(aggr='add')\n",
    "        self.linear = nn.Linear(args.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# way given by link under class\n",
    "\n",
    "# basic GCNConv\n",
    "\n",
    "from torch.nn import Dropout, ReLU\n",
    "from torch_geometric.nn import GCNConv\n",
    "from torch_geometric.data import Data, InMemoryDataset\n",
    "\n",
    "class StandardGCN(torch.nn.Module):\n",
    "    \"\"\" Standard implementation of GCN with GCNConv layers. Code mostly lifted from https://github.com/klicperajo/gdc/blob/master/models.py\n",
    "        Used to evaluate 2D molecular graph created by our .sdf data as a baseline against proposed 3D methods.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, geometry_dataset: InMemoryDataset, hidden: List[int] = 2, dropout: float = 0.5):\n",
    "        super(GCN, self).__init__()\n",
    "\n",
    "        num_features = [geometry_dataset.num_featuresdata.x.shape[1]] + hidden + [geometry_dataset.num_classes]\n",
    "        layers = []\n",
    "        for in_features, out_features in zip(num_features[:-1], num_features[1:]):\n",
    "            layers.append(GCNConv(in_features, out_features))\n",
    "        self.layers = ModuleList(layers)\n",
    "        \n",
    "        self.dropout = Dropout(p=dropout)\n",
    "        self.activation_func = ReLU()\n",
    "\n",
    "    def reset_parameters(self):\n",
    "        for layer in self.layers:\n",
    "            layer.reset_parameters()\n",
    "    \n",
    "    def forward(self, data: Data):\n",
    "        x, edge_index, edge_attr = data.x, data.edge_index, data.edge_attr\n",
    "\n",
    "        for i, layer in enumerate(self.layers):\n",
    "            x = layer(x, edge_index, edge_weight=edge_attr)\n",
    "            if i == len(self.layers) - 1:\n",
    "                break\n",
    "            x = self.activation_func(x)\n",
    "            x = self.dropout(x)\n",
    "        return torch.nn.functional.log_softmax(x, dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "torch.Size([11202, 11])"
      ]
     },
     "metadata": {},
     "execution_count": 25
    }
   ],
   "source": [
    "test_r_data.data.x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "11"
      ]
     },
     "metadata": {},
     "execution_count": 26
    }
   ],
   "source": [
    "test_r_data.num_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loss for R, P latent spaces\n",
    "    # frame func as generate R, P latent spaces\n",
    "# loss for TS decoding \n",
    "\n",
    "# related: DimeNet, GNNExplainer, SchNet \n",
    "# VAEs: VGAE, ARGVA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://github.com/rusty1s/pytorch_geometric/blob/master/examples/autoencoder.py\n",
    "def train():\n",
    "    # train\n",
    "    # use optimiser\n",
    "    # encode\n",
    "    # decode to TS\n",
    "    # evaluate loss compared to expected TS\n",
    "    # loss.backward() \n",
    "    # optimiser.step()\n",
    "    # return float(loss)\n",
    "\n",
    "# run test_r and test_p through encoder and decode to TS, eval against test_ts\n",
    "def test():\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "LATENT_DIM = 4      # arbitrary\n",
    "MAX_SIZE = 22*3     # try first with (x,y,z) for each atom\n",
    "\n",
    "class MoleculeVAE(nn.Module):\n",
    "    def __init__(self): # maybe also init encoder, decoder, in_channels, out_channels, depth, hidden size, dropout, gnn_type\n",
    "        # self.decoder = DefaultDecoder() if decoder is None else decoder\n",
    "        # maybe pass in data as reaction frame here too?\n",
    "        super().__init__()\n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Linear(MAX_SIZE, 32),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(32, 2*LATENT_DIM)\n",
    "        )\n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.Linear(2*LATENT_DIM, 32),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(32, MAX_SIZE)\n",
    "        )\n",
    "\n",
    "        \"\"\"\n",
    "        self.convs = torch.nn.ModuleList()\n",
    "\n",
    "        for _ in range(self.depth):\n",
    "            if self.gnn_type == ?:\n",
    "                self.convs.append(e.g. GCNConv(args))\n",
    "        \"\"\"\n",
    "    \n",
    "    def reparameterise(self, mean_z, log_var_z):\n",
    "        if self.training:\n",
    "            eps = randn_like() # is this meant to be randn_like(log_var_z)?\n",
    "            z = mean_z + eps * sqrt(exp(log_var_z))\n",
    "            return z\n",
    "        else:\n",
    "            return mean_z\n",
    "    \n",
    "    def forward(self, x): # note: might be easier to do this the other way explicitly defining mean and var\n",
    "        # reshape input into a vector, then reshape using view(-1, batchsize=2, d)\n",
    "        params_z = self.encoder(x.view(-1, input_size)).view(-1, 2, LATENT_DIM) # this encoder may need to be changed\n",
    "        mean_z = params_z[:, 0, :]\n",
    "        log_var_z = params_z[:, 1, :]\n",
    "        z = self.reparameterise(mean_z, log_var_z)\n",
    "        return self.decoder(z), mean_z, log_var_z \n",
    "\n",
    "    # x_hat = model TS; x = TS\n",
    "    def loss_func(generated_TS, real_TS, mean_z, log_var_z, beta=1):\n",
    "        BCE = nn.functional.binary_cross_entropy(generated_TS, real_TS.view(-1, MAX_SIZE), reduction='sum') \n",
    "        KLD = 0.5 * torch.sum(exp(log_var_z) - log_var_z - 1 + mean_z**2)\n",
    "        return BCE + beta * KLD\n",
    "\n",
    "# define device and model\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = MoleculeVAE().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ts_vae.data_processors.grambow_processor import ReactionDataset\n",
    "\n",
    "base_path = r'data/'\n",
    "\n",
    "train_r_data = ReactionDataset(base_path, geo_file = 'train_r') \n",
    "train_ts_data = ReactionDataset(base_path, geo_file = 'train_ts')\n",
    "train_p_data = ReactionDataset(base_path, geo_file = 'train_p')  \n",
    "\n",
    "test_r_data = ReactionDataset(base_path, geo_file = 'test_r') \n",
    "test_ts_data = ReactionDataset(base_path, geo_file = 'test_ts')\n",
    "test_p_data = ReactionDataset(base_path, geo_file = 'test_p')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# either take in reaction dataset or take in .sdf?\n",
    "# might be better to keep these functions inside the original processor\n",
    "class EDA():\n",
    "    \n",
    "    def __init__(self):\n",
    "        pass\n",
    "\n",
    "    # TODO\n",
    "    def visualise_feature_dynamics(self):\n",
    "        # takes in reactants, ts, products; calculates reaction centre\n",
    "        # compare how reaction centre changes: by how much, what precision do we need?\n",
    "        # could do similar with interatomic distances\n",
    "        return\n",
    "\n",
    "# model run class\n",
    "class ModelRun():\n",
    "    def __init__(self, training_rxns, test_rxns, model):\n",
    "        self.training_rxns = training_rxns\n",
    "        self.test_rxns = test_rxns\n",
    "\n",
    "    # plot loss \n",
    "    # plotting evaluation here\n",
    "    \n",
    "    def preprocess_data():\n",
    "        # preprocess the data for each model as it suits\n",
    "        return\n",
    "    \n",
    "    # compare model TS: average, initial guesses, final estimates, reals\n",
    "        # will allow me to compare several models against each other\n",
    "    \n",
    "    # will have funcs to evaluate structure of output\n",
    "        # for generative models: evaluate structure of latent space\n",
    "        # evaluate how R and P are combined\n",
    "\n",
    "    # how are TS formed?\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "list"
      ]
     },
     "metadata": {},
     "execution_count": 13
    }
   ],
   "source": [
    "def create_dataloader(args):\n",
    "\n",
    "    if isinstance(modes, str):\n",
    "        modes = [modes]\n",
    "\n",
    "\n",
    "def construct_loader(args, modes=('train', 'val')):\n",
    "\n",
    "    if isinstance(modes, str):\n",
    "        modes = [modes]\n",
    "\n",
    "    data_df = pd.read_csv(args.data_path)\n",
    "\n",
    "    smiles = data_df.iloc[:, 0].values\n",
    "    labels = data_df.iloc[:, 1].values.astype(np.float32)\n",
    "\n",
    "    loaders = []\n",
    "    for mode in modes:\n",
    "        dataset = MolDataset(smiles, labels, args, mode)\n",
    "        loader = DataLoader(dataset=dataset,\n",
    "                            batch_size=args.batch_size,\n",
    "                            shuffle=not args.no_shuffle if mode == 'train' else False,\n",
    "                            num_workers=args.num_workers,\n",
    "                            pin_memory=True,\n",
    "                            sampler=StereoSampler(dataset) if args.shuffle_pairs else None)\n",
    "        loaders.append(loader)\n",
    "\n",
    "    if len(loaders) == 1:\n",
    "        return loaders[0]\n",
    "    else:\n",
    "        return loaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "NameError",
     "evalue": "name 'test_loader' is not defined",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-13-b7c0f232b247>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     25\u001b[0m         \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0meval\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     26\u001b[0m         \u001b[0mtest_loss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 27\u001b[1;33m         \u001b[1;32mfor\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mtest_loader\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     28\u001b[0m             \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     29\u001b[0m             \u001b[1;31m# === forward ===\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'test_loader' is not defined"
     ]
    }
   ],
   "source": [
    "# setting optimiser\n",
    "learning_rate = 1e-3\n",
    "optimiser = torch.optim.Adam(model.parameters(), lr = learning_rate)\n",
    "\n",
    "# training and testing the VAE\n",
    "epochs = 5\n",
    "codes = dict(mean=list(), log_var=list(), y=list())\n",
    "for epoch in range(0, epochs+1):\n",
    "    # training\n",
    "    if epoch > 0:\n",
    "        model.train()\n",
    "        train_loss = 0\n",
    "        for real_TS, _ in train_loader:\n",
    "            real_TS = real_TS.to(device)\n",
    "            # === forward ===\n",
    "            generated_TS, mean_z, log_var_z = model(x)\n",
    "            loss = loss_func(generated_TS, real_TS, mean_z, log_var_z)\n",
    "            train_loss += loss.item()\n",
    "            # === backward ===\n",
    "            optimiser.zero_grad()\n",
    "            loss.backward()\n",
    "            optimiser.step()\n",
    "        # === log ===\n",
    "        print(f'====> Epoch: {epoch} Average loss: {train_loss / len(train_loader.dataset):.4f}')\n",
    "        \n",
    "    # testing\n",
    "    means, log_vars, labels = list(), list(), list()\n",
    "    with torch.no_grad():\n",
    "        model.eval()\n",
    "        test_loss = 0\n",
    "        for x, y in test_loader:\n",
    "            x = x.to(device)\n",
    "            # === forward ===\n",
    "            x_hat, mean, log_var = model(x)\n",
    "            test_loss += loss_function(x_hat, x, mean, log_var).item()\n",
    "            # === log ===\n",
    "            means.append(mean.detach())\n",
    "            log_vars.append(log_var.detach())\n",
    "            labels.append(y.detach())\n",
    "    # === log ===\n",
    "    codes['mean'].append(torch.cat(means))\n",
    "    codes['log_var'].append(torch.cat(log_vars))\n",
    "    codes['y'].append(torch.cat(labels))\n",
    "    test_loss /= len(test_loader.dataset)\n",
    "    print(f'===> Test set loss: {test_loss:.4f}')\n",
    "    display_images(x, x_hat, 1, f'Epoch {epoch}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class VAE(nn.Module):\n",
    "    \n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.encoder = nn.Sequential(\n",
    "            # linear (size of input, 2d), size of input= max possible size i.e. largest mol\n",
    "            nn.Linear(input_size, d**2),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(d ** 2, d * 2)\n",
    "        )\n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.Linear(d, d ** 2),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(d ** 2, input_size)\n",
    "            # would use sigmoid here if input was between 0 and 1\n",
    "        )\n",
    "\n",
    "    def reparameterise(self, mean_z, log_var_z):\n",
    "        if self.training:\n",
    "            # eps = normal(loc=0, scale=1, size=(len(graphs.nodes), self.latent_dim=2d))\n",
    "            # since variances only positive, computing log allows you to output full real range for encoder\n",
    "            eps = normal(0, 1, size=(len(input_nodes), latent_dims=2d))\n",
    "            z = mean_z + eps * sqrt(exp(log_var_z))\n",
    "            return z\n",
    "        else:\n",
    "            return mean_z\n",
    "\n",
    "    def forward(self, x):\n",
    "        # reshape input into a vector, then reshape using view(-1, batchsize=2, d)\n",
    "        params_z = self.encoder(x.view(-1, input_size)).view(-1, 2, d)\n",
    "        \n",
    "        mean_z = params_z[:, 0, :]\n",
    "        log_var_z = params_z[:, 1, :]\n",
    "        z = self.reparameterise(mean_z, log_var_z)\n",
    "        return self.decoder(z), mean_z, log_var_z \n",
    "\n",
    "model = VAE().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# setting optimiser\n",
    "learning_rate = 1e-3\n",
    "optimiser = torch.optim.Adam(model.parameters(), lr = learning_rate)\n",
    "\n",
    "# reconstruction + KL divergence losses summed over all elements\n",
    "def loss_function(x_hat, x, mean_z, log_var_z, beta):\n",
    "    # binary cross entropy between input and reconstruction\n",
    "    BCE = nn.functional.binary_cross_entropy(x_hat, x.view(-1, 784), reduction='sum') \n",
    "    # kl divergence: var is linear, - log var is logarithmic, mean is squared \n",
    "    KLD = 0.5 * torch.sum(exp(log_var_z) - log_var_z - 1 + mean_z**2)\n",
    "    return BCE + beta * KLD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# training and testing the VAE\n",
    "epochs = 5\n",
    "codes = dict(mean=list(), log_var=list(), y=list())\n",
    "for epoch in range(0, epochs+1):\n",
    "    # training\n",
    "    if epoch > 0:\n",
    "        model.train()\n",
    "        train_loss = 0\n",
    "        for x, _ in train_loader:\n",
    "            x = x.to(device)\n",
    "            # === forward ===\n",
    "            x_hat, mean, log_var = model(x)\n",
    "            loss = loss_function(x_hat, x, mean, log_var)\n",
    "            train_loss += loss.item()\n",
    "            # === backward ===\n",
    "            optimiser.zero_grad()\n",
    "            loss.backward()\n",
    "            optimiser.step()\n",
    "        # === log ===\n",
    "        print(f'====> Epoch: {epoch} Average loss: {\n",
    "            train_loss / len(train_loader.dataset):.4f}')\n",
    "        \n",
    "    # testing\n",
    "    means, log_vars, labels = list(), list(), list()\n",
    "    with torch.no_grad():\n",
    "        model.eval()\n",
    "        test_loss = 0\n",
    "        for x, y in test_loader:\n",
    "            x = x.to(device)\n",
    "            # === forward ===\n",
    "            x_hat, mean, log_var = model(x)\n",
    "            test_loss += loss_function(x_hat, x, mean, log_var).item()\n",
    "            # === log ===\n",
    "            means.append(mean.detach())\n",
    "            log_vars.append(log_var.detach())\n",
    "            labels.append(y.detach())\n",
    "    # === log ===\n",
    "    codes['mean'].append(torch.cat(means))\n",
    "    codes['log_var'].append(torch.cat(log_vars))\n",
    "    codes['y'].append(torch.cat(labels))\n",
    "    test_loss /= len(test_loader.dataset)\n",
    "    print(f'===> Test set loss: {test_loss:.4f}')\n",
    "    display_images(x, x_hat, 1, f'Epoch {epoch}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generating a few samples\n",
    "N = 16\n",
    "z = torch.randn((N, d)).to(device)\n",
    "sample = model.decoder(z)\n",
    "display_images(None, sample, N//4, count=True)\n",
    "\n",
    "# Choose starting and ending point for the interpolation -> shows original and reconstructed\n",
    "\n",
    "A, B = 1, 14\n",
    "sample = model.decoder(torch.stack((mean[A].data, mean[B].data), 0))\n",
    "display_images(None, torch.stack(((\n",
    "    x[A].data.view(-1),\n",
    "    x[B].data.view(-1),\n",
    "    sample.data[0],\n",
    "    sample.data[1]\n",
    ")), 0))"
   ]
  }
 ]
}