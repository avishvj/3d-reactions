{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# you would need to do this for each batch\r\n",
    "import torch\r\n",
    "def sequence_mask(sizes, max_size = None, dtype = torch.bool):\r\n",
    "    if max_size is None:\r\n",
    "        max_size = sizes.max()\r\n",
    "    row_vector = torch.arange(0, max_size, 1)\r\n",
    "    matrix = torch.unsqueeze(sizes, dim = -1)\r\n",
    "    mask = row_vector < matrix\r\n",
    "\r\n",
    "    mask.type(dtype)\r\n",
    "    return mask\r\n",
    "\r\n",
    "sizes = torch.tensor([10, 12, 20, 18]) # num_atoms in each graph\r\n",
    "max_size = 21\r\n",
    "mask = sequence_mask(sizes, max_size)\r\n",
    "\r\n",
    "mask_n = torch.unsqueeze(mask, 2)\r\n",
    "mask_v = torch.unsqueeze(mask_n, 1) * torch.unsqueeze(mask_n, 2)\r\n",
    "mask_n.shape, mask_v.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[-1.023,  1.760, -0.260, -0.519],\n",
      "         [-1.073,  1.263,  1.337, -0.967]],\n",
      "\n",
      "        [[-0.726, -0.880,  1.027, -0.491],\n",
      "         [-0.824,  0.530,  1.237, -0.893]]])\n",
      "tensor([[-1.023,  1.760, -0.260, -0.519],\n",
      "        [-1.073,  1.263,  1.337, -0.967],\n",
      "        [-0.726, -0.880,  1.027, -0.491],\n",
      "        [-0.824,  0.530,  1.237, -0.893]])\n"
     ]
    }
   ],
   "source": [
    "import torch\r\n",
    "edge_attr = torch.randn(2, 2, 4)\r\n",
    "print(edge_attr)\r\n",
    "edge_attr = edge_attr.view(4, 4)\r\n",
    "print(edge_attr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files removed.\n",
      "Processing...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 10/7581 [00:00<00:34, 217.79it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done!\n",
      "Starting ablation experiment...\n",
      "torch.Size([441, 100]) torch.Size([441, 100])\n",
      "torch.Size([441, 100]) torch.Size([441, 100])\n",
      "torch.Size([441, 100]) torch.Size([441, 100])\n",
      "torch.Size([441, 100]) torch.Size([441, 100])\n",
      "torch.Size([441, 100]) torch.Size([441, 100])\n",
      "torch.Size([441, 100]) torch.Size([441, 100])\n",
      "torch.Size([441, 100]) torch.Size([441, 100])\n",
      "torch.Size([441, 100]) torch.Size([441, 100])\n",
      "torch.Size([441, 100]) torch.Size([441, 100])\n",
      "torch.Size([441, 100]) torch.Size([441, 100])\n",
      "torch.Size([441, 100]) torch.Size([441, 100])\n",
      "torch.Size([441, 100]) torch.Size([441, 100])\n",
      "torch.Size([441, 100]) torch.Size([441, 100])\n",
      "torch.Size([441, 100]) torch.Size([441, 100])\n",
      "torch.Size([441, 100]) torch.Size([441, 100])\n",
      "torch.Size([441, 100]) torch.Size([441, 100])\n",
      "torch.Size([441, 100]) torch.Size([441, 100])\n",
      "torch.Size([441, 100]) torch.Size([441, 100])\n",
      "torch.Size([441, 100]) torch.Size([441, 100])\n",
      "torch.Size([441, 100]) torch.Size([441, 100])\n",
      "torch.Size([441, 100]) torch.Size([441, 100])\n",
      "torch.Size([441, 100]) torch.Size([441, 100])\n",
      "torch.Size([441, 100]) torch.Size([441, 100])\n",
      "torch.Size([441, 100]) torch.Size([441, 100])\n",
      "===== Training epoch 001 complete with loss: 3.6251 ====\n",
      "torch.Size([441, 100]) torch.Size([441, 100])\n",
      "torch.Size([441, 100]) torch.Size([441, 100])\n",
      "torch.Size([441, 100]) torch.Size([441, 100])\n",
      "torch.Size([441, 100]) torch.Size([441, 100])\n",
      "torch.Size([441, 100]) torch.Size([441, 100])\n",
      "torch.Size([441, 100]) torch.Size([441, 100])\n",
      "torch.Size([441, 100]) torch.Size([441, 100])\n",
      "torch.Size([441, 100]) torch.Size([441, 100])\n",
      "torch.Size([441, 100]) torch.Size([441, 100])\n",
      "torch.Size([441, 100]) torch.Size([441, 100])\n",
      "torch.Size([441, 100]) torch.Size([441, 100])\n",
      "torch.Size([441, 100]) torch.Size([441, 100])\n",
      "torch.Size([441, 100]) torch.Size([441, 100])\n",
      "torch.Size([441, 100]) torch.Size([441, 100])\n",
      "torch.Size([441, 100]) torch.Size([441, 100])\n",
      "torch.Size([441, 100]) torch.Size([441, 100])\n",
      "torch.Size([441, 100]) torch.Size([441, 100])\n",
      "torch.Size([441, 100]) torch.Size([441, 100])\n",
      "torch.Size([441, 100]) torch.Size([441, 100])\n",
      "torch.Size([441, 100]) torch.Size([441, 100])\n",
      "torch.Size([441, 100]) torch.Size([441, 100])\n",
      "torch.Size([441, 100]) torch.Size([441, 100])\n",
      "torch.Size([441, 100]) torch.Size([441, 100])\n",
      "torch.Size([441, 100]) torch.Size([441, 100])\n",
      "===== Training epoch 002 complete with loss: 3.4368 ====\n",
      "torch.Size([441, 100]) torch.Size([441, 100])\n",
      "torch.Size([441, 100]) torch.Size([441, 100])\n",
      "torch.Size([441, 100]) torch.Size([441, 100])\n",
      "torch.Size([441, 100]) torch.Size([441, 100])\n",
      "torch.Size([441, 100]) torch.Size([441, 100])\n",
      "torch.Size([441, 100]) torch.Size([441, 100])\n",
      "===== Testing epoch 002 complete with loss: 4.7770 ====\n",
      "Completed ablation experiment, use the experiment log to print results.\n"
     ]
    }
   ],
   "source": [
    "from experiments.building_on_mit.meta_eval.meta_eval import ablation_experiment\r\n",
    "from ts_vae.utils import remove_files\r\n",
    "remove_files()\r\n",
    "# have to use batch_size = 1 right now\r\n",
    "train_log, test_log = ablation_experiment(0.8, 1, 2, 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- How to batch edge_attr (dim = NxNxEA) properly? i.e. on NxN\r\n",
    "- Sort the collate for the tsgendatset. What is diff between collate for loader and inmemorydataset?\r\n",
    "    - Loader: pass in Collater class with collate() for batching\r\n",
    "        - The main issue is in Collater(), you need to write a Batch.from_data_list() func which is q long.\r\n",
    "    - InMemoryDataset: collate is for slicing appropriately. You'd then need to specify follow_batch etc\r\n",
    "<br><br>\r\n",
    "- Ignore above, just get working for constant size and batch length.\r\n",
    "- Try and replicate their results. Main thing to do."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.6.13 64-bit (conda)",
   "name": "python3613jvsc74a57bd0f4671ad35fdc0609fa675edcd17de5b3092cb55d03f1d9670a78611a41fb18f3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  },
  "orig_nbformat": 2
 },
 "nbformat": 4,
 "nbformat_minor": 2
}