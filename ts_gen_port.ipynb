{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# you would need to do this for each batch\r\n",
    "\r\n",
    "import torch\r\n",
    "def sequence_mask(sizes, max_size = None, dtype = torch.bool):\r\n",
    "    if max_size is None:\r\n",
    "        max_size = sizes.max()\r\n",
    "    row_vector = torch.arange(0, max_size, 1)\r\n",
    "    matrix = torch.unsqueeze(sizes, dim = -1)\r\n",
    "    mask = row_vector < matrix\r\n",
    "\r\n",
    "    mask.type(dtype)\r\n",
    "    return mask\r\n",
    "\r\n",
    "sizes = torch.tensor([10, 12, 20, 18]) # num_atoms in each graph\r\n",
    "max_size = 21\r\n",
    "mask = sequence_mask(sizes, max_size)\r\n",
    "\r\n",
    "mask_n = torch.unsqueeze(mask, 2)\r\n",
    "mask_v = torch.unsqueeze(mask_n, 1) * torch.unsqueeze(mask_n, 2)\r\n",
    "mask_n.shape, mask_v.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from experiments.building_on_mit.meta_eval.meta_eval import ablation_experiment\r\n",
    "# from ts_vae.utils import remove_files\r\n",
    "# remove_files()\r\n",
    "# have to use batch_size = 1 right now\r\n",
    "train_log, test_log = ablation_experiment(0.8, 1, 2, 2"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.6.13 64-bit (conda)",
   "name": "python3613jvsc74a57bd0f4671ad35fdc0609fa675edcd17de5b3092cb55d03f1d9670a78611a41fb18f3"
  },
  "language_info": {
   "name": "python",
   "version": ""
  },
  "orig_nbformat": 2
 },
 "nbformat": 4,
 "nbformat_minor": 2
}