{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3613jvsc74a57bd0f4671ad35fdc0609fa675edcd17de5b3092cb55d03f1d9670a78611a41fb18f3",
   "display_name": "Python 3.6.13 64-bit (conda)"
  },
  "metadata": {
   "interpreter": {
    "hash": "f4671ad35fdc0609fa675edcd17de5b3092cb55d03f1d9670a78611a41fb18f3"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as functional\n",
    "import sklearn.metrics as metrics\n",
    "from rdkit import Chem\n",
    "from rdkit.Chem import rdchem as utils\n",
    "\n",
    "import numpy as np\n",
    "from numpy import exp\n",
    "from numpy.random import normal\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_folder = r'spare_data/'\n",
    "\n",
    "train_r_file = base_folder + 'train_reactants.sdf'\n",
    "train_ts_file = base_folder + 'train_ts.sdf'\n",
    "train_p_file = base_folder + 'train_products.sdf'\n",
    "\n",
    "test_r_file = base_folder + 'test_reactants.sdf'\n",
    "test_ts_file = base_folder + 'test_ts.sdf'\n",
    "test_p_file = base_folder + 'test_products.sdf'\n",
    "\n",
    "train_r = Chem.ForwardSDMolSupplier(train_r_file, removeHs=False, sanitize=False)\n",
    "train_r = [x for x in train_r]\n",
    "train_ts = Chem.ForwardSDMolSupplier(train_ts_file, removeHs=False, sanitize=False)\n",
    "train_ts = [x for x in train_ts]\n",
    "train_p = Chem.ForwardSDMolSupplier(train_p_file, removeHs=False, sanitize=False)\n",
    "train_p = [x for x in train_p]\n",
    "\n",
    "test_r = Chem.ForwardSDMolSupplier(test_r_file, removeHs=False, sanitize=False)\n",
    "test_r = [x for x in test_r]\n",
    "test_ts = Chem.ForwardSDMolSupplier(test_ts_file, removeHs=False, sanitize=False)\n",
    "test_ts = [x for x in test_ts]\n",
    "test_p = Chem.ForwardSDMolSupplier(test_p_file, removeHs=False, sanitize=False)\n",
    "test_p = [x for x in test_p]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "100"
      ]
     },
     "metadata": {},
     "execution_count": 42
    }
   ],
   "source": [
    "# restrict number of products created to 30 for testing\n",
    "\n",
    "len(train_r[0:100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "21"
      ]
     },
     "metadata": {},
     "execution_count": 71
    }
   ],
   "source": [
    "# figuring out padding\n",
    "max(mol.GetNumAtoms() for mol in train_r) # = 21, same for ts, p\n",
    "# min(mol.GetNumAtoms() for mol in train_r) # = 4\n",
    "# need to get more\n",
    "\n",
    "# train_r_small = train_r[0:100]\n",
    "# train_ts_small = train_ts[0:100]\n",
    "# train_p_small = train_p[0:100]\n",
    "\n",
    "print(torch.__version__)\n",
    "# do AE\n",
    "# then get to grips with PTG\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ts_vae.data_processors.grambow_processor import ReactionDataset\n",
    "\n",
    "base_path = r'data/'\n",
    "train_r_data = ReactionDataset(base_path, geo_file = 'train_r') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "Data(edge_attr=[173336, 4], edge_index=[2, 173336], idx=[6739], pos=[89300, 3], x=[89300, 11], z=[89300])"
      ]
     },
     "metadata": {},
     "execution_count": 14
    }
   ],
   "source": [
    "train_r_data.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.nn import ReLU\n",
    "\n",
    "class MLPLayer(nn.Module):\n",
    "    \"\"\" Standard MLP layer. \"\"\"\n",
    "\n",
    "    def __init__(self, input_dim, output_dim, activation=ReLU, num_hidden=2):\n",
    "        super().__init__()\n",
    "        # fc_layers = fully connected layers\n",
    "        fc_layers = [nn.Linear(input_dim, input_dim) for hidden_idx in range(num_hidden)]\n",
    "        fc_layers.append(nn.Linear(input_dim, output_dim))\n",
    "        self.fc_layers = nn.ModuleList(fc_layers)\n",
    "        self.num_hidden = num_hidden\n",
    "        self.activation = activation\n",
    "        \n",
    "    def forward(self, x):\n",
    "        y = x\n",
    "        for hidden_idx in range(self.num_hidden):\n",
    "            y = self.fc_layers[hidden_idx](y)\n",
    "            y = self.activation(y)\n",
    "        y = self.fc_layers[self.num_hidden](y)\n",
    "        return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from torch.nn import Linear, ReLU\n",
    "# from torch_geometric.nn import Sequential\n",
    "\n",
    "class StandardGNN(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, output_dim, ):\n",
    "        super(StandardGNN, self).__init__()\n",
    "        self.l1 = Linear(dataset.num_features, 6)\n",
    "        self.l2 = Linear(6, 3)\n",
    "\n",
    "        self.conv1 = GCNConv(dataset.num_features, , cached=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# notes\n",
    "num_latent_params = 2 * latent_space_dim\n",
    "network = nn.Sequential(nn.Linear(data_dim, 300), ..., nn.Linear(400, num_latent_params))\n",
    "encoder(network)"
   ]
  }
 ]
}